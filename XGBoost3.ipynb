{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost + one hot encoding + scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv').drop(columns=['UID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   주거 형태              10000 non-null  object \n",
      " 1   연간 소득              10000 non-null  float64\n",
      " 2   현재 직장 근속 연수        10000 non-null  object \n",
      " 3   체납 세금 압류 횟수        10000 non-null  float64\n",
      " 4   개설된 신용계좌 수         10000 non-null  int64  \n",
      " 5   신용 거래 연수           10000 non-null  float64\n",
      " 6   최대 신용한도            10000 non-null  float64\n",
      " 7   신용 문제 발생 횟수        10000 non-null  int64  \n",
      " 8   마지막 연체 이후 경과 개월 수  10000 non-null  int64  \n",
      " 9   개인 파산 횟수           10000 non-null  int64  \n",
      " 10  대출 목적              10000 non-null  object \n",
      " 11  대출 상환 기간           10000 non-null  object \n",
      " 12  현재 대출 잔액           10000 non-null  float64\n",
      " 13  현재 미상환 신용액         10000 non-null  float64\n",
      " 14  월 상환 부채액           10000 non-null  float64\n",
      " 15  신용 점수              10000 non-null  int64  \n",
      " 16  채무 불이행 여부          10000 non-null  int64  \n",
      "dtypes: float64(7), int64(6), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()   # non-null: 이상치 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                주거 형태      연간 소득 현재 직장 근속 연수  체납 세금 압류 횟수  개설된 신용계좌 수  \\\n",
      "0                  자가  1941337.5      10년 이상          0.0           9   \n",
      "1                  월세  1979505.0      10년 이상          0.0           5   \n",
      "2                  월세  1356381.0          4년          0.0          12   \n",
      "3                  월세  1049017.5          6년          0.0          15   \n",
      "4                  월세  4320217.5          2년          0.0          11   \n",
      "...               ...        ...         ...          ...         ...   \n",
      "9995  주택 담보 대출 (거주 중)  1339473.0      10년 이상          0.0           9   \n",
      "9996  주택 담보 대출 (거주 중)  2297230.5          2년          0.0          11   \n",
      "9997  주택 담보 대출 (거주 중)  1221523.5      10년 이상          0.0           9   \n",
      "9998               자가  3343584.0      10년 이상          0.0          10   \n",
      "9999  주택 담보 대출 (거주 중)  2175133.5          5년          0.0           5   \n",
      "\n",
      "      신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  마지막 연체 이후 경과 개월 수  개인 파산 횟수   대출 목적  \\\n",
      "0         13.4  400597.5            0                 24         1   부채 통합   \n",
      "1         15.1  360679.5            0                 11         0   부채 통합   \n",
      "2         18.8  491770.5            1                 74         3   부채 통합   \n",
      "3         14.8  411546.0            1                 22         1   부채 통합   \n",
      "4         26.1  895288.5            0                 32         0   부채 통합   \n",
      "...        ...       ...          ...                ...       ...     ...   \n",
      "9995      18.7  319027.5            0                 68         0   부채 통합   \n",
      "9996      28.3  399799.5            0                  7         0  주택 개보수   \n",
      "9997      30.1  823305.0            0                 14         0   부채 통합   \n",
      "9998      20.3  724314.0            0                 25         0   부채 통합   \n",
      "9999      24.9   52999.5            0                  9         0  주택 개보수   \n",
      "\n",
      "     대출 상환 기간   현재 대출 잔액  현재 미상환 신용액  월 상환 부채액  신용 점수  \n",
      "0       단기 상환   390903.0    225457.5    8806.5    767  \n",
      "1       단기 상환  1002184.5     64749.0   24961.5    767  \n",
      "2       단기 상환   227775.0    487644.0   12069.0    800  \n",
      "3       단기 상환   251383.5    413211.0   31749.0    796  \n",
      "4       장기 상환  1163176.5     78991.5    5862.0    751  \n",
      "...       ...        ...         ...       ...    ...  \n",
      "9995    단기 상환   126216.0    177028.5    6237.0    755  \n",
      "9996    장기 상환   371907.0    347449.5   53301.0    707  \n",
      "9997    장기 상환   869736.0    176905.5   11436.0    733  \n",
      "9998    단기 상환   443008.5    139294.5   25567.5    696  \n",
      "9999    장기 상환  1152918.0    106930.5   12676.5    676  \n",
      "\n",
      "[10000 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "Y = df['채무 불이행 여부']\n",
    "X = df.drop('채무 불이행 여부', axis=1)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "\n",
    "font_path = 'C:\\\\Windows\\\\Fonts\\\\gulim.ttc'\n",
    "font = fm.FontProperties(fname = font_path).get_name()\n",
    "matplotlib.rc('font', family=font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간 소득</th>\n",
       "      <th>체납 세금 압류 횟수</th>\n",
       "      <th>개설된 신용계좌 수</th>\n",
       "      <th>신용 거래 연수</th>\n",
       "      <th>최대 신용한도</th>\n",
       "      <th>신용 문제 발생 횟수</th>\n",
       "      <th>마지막 연체 이후 경과 개월 수</th>\n",
       "      <th>개인 파산 횟수</th>\n",
       "      <th>현재 대출 잔액</th>\n",
       "      <th>현재 미상환 신용액</th>\n",
       "      <th>...</th>\n",
       "      <th>대출 목적_소규모 사업 자금</th>\n",
       "      <th>대출 목적_여행 자금</th>\n",
       "      <th>대출 목적_의료비</th>\n",
       "      <th>대출 목적_이사 비용</th>\n",
       "      <th>대출 목적_자동차 구매</th>\n",
       "      <th>대출 목적_주택 개보수</th>\n",
       "      <th>대출 목적_주택 구매</th>\n",
       "      <th>대출 목적_휴가 비용</th>\n",
       "      <th>대출 상환 기간_단기 상환</th>\n",
       "      <th>대출 상환 기간_장기 상환</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1941337.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>400597.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>390903.0</td>\n",
       "      <td>225457.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>360679.5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1002184.5</td>\n",
       "      <td>64749.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1356381.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>491770.5</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>227775.0</td>\n",
       "      <td>487644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049017.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.8</td>\n",
       "      <td>411546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>251383.5</td>\n",
       "      <td>413211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4320217.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>26.1</td>\n",
       "      <td>895288.5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1163176.5</td>\n",
       "      <td>78991.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1339473.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>319027.5</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>126216.0</td>\n",
       "      <td>177028.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2297230.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>28.3</td>\n",
       "      <td>399799.5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>371907.0</td>\n",
       "      <td>347449.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1221523.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>823305.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>869736.0</td>\n",
       "      <td>176905.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3343584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20.3</td>\n",
       "      <td>724314.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>443008.5</td>\n",
       "      <td>139294.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2175133.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>52999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1152918.0</td>\n",
       "      <td>106930.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          연간 소득  체납 세금 압류 횟수  개설된 신용계좌 수  신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  \\\n",
       "0     1941337.5          0.0           9      13.4  400597.5            0   \n",
       "1     1979505.0          0.0           5      15.1  360679.5            0   \n",
       "2     1356381.0          0.0          12      18.8  491770.5            1   \n",
       "3     1049017.5          0.0          15      14.8  411546.0            1   \n",
       "4     4320217.5          0.0          11      26.1  895288.5            0   \n",
       "...         ...          ...         ...       ...       ...          ...   \n",
       "9995  1339473.0          0.0           9      18.7  319027.5            0   \n",
       "9996  2297230.5          0.0          11      28.3  399799.5            0   \n",
       "9997  1221523.5          0.0           9      30.1  823305.0            0   \n",
       "9998  3343584.0          0.0          10      20.3  724314.0            0   \n",
       "9999  2175133.5          0.0           5      24.9   52999.5            0   \n",
       "\n",
       "      마지막 연체 이후 경과 개월 수  개인 파산 횟수   현재 대출 잔액  현재 미상환 신용액  ...  \\\n",
       "0                    24         1   390903.0    225457.5  ...   \n",
       "1                    11         0  1002184.5     64749.0  ...   \n",
       "2                    74         3   227775.0    487644.0  ...   \n",
       "3                    22         1   251383.5    413211.0  ...   \n",
       "4                    32         0  1163176.5     78991.5  ...   \n",
       "...                 ...       ...        ...         ...  ...   \n",
       "9995                 68         0   126216.0    177028.5  ...   \n",
       "9996                  7         0   371907.0    347449.5  ...   \n",
       "9997                 14         0   869736.0    176905.5  ...   \n",
       "9998                 25         0   443008.5    139294.5  ...   \n",
       "9999                  9         0  1152918.0    106930.5  ...   \n",
       "\n",
       "      대출 목적_소규모 사업 자금  대출 목적_여행 자금  대출 목적_의료비  대출 목적_이사 비용  대출 목적_자동차 구매  \\\n",
       "0                   0            0          0            0             0   \n",
       "1                   0            0          0            0             0   \n",
       "2                   0            0          0            0             0   \n",
       "3                   0            0          0            0             0   \n",
       "4                   0            0          0            0             0   \n",
       "...               ...          ...        ...          ...           ...   \n",
       "9995                0            0          0            0             0   \n",
       "9996                0            0          0            0             0   \n",
       "9997                0            0          0            0             0   \n",
       "9998                0            0          0            0             0   \n",
       "9999                0            0          0            0             0   \n",
       "\n",
       "      대출 목적_주택 개보수  대출 목적_주택 구매  대출 목적_휴가 비용  대출 상환 기간_단기 상환  대출 상환 기간_장기 상환  \n",
       "0                0            0            0               1               0  \n",
       "1                0            0            0               1               0  \n",
       "2                0            0            0               1               0  \n",
       "3                0            0            0               1               0  \n",
       "4                0            0            0               0               1  \n",
       "...            ...          ...          ...             ...             ...  \n",
       "9995             0            0            0               1               0  \n",
       "9996             1            0            0               0               1  \n",
       "9997             0            0            0               0               1  \n",
       "9998             0            0            0               1               0  \n",
       "9999             1            0            0               0               1  \n",
       "\n",
       "[10000 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원 핫 인코딩\n",
    "categories = ['주거 형태', '현재 직장 근속 연수', '대출 목적', '대출 상환 기간']\n",
    "\n",
    "\n",
    "X = pd.get_dummies(X, columns = categories, dtype=int) \n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연간 소득</th>\n",
       "      <th>체납 세금 압류 횟수</th>\n",
       "      <th>개설된 신용계좌 수</th>\n",
       "      <th>신용 거래 연수</th>\n",
       "      <th>최대 신용한도</th>\n",
       "      <th>신용 문제 발생 횟수</th>\n",
       "      <th>마지막 연체 이후 경과 개월 수</th>\n",
       "      <th>개인 파산 횟수</th>\n",
       "      <th>현재 대출 잔액</th>\n",
       "      <th>현재 미상환 신용액</th>\n",
       "      <th>...</th>\n",
       "      <th>대출 목적_소규모 사업 자금</th>\n",
       "      <th>대출 목적_여행 자금</th>\n",
       "      <th>대출 목적_의료비</th>\n",
       "      <th>대출 목적_이사 비용</th>\n",
       "      <th>대출 목적_자동차 구매</th>\n",
       "      <th>대출 목적_주택 개보수</th>\n",
       "      <th>대출 목적_주택 구매</th>\n",
       "      <th>대출 목적_휴가 비용</th>\n",
       "      <th>대출 상환 기간_단기 상환</th>\n",
       "      <th>대출 상환 기간_장기 상환</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1941337.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>13.4</td>\n",
       "      <td>400597.5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12.876217</td>\n",
       "      <td>12.325891</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1979505.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>360679.5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13.817694</td>\n",
       "      <td>11.078289</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1356381.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>18.8</td>\n",
       "      <td>491770.5</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>12.336118</td>\n",
       "      <td>13.097343</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049017.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.8</td>\n",
       "      <td>411546.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>12.434739</td>\n",
       "      <td>12.931716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4320217.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>26.1</td>\n",
       "      <td>895288.5</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>13.966666</td>\n",
       "      <td>11.277108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1339473.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>18.7</td>\n",
       "      <td>319027.5</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>11.745758</td>\n",
       "      <td>12.084072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2297230.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>28.3</td>\n",
       "      <td>399799.5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12.826402</td>\n",
       "      <td>12.758377</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1221523.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>823305.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>13.675946</td>\n",
       "      <td>12.083377</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3343584.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>20.3</td>\n",
       "      <td>724314.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>13.001346</td>\n",
       "      <td>11.844353</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2175133.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>52999.5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>13.957808</td>\n",
       "      <td>11.579944</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          연간 소득  체납 세금 압류 횟수  개설된 신용계좌 수  신용 거래 연수   최대 신용한도  신용 문제 발생 횟수  \\\n",
       "0     1941337.5          0.0           9      13.4  400597.5            0   \n",
       "1     1979505.0          0.0           5      15.1  360679.5            0   \n",
       "2     1356381.0          0.0          12      18.8  491770.5            1   \n",
       "3     1049017.5          0.0          15      14.8  411546.0            1   \n",
       "4     4320217.5          0.0          11      26.1  895288.5            0   \n",
       "...         ...          ...         ...       ...       ...          ...   \n",
       "9995  1339473.0          0.0           9      18.7  319027.5            0   \n",
       "9996  2297230.5          0.0          11      28.3  399799.5            0   \n",
       "9997  1221523.5          0.0           9      30.1  823305.0            0   \n",
       "9998  3343584.0          0.0          10      20.3  724314.0            0   \n",
       "9999  2175133.5          0.0           5      24.9   52999.5            0   \n",
       "\n",
       "      마지막 연체 이후 경과 개월 수  개인 파산 횟수   현재 대출 잔액  현재 미상환 신용액  ...  \\\n",
       "0                    24         1  12.876217   12.325891  ...   \n",
       "1                    11         0  13.817694   11.078289  ...   \n",
       "2                    74         3  12.336118   13.097343  ...   \n",
       "3                    22         1  12.434739   12.931716  ...   \n",
       "4                    32         0  13.966666   11.277108  ...   \n",
       "...                 ...       ...        ...         ...  ...   \n",
       "9995                 68         0  11.745758   12.084072  ...   \n",
       "9996                  7         0  12.826402   12.758377  ...   \n",
       "9997                 14         0  13.675946   12.083377  ...   \n",
       "9998                 25         0  13.001346   11.844353  ...   \n",
       "9999                  9         0  13.957808   11.579944  ...   \n",
       "\n",
       "      대출 목적_소규모 사업 자금  대출 목적_여행 자금  대출 목적_의료비  대출 목적_이사 비용  대출 목적_자동차 구매  \\\n",
       "0                   0            0          0            0             0   \n",
       "1                   0            0          0            0             0   \n",
       "2                   0            0          0            0             0   \n",
       "3                   0            0          0            0             0   \n",
       "4                   0            0          0            0             0   \n",
       "...               ...          ...        ...          ...           ...   \n",
       "9995                0            0          0            0             0   \n",
       "9996                0            0          0            0             0   \n",
       "9997                0            0          0            0             0   \n",
       "9998                0            0          0            0             0   \n",
       "9999                0            0          0            0             0   \n",
       "\n",
       "      대출 목적_주택 개보수  대출 목적_주택 구매  대출 목적_휴가 비용  대출 상환 기간_단기 상환  대출 상환 기간_장기 상환  \n",
       "0                0            0            0               1               0  \n",
       "1                0            0            0               1               0  \n",
       "2                0            0            0               1               0  \n",
       "3                0            0            0               1               0  \n",
       "4                0            0            0               0               1  \n",
       "...            ...          ...          ...             ...             ...  \n",
       "9995             0            0            0               1               0  \n",
       "9996             1            0            0               0               1  \n",
       "9997             0            0            0               0               1  \n",
       "9998             0            0            0               1               0  \n",
       "9999             1            0            0               0               1  \n",
       "\n",
       "[10000 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로그\n",
    "cl = ['현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액']\n",
    "\n",
    "for i in cl:\n",
    "    X[i] = X[i].apply(lambda x: np.log1p(x))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5, \n",
    "    learning_rate=0.1,\n",
    "    random_state=0\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred_train = xgb_clf.predict(X_train)\n",
    "y_pred_test = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 정확도:\n",
      " 0.7988\n",
      "훈련 데이터 정밀도:\n",
      " 0.7928858290304074\n",
      "훈련 데이터 재현율:\n",
      " 0.5462450592885375\n",
      "==============================\n",
      "평가 데이터 정확도:\n",
      " 0.7184\n",
      "평가 데이터 정밀도:\n",
      " 0.6618181818181819\n",
      "평가 데이터 재현율:\n",
      " 0.4126984126984127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "# 평가 (accuracy_score 사용)\n",
    "print(\"훈련 데이터 정확도:\\n\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"훈련 데이터 정밀도:\\n\", precision_score(y_train, y_pred_train))\n",
    "print(\"훈련 데이터 재현율:\\n\", recall_score(y_train, y_pred_train))\n",
    "\n",
    "print('='*30)\n",
    "\n",
    "print(\"평가 데이터 정확도:\\n\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"평가 데이터 정밀도:\\n\", precision_score(y_test, y_pred_test))\n",
    "print(\"평가 데이터 재현율:\\n\", recall_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988\n",
      "0.7184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80      1618\n",
      "           1       0.66      0.41      0.51       882\n",
      "\n",
      "    accuracy                           0.72      2500\n",
      "   macro avg       0.70      0.65      0.66      2500\n",
      "weighted avg       0.71      0.72      0.70      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(accuracy_score(y_train, y_pred_train))\n",
    "print(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier에 조기종료 적용 -> 과적합 방지, 훈련시간 단축\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=5, \n",
    "    learning_rate=0.1,\n",
    "    random_state=0,\n",
    "    early_stopping_rounds=10,   # 성능이 일정 횟수 이상 향상되지 않으면 조기종료 (반복을 중단할 횟수)\n",
    "    eval_metrics='logloss'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.62454\tvalidation_1-logloss:0.62788\n",
      "[1]\tvalidation_0-logloss:0.61235\tvalidation_1-logloss:0.61791\n",
      "[2]\tvalidation_0-logloss:0.60184\tvalidation_1-logloss:0.60924\n",
      "[3]\tvalidation_0-logloss:0.59329\tvalidation_1-logloss:0.60192\n",
      "[4]\tvalidation_0-logloss:0.58560\tvalidation_1-logloss:0.59584\n",
      "[5]\tvalidation_0-logloss:0.57837\tvalidation_1-logloss:0.59149\n",
      "[6]\tvalidation_0-logloss:0.57198\tvalidation_1-logloss:0.58692\n",
      "[7]\tvalidation_0-logloss:0.56627\tvalidation_1-logloss:0.58355\n",
      "[8]\tvalidation_0-logloss:0.56114\tvalidation_1-logloss:0.58074\n",
      "[9]\tvalidation_0-logloss:0.55538\tvalidation_1-logloss:0.57828\n",
      "[10]\tvalidation_0-logloss:0.55026\tvalidation_1-logloss:0.57565\n",
      "[11]\tvalidation_0-logloss:0.54583\tvalidation_1-logloss:0.57370\n",
      "[12]\tvalidation_0-logloss:0.54178\tvalidation_1-logloss:0.57213\n",
      "[13]\tvalidation_0-logloss:0.53748\tvalidation_1-logloss:0.57069\n",
      "[14]\tvalidation_0-logloss:0.53403\tvalidation_1-logloss:0.56845\n",
      "[15]\tvalidation_0-logloss:0.53035\tvalidation_1-logloss:0.56602\n",
      "[16]\tvalidation_0-logloss:0.52632\tvalidation_1-logloss:0.56411\n",
      "[17]\tvalidation_0-logloss:0.52287\tvalidation_1-logloss:0.56270\n",
      "[18]\tvalidation_0-logloss:0.51940\tvalidation_1-logloss:0.56154\n",
      "[19]\tvalidation_0-logloss:0.51691\tvalidation_1-logloss:0.56088\n",
      "[20]\tvalidation_0-logloss:0.51436\tvalidation_1-logloss:0.55982\n",
      "[21]\tvalidation_0-logloss:0.51173\tvalidation_1-logloss:0.55965\n",
      "[22]\tvalidation_0-logloss:0.50957\tvalidation_1-logloss:0.55932\n",
      "[23]\tvalidation_0-logloss:0.50657\tvalidation_1-logloss:0.55812\n",
      "[24]\tvalidation_0-logloss:0.50379\tvalidation_1-logloss:0.55744\n",
      "[25]\tvalidation_0-logloss:0.50177\tvalidation_1-logloss:0.55744\n",
      "[26]\tvalidation_0-logloss:0.49906\tvalidation_1-logloss:0.55640\n",
      "[27]\tvalidation_0-logloss:0.49705\tvalidation_1-logloss:0.55614\n",
      "[28]\tvalidation_0-logloss:0.49479\tvalidation_1-logloss:0.55666\n",
      "[29]\tvalidation_0-logloss:0.49204\tvalidation_1-logloss:0.55638\n",
      "[30]\tvalidation_0-logloss:0.48976\tvalidation_1-logloss:0.55587\n",
      "[31]\tvalidation_0-logloss:0.48766\tvalidation_1-logloss:0.55595\n",
      "[32]\tvalidation_0-logloss:0.48588\tvalidation_1-logloss:0.55537\n",
      "[33]\tvalidation_0-logloss:0.48371\tvalidation_1-logloss:0.55503\n",
      "[34]\tvalidation_0-logloss:0.48236\tvalidation_1-logloss:0.55501\n",
      "[35]\tvalidation_0-logloss:0.48077\tvalidation_1-logloss:0.55476\n",
      "[36]\tvalidation_0-logloss:0.47933\tvalidation_1-logloss:0.55535\n",
      "[37]\tvalidation_0-logloss:0.47796\tvalidation_1-logloss:0.55535\n",
      "[38]\tvalidation_0-logloss:0.47589\tvalidation_1-logloss:0.55491\n",
      "[39]\tvalidation_0-logloss:0.47473\tvalidation_1-logloss:0.55457\n",
      "[40]\tvalidation_0-logloss:0.47349\tvalidation_1-logloss:0.55434\n",
      "[41]\tvalidation_0-logloss:0.47240\tvalidation_1-logloss:0.55454\n",
      "[42]\tvalidation_0-logloss:0.47106\tvalidation_1-logloss:0.55482\n",
      "[43]\tvalidation_0-logloss:0.47053\tvalidation_1-logloss:0.55508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [00:48:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"eval_metrics\" } are not used.\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44]\tvalidation_0-logloss:0.46903\tvalidation_1-logloss:0.55484\n",
      "[45]\tvalidation_0-logloss:0.46723\tvalidation_1-logloss:0.55455\n",
      "[46]\tvalidation_0-logloss:0.46574\tvalidation_1-logloss:0.55463\n",
      "[47]\tvalidation_0-logloss:0.46507\tvalidation_1-logloss:0.55449\n",
      "[48]\tvalidation_0-logloss:0.46379\tvalidation_1-logloss:0.55440\n",
      "[49]\tvalidation_0-logloss:0.46205\tvalidation_1-logloss:0.55417\n",
      "[50]\tvalidation_0-logloss:0.46171\tvalidation_1-logloss:0.55407\n",
      "[51]\tvalidation_0-logloss:0.46024\tvalidation_1-logloss:0.55385\n",
      "[52]\tvalidation_0-logloss:0.45948\tvalidation_1-logloss:0.55375\n",
      "[53]\tvalidation_0-logloss:0.45837\tvalidation_1-logloss:0.55390\n",
      "[54]\tvalidation_0-logloss:0.45796\tvalidation_1-logloss:0.55379\n",
      "[55]\tvalidation_0-logloss:0.45670\tvalidation_1-logloss:0.55380\n",
      "[56]\tvalidation_0-logloss:0.45534\tvalidation_1-logloss:0.55383\n",
      "[57]\tvalidation_0-logloss:0.45479\tvalidation_1-logloss:0.55352\n",
      "[58]\tvalidation_0-logloss:0.45407\tvalidation_1-logloss:0.55320\n",
      "[59]\tvalidation_0-logloss:0.45318\tvalidation_1-logloss:0.55301\n",
      "[60]\tvalidation_0-logloss:0.45175\tvalidation_1-logloss:0.55294\n",
      "[61]\tvalidation_0-logloss:0.45073\tvalidation_1-logloss:0.55305\n",
      "[62]\tvalidation_0-logloss:0.44904\tvalidation_1-logloss:0.55302\n",
      "[63]\tvalidation_0-logloss:0.44873\tvalidation_1-logloss:0.55307\n",
      "[64]\tvalidation_0-logloss:0.44824\tvalidation_1-logloss:0.55329\n",
      "[65]\tvalidation_0-logloss:0.44635\tvalidation_1-logloss:0.55285\n",
      "[66]\tvalidation_0-logloss:0.44545\tvalidation_1-logloss:0.55296\n",
      "[67]\tvalidation_0-logloss:0.44467\tvalidation_1-logloss:0.55313\n",
      "[68]\tvalidation_0-logloss:0.44349\tvalidation_1-logloss:0.55369\n",
      "[69]\tvalidation_0-logloss:0.44264\tvalidation_1-logloss:0.55370\n",
      "[70]\tvalidation_0-logloss:0.44072\tvalidation_1-logloss:0.55357\n",
      "[71]\tvalidation_0-logloss:0.43980\tvalidation_1-logloss:0.55324\n",
      "[72]\tvalidation_0-logloss:0.43857\tvalidation_1-logloss:0.55357\n",
      "[73]\tvalidation_0-logloss:0.43695\tvalidation_1-logloss:0.55413\n",
      "[74]\tvalidation_0-logloss:0.43606\tvalidation_1-logloss:0.55430\n",
      "[75]\tvalidation_0-logloss:0.43550\tvalidation_1-logloss:0.55439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric=None,\n",
       "              eval_metrics=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric=None,\n",
       "              eval_metrics=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric=None,\n",
       "              eval_metrics='logloss', feature_types=None, feature_weights=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, random_state=0)\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=eval_set, verbose=True)\n",
    "# eval_set: 검증 데이터, verbose: 학습 중 평가 결과 출력 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 훈련 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result = xgb_clf.evals_result()\n",
    "train_loss = result['validation_0']['logloss']\n",
    "val_loss = result['validation_1']['logloss']\n",
    "\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('nth round')\n",
    "plt.ylabel('logloss')\n",
    "plt.legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 00:48:31,583] A new study created in memory with name: no-name-f4b593d7-ee94-4d8e-b8bf-35adf118d6d0\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:31,696] Trial 0 finished with value: 0.7148 and parameters: {'max_depth': 7, 'learning_rate': 0.2251180157271257, 'n_estimators': 115, 'subsample': 0.5425801741755567, 'colsample_bytree': 0.8159436698423865, 'reg_alpha': 2.096676255275556, 'reg_lambda': 8.447193998282096, 'gamma': 3.678261734758908}. Best is trial 0 with value: 0.7148.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:32,045] Trial 1 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.10361998068272961, 'n_estimators': 460, 'subsample': 0.8479133989148354, 'colsample_bytree': 0.5287291310553128, 'reg_alpha': 2.3526958051780698, 'reg_lambda': 4.791070178884883, 'gamma': 3.069719922134084}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:32,669] Trial 2 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.021730824224836524, 'n_estimators': 882, 'subsample': 0.6800669223968652, 'colsample_bytree': 0.5145736862760988, 'reg_alpha': 1.040172096195452, 'reg_lambda': 9.081201035473539, 'gamma': 4.513742657441472}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:32,844] Trial 3 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.22991409577572278, 'n_estimators': 253, 'subsample': 0.8235183834838301, 'colsample_bytree': 0.6930399150487827, 'reg_alpha': 3.2717947954885407, 'reg_lambda': 9.351780884787543, 'gamma': 3.315576248880017}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:33,600] Trial 4 finished with value: 0.6952 and parameters: {'max_depth': 8, 'learning_rate': 0.1909917669900979, 'n_estimators': 811, 'subsample': 0.5870022315686259, 'colsample_bytree': 0.7170226331828586, 'reg_alpha': 0.45070005700685645, 'reg_lambda': 5.8732413926826705, 'gamma': 0.7655272290613457}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:34,006] Trial 5 finished with value: 0.7184 and parameters: {'max_depth': 6, 'learning_rate': 0.04274500015917789, 'n_estimators': 622, 'subsample': 0.9822763551380325, 'colsample_bytree': 0.8074039102393327, 'reg_alpha': 2.063917408391762, 'reg_lambda': 4.419223110704921, 'gamma': 3.673644977978372}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:34,117] Trial 6 finished with value: 0.7104 and parameters: {'max_depth': 10, 'learning_rate': 0.09710005528776255, 'n_estimators': 114, 'subsample': 0.9868418237256769, 'colsample_bytree': 0.8627247336785607, 'reg_alpha': 9.615379571854735, 'reg_lambda': 6.247756089369883, 'gamma': 4.1910069236964995}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:34,552] Trial 7 finished with value: 0.7164 and parameters: {'max_depth': 4, 'learning_rate': 0.030567244387657636, 'n_estimators': 639, 'subsample': 0.8288525229672881, 'colsample_bytree': 0.9356491754131341, 'reg_alpha': 3.2651648864988436, 'reg_lambda': 1.562394582759754, 'gamma': 3.6020719798358907}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:34,726] Trial 8 finished with value: 0.7208 and parameters: {'max_depth': 9, 'learning_rate': 0.18160987511184865, 'n_estimators': 251, 'subsample': 0.8860004060645899, 'colsample_bytree': 0.5244160893940486, 'reg_alpha': 0.28542651494464, 'reg_lambda': 8.471349894602914, 'gamma': 3.8261326455466103}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:35,202] Trial 9 finished with value: 0.7156 and parameters: {'max_depth': 8, 'learning_rate': 0.1406503546444816, 'n_estimators': 797, 'subsample': 0.9475662685838041, 'colsample_bytree': 0.8527760636999131, 'reg_alpha': 4.917293373725878, 'reg_lambda': 7.219259988163628, 'gamma': 2.8028752294867636}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:35,533] Trial 10 finished with value: 0.718 and parameters: {'max_depth': 3, 'learning_rate': 0.2847421616737207, 'n_estimators': 446, 'subsample': 0.71038595116722, 'colsample_bytree': 0.6240403046008447, 'reg_alpha': 8.151325200971282, 'reg_lambda': 3.4078638508461117, 'gamma': 1.519907043724}. Best is trial 1 with value: 0.7228.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:35,832] Trial 11 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.2582675582973106, 'n_estimators': 382, 'subsample': 0.814763627626829, 'colsample_bytree': 0.6783831219579314, 'reg_alpha': 5.020619180001164, 'reg_lambda': 2.758489897518683, 'gamma': 2.582692521711369}. Best is trial 11 with value: 0.7256.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:36,129] Trial 12 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.10589192262117783, 'n_estimators': 402, 'subsample': 0.7860328872612361, 'colsample_bytree': 0.6172203725813509, 'reg_alpha': 6.190625267122457, 'reg_lambda': 0.18731781067105402, 'gamma': 1.9903498162584998}. Best is trial 11 with value: 0.7256.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:36,405] Trial 13 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.29732193333404333, 'n_estimators': 362, 'subsample': 0.7572646523646056, 'colsample_bytree': 0.6396702139441477, 'reg_alpha': 6.438723671243999, 'reg_lambda': 0.023787000718404144, 'gamma': 1.986945812801485}. Best is trial 11 with value: 0.7256.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:36,798] Trial 14 finished with value: 0.7272 and parameters: {'max_depth': 4, 'learning_rate': 0.0961888804461834, 'n_estimators': 507, 'subsample': 0.7629721105404531, 'colsample_bytree': 0.6180672336472876, 'reg_alpha': 5.871814141546236, 'reg_lambda': 2.1749391142637586, 'gamma': 2.0796142704300093}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:37,608] Trial 15 finished with value: 0.7196 and parameters: {'max_depth': 6, 'learning_rate': 0.06896522333262499, 'n_estimators': 564, 'subsample': 0.6708883884991154, 'colsample_bytree': 0.6728788935778884, 'reg_alpha': 4.951366363111168, 'reg_lambda': 2.714320530812279, 'gamma': 0.10205206978920867}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:38,054] Trial 16 finished with value: 0.7184 and parameters: {'max_depth': 4, 'learning_rate': 0.14582512801311082, 'n_estimators': 700, 'subsample': 0.9181191708253469, 'colsample_bytree': 0.5842017465921439, 'reg_alpha': 6.738556471777134, 'reg_lambda': 2.067654561484786, 'gamma': 2.3008660411314104}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:38,325] Trial 17 finished with value: 0.7096 and parameters: {'max_depth': 4, 'learning_rate': 0.25252330691958963, 'n_estimators': 305, 'subsample': 0.7358860301641224, 'colsample_bytree': 0.7543082366872643, 'reg_alpha': 4.2246165893743335, 'reg_lambda': 3.546192965898554, 'gamma': 1.1853578799260296}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:39,081] Trial 18 finished with value: 0.7204 and parameters: {'max_depth': 7, 'learning_rate': 0.17608615170076067, 'n_estimators': 988, 'subsample': 0.6370081011691532, 'colsample_bytree': 0.761336810861832, 'reg_alpha': 7.769601164803335, 'reg_lambda': 1.2179308503266952, 'gamma': 2.5451633017344424}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:39,467] Trial 19 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.06284182155706192, 'n_estimators': 496, 'subsample': 0.7890112008235239, 'colsample_bytree': 0.5880857037981351, 'reg_alpha': 5.558230673895087, 'reg_lambda': 3.6918382809194066, 'gamma': 1.4918040517640518}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:39,919] Trial 20 finished with value: 0.7156 and parameters: {'max_depth': 6, 'learning_rate': 0.1224382390472114, 'n_estimators': 544, 'subsample': 0.8991288380418471, 'colsample_bytree': 0.9448829498926585, 'reg_alpha': 7.745170403605802, 'reg_lambda': 2.4008207763395664, 'gamma': 0.5165653123709819}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:40,195] Trial 21 finished with value: 0.7188 and parameters: {'max_depth': 3, 'learning_rate': 0.08810158950143307, 'n_estimators': 365, 'subsample': 0.7743000608922118, 'colsample_bytree': 0.5833881485650366, 'reg_alpha': 6.397364478492208, 'reg_lambda': 0.31106610690439496, 'gamma': 1.9763227304427153}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:40,563] Trial 22 finished with value: 0.7172 and parameters: {'max_depth': 4, 'learning_rate': 0.12141226081970168, 'n_estimators': 380, 'subsample': 0.799230988829539, 'colsample_bytree': 0.666371677964888, 'reg_alpha': 5.53109609698172, 'reg_lambda': 1.0339200222533398, 'gamma': 2.126001341780217}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:40,759] Trial 23 finished with value: 0.718 and parameters: {'max_depth': 3, 'learning_rate': 0.06764295719894445, 'n_estimators': 210, 'subsample': 0.863881461013019, 'colsample_bytree': 0.629030560188815, 'reg_alpha': 4.031901432066396, 'reg_lambda': 0.7182943318531905, 'gamma': 2.6654360086556053}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:41,074] Trial 24 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.1608390711102143, 'n_estimators': 408, 'subsample': 0.7081921787977008, 'colsample_bytree': 0.7192002816600034, 'reg_alpha': 7.008443201758128, 'reg_lambda': 1.974160605189468, 'gamma': 1.7836598281747382}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:41,466] Trial 25 finished with value: 0.718 and parameters: {'max_depth': 5, 'learning_rate': 0.2102998062636608, 'n_estimators': 523, 'subsample': 0.7335688031989255, 'colsample_bytree': 0.5832392303893751, 'reg_alpha': 8.778471013146959, 'reg_lambda': 2.7549331332740543, 'gamma': 1.262100557789219}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:41,870] Trial 26 finished with value: 0.7196 and parameters: {'max_depth': 3, 'learning_rate': 0.13820845939825993, 'n_estimators': 653, 'subsample': 0.7984731236465686, 'colsample_bytree': 0.5512864776627362, 'reg_alpha': 5.467225977159337, 'reg_lambda': 1.3483898173977682, 'gamma': 3.0465951111795437}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:42,118] Trial 27 finished with value: 0.7216 and parameters: {'max_depth': 4, 'learning_rate': 0.2589143419747317, 'n_estimators': 313, 'subsample': 0.6568647559583138, 'colsample_bytree': 0.652443120092616, 'reg_alpha': 4.071943950561583, 'reg_lambda': 3.068498617548009, 'gamma': 2.5402765134397276}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:42,538] Trial 28 finished with value: 0.714 and parameters: {'max_depth': 5, 'learning_rate': 0.1194788415284118, 'n_estimators': 441, 'subsample': 0.6085590755842482, 'colsample_bytree': 0.6101772231647218, 'reg_alpha': 5.785658910600398, 'reg_lambda': 4.09314906890898, 'gamma': 0.9885340874515016}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:42,789] Trial 29 finished with value: 0.7256 and parameters: {'max_depth': 7, 'learning_rate': 0.08508526558698824, 'n_estimators': 200, 'subsample': 0.5169888965419607, 'colsample_bytree': 0.9922831809324324, 'reg_alpha': 7.236442115622593, 'reg_lambda': 5.427254473875707, 'gamma': 1.7050938367055617}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:43,023] Trial 30 finished with value: 0.718 and parameters: {'max_depth': 7, 'learning_rate': 0.04996121671646242, 'n_estimators': 179, 'subsample': 0.5089774061601092, 'colsample_bytree': 0.8965214397622946, 'reg_alpha': 7.123185478055046, 'reg_lambda': 5.559987693190939, 'gamma': 2.296209175334576}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:43,258] Trial 31 finished with value: 0.7188 and parameters: {'max_depth': 8, 'learning_rate': 0.08411349799343996, 'n_estimators': 145, 'subsample': 0.5547460618036021, 'colsample_bytree': 0.9933094625287306, 'reg_alpha': 5.940508514996056, 'reg_lambda': 6.610202133890329, 'gamma': 1.6354490175919192}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:43,566] Trial 32 finished with value: 0.7244 and parameters: {'max_depth': 6, 'learning_rate': 0.1021739522140611, 'n_estimators': 302, 'subsample': 0.8390590080400004, 'colsample_bytree': 0.7836776494092942, 'reg_alpha': 8.803623230906016, 'reg_lambda': 4.955929388689725, 'gamma': 2.9187483942722645}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:43,830] Trial 33 finished with value: 0.7216 and parameters: {'max_depth': 6, 'learning_rate': 0.08039739023454669, 'n_estimators': 294, 'subsample': 0.8399566718904188, 'colsample_bytree': 0.8193800691921934, 'reg_alpha': 9.834068694038447, 'reg_lambda': 5.053529517740143, 'gamma': 3.010271729698404}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:44,044] Trial 34 finished with value: 0.7192 and parameters: {'max_depth': 7, 'learning_rate': 0.10679149661316928, 'n_estimators': 226, 'subsample': 0.8681238746812339, 'colsample_bytree': 0.7853409566175261, 'reg_alpha': 8.602120779196063, 'reg_lambda': 5.292171596375326, 'gamma': 2.817624063233549}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:44,201] Trial 35 finished with value: 0.7188 and parameters: {'max_depth': 6, 'learning_rate': 0.16207980045257564, 'n_estimators': 168, 'subsample': 0.9279614177519482, 'colsample_bytree': 0.7009910180995411, 'reg_alpha': 9.165496490510266, 'reg_lambda': 7.0869817513415425, 'gamma': 3.3197106741769056}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:44,491] Trial 36 finished with value: 0.7204 and parameters: {'max_depth': 5, 'learning_rate': 0.04716249715255377, 'n_estimators': 332, 'subsample': 0.8177349329512962, 'colsample_bytree': 0.7311659802077862, 'reg_alpha': 7.675475426750351, 'reg_lambda': 4.3893804135925425, 'gamma': 2.2871704426443284}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:44,827] Trial 37 finished with value: 0.7144 and parameters: {'max_depth': 7, 'learning_rate': 0.011910491130747353, 'n_estimators': 270, 'subsample': 0.7604397768578832, 'colsample_bytree': 0.9852729663084877, 'reg_alpha': 7.434342295510325, 'reg_lambda': 7.667759853243076, 'gamma': 4.127218907869404}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:45,187] Trial 38 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.2417240476706095, 'n_estimators': 486, 'subsample': 0.8542825942802794, 'colsample_bytree': 0.688878703641458, 'reg_alpha': 3.137505954486416, 'reg_lambda': 4.804619201475925, 'gamma': 3.227132362896655}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:45,632] Trial 39 finished with value: 0.7228 and parameters: {'max_depth': 8, 'learning_rate': 0.20712604455830597, 'n_estimators': 577, 'subsample': 0.7009073093514486, 'colsample_bytree': 0.5022603116842389, 'reg_alpha': 8.378897153648987, 'reg_lambda': 6.140851123832189, 'gamma': 1.7461546880843022}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:45,861] Trial 40 finished with value: 0.7124 and parameters: {'max_depth': 5, 'learning_rate': 0.029644554166155357, 'n_estimators': 128, 'subsample': 0.8168984774620187, 'colsample_bytree': 0.8867602371214608, 'reg_alpha': 9.216323224582037, 'reg_lambda': 4.177132306997238, 'gamma': 3.4937574419476745}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:46,263] Trial 41 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.09697125241619449, 'n_estimators': 421, 'subsample': 0.739932276313597, 'colsample_bytree': 0.5504269649519631, 'reg_alpha': 4.6129122486791525, 'reg_lambda': 9.898483104657949, 'gamma': 2.1027746735298187}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:46,544] Trial 42 finished with value: 0.7176 and parameters: {'max_depth': 9, 'learning_rate': 0.11084285845735657, 'n_estimators': 353, 'subsample': 0.7823040043283324, 'colsample_bytree': 0.611718752538693, 'reg_alpha': 6.285699405584345, 'reg_lambda': 1.9271888562713242, 'gamma': 2.8152188792777286}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:46,845] Trial 43 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.12812914504452974, 'n_estimators': 253, 'subsample': 0.8826255281082575, 'colsample_bytree': 0.5462888080923631, 'reg_alpha': 6.050819940572798, 'reg_lambda': 0.5677779233381937, 'gamma': 1.3613832577989737}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:47,170] Trial 44 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.09873441755620568, 'n_estimators': 406, 'subsample': 0.8265805978057955, 'colsample_bytree': 0.6550729981757255, 'reg_alpha': 1.5244431818050042, 'reg_lambda': 5.615593008246824, 'gamma': 4.8245795823773445}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:47,550] Trial 45 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.08066131558173512, 'n_estimators': 475, 'subsample': 0.7658789034847509, 'colsample_bytree': 0.6842707271986248, 'reg_alpha': 6.777367919913795, 'reg_lambda': 3.2170663625869382, 'gamma': 1.942684010630411}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:47,762] Trial 46 finished with value: 0.7136 and parameters: {'max_depth': 7, 'learning_rate': 0.14927771141014695, 'n_estimators': 223, 'subsample': 0.9577552355927939, 'colsample_bytree': 0.8210197938425612, 'reg_alpha': 5.141256298639602, 'reg_lambda': 3.8125018371456996, 'gamma': 2.4368829806781527}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:48,257] Trial 47 finished with value: 0.708 and parameters: {'max_depth': 4, 'learning_rate': 0.13299124611816387, 'n_estimators': 604, 'subsample': 0.8091706586638947, 'colsample_bytree': 0.7828014859103141, 'reg_alpha': 2.661200656924918, 'reg_lambda': 1.748039245284947, 'gamma': 0.979699074586371}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:48,774] Trial 48 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.05230933361893733, 'n_estimators': 713, 'subsample': 0.5790914904401425, 'colsample_bytree': 0.7333959077602352, 'reg_alpha': 4.3801770284652966, 'reg_lambda': 2.6238758422674535, 'gamma': 3.9176438886127496}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:49,294] Trial 49 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.05663844597195674, 'n_estimators': 737, 'subsample': 0.5246377264830666, 'colsample_bytree': 0.852033184472871, 'reg_alpha': 3.5311828704320654, 'reg_lambda': 2.7769816659297994, 'gamma': 3.907132589736246}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:49,875] Trial 50 finished with value: 0.7212 and parameters: {'max_depth': 8, 'learning_rate': 0.04000861971393087, 'n_estimators': 870, 'subsample': 0.5547000044744815, 'colsample_bytree': 0.738222954075092, 'reg_alpha': 4.501239121733647, 'reg_lambda': 2.4326439101701913, 'gamma': 4.468546056111761}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:50,347] Trial 51 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.06881592122743715, 'n_estimators': 664, 'subsample': 0.5651711024706152, 'colsample_bytree': 0.7071776229939251, 'reg_alpha': 8.101404597487111, 'reg_lambda': 0.10092041124077866, 'gamma': 1.8316007599298865}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:50,600] Trial 52 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.11028389175007905, 'n_estimators': 286, 'subsample': 0.5029476208997512, 'colsample_bytree': 0.6437273943579628, 'reg_alpha': 5.07222901321555, 'reg_lambda': 1.066851512975398, 'gamma': 2.1841434711686576}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:51,094] Trial 53 finished with value: 0.7204 and parameters: {'max_depth': 4, 'learning_rate': 0.08808416331516009, 'n_estimators': 770, 'subsample': 0.6229942688196208, 'colsample_bytree': 0.9555403322509761, 'reg_alpha': 4.57837166869521, 'reg_lambda': 4.503914871079446, 'gamma': 4.999394484483687}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:51,495] Trial 54 finished with value: 0.704 and parameters: {'max_depth': 3, 'learning_rate': 0.2792627768216308, 'n_estimators': 518, 'subsample': 0.5729363432645601, 'colsample_bytree': 0.7654592302887925, 'reg_alpha': 3.7120393889951955, 'reg_lambda': 2.3066889592180955, 'gamma': 1.56266698916836}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:51,843] Trial 55 finished with value: 0.7192 and parameters: {'max_depth': 4, 'learning_rate': 0.07352663733899538, 'n_estimators': 454, 'subsample': 0.5277411749087573, 'colsample_bytree': 0.6771134432095165, 'reg_alpha': 6.563593406228317, 'reg_lambda': 8.283012341082074, 'gamma': 2.4613968435130857}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:51,972] Trial 56 finished with value: 0.7132 and parameters: {'max_depth': 3, 'learning_rate': 0.05688809378121953, 'n_estimators': 100, 'subsample': 0.6046192035001599, 'colsample_bytree': 0.6048459374846523, 'reg_alpha': 7.24740959815412, 'reg_lambda': 6.508543642595308, 'gamma': 2.6245232187847987}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:52,250] Trial 57 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.09639210031443231, 'n_estimators': 383, 'subsample': 0.7237197913176631, 'colsample_bytree': 0.6276149609139263, 'reg_alpha': 5.318419821933014, 'reg_lambda': 3.0829566087536726, 'gamma': 3.913551872016365}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:52,505] Trial 58 finished with value: 0.7176 and parameters: {'max_depth': 5, 'learning_rate': 0.11538182750140728, 'n_estimators': 323, 'subsample': 0.6922975238215844, 'colsample_bytree': 0.799683424799806, 'reg_alpha': 5.873973378247252, 'reg_lambda': 1.4519138094095485, 'gamma': 2.979864003158772}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:53,100] Trial 59 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.035882094272141556, 'n_estimators': 942, 'subsample': 0.8463497559761652, 'colsample_bytree': 0.7351067466076103, 'reg_alpha': 4.708510983777901, 'reg_lambda': 0.8138209866136434, 'gamma': 3.5799570874004383}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:53,490] Trial 60 finished with value: 0.7208 and parameters: {'max_depth': 9, 'learning_rate': 0.1811586860282015, 'n_estimators': 603, 'subsample': 0.7485367444826904, 'colsample_bytree': 0.9185896826660487, 'reg_alpha': 6.889832860246059, 'reg_lambda': 3.6512552411400243, 'gamma': 4.3994673714329195}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:53,777] Trial 61 finished with value: 0.7264 and parameters: {'max_depth': 4, 'learning_rate': 0.09732004470388865, 'n_estimators': 353, 'subsample': 0.6523178535122507, 'colsample_bytree': 0.5546931839710227, 'reg_alpha': 4.89436212621893, 'reg_lambda': 9.582282275765593, 'gamma': 2.0569190287712615}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:54,063] Trial 62 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.09177577293519774, 'n_estimators': 343, 'subsample': 0.6572009331233587, 'colsample_bytree': 0.5681938434826869, 'reg_alpha': 4.207240344998191, 'reg_lambda': 8.430348444326293, 'gamma': 1.9977886336304982}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:54,259] Trial 63 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.07631244001394841, 'n_estimators': 180, 'subsample': 0.6485963490313716, 'colsample_bytree': 0.5680051028567763, 'reg_alpha': 4.284060548649921, 'reg_lambda': 9.9139623075276, 'gamma': 2.055969220068959}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:54,550] Trial 64 finished with value: 0.7196 and parameters: {'max_depth': 4, 'learning_rate': 0.09209123794419086, 'n_estimators': 329, 'subsample': 0.5885626350296753, 'colsample_bytree': 0.5226331065981773, 'reg_alpha': 3.8669421826939, 'reg_lambda': 8.87228791388587, 'gamma': 1.690579404198179}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:54,814] Trial 65 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.06011646716985852, 'n_estimators': 263, 'subsample': 0.6628016881499617, 'colsample_bytree': 0.5701823591416265, 'reg_alpha': 3.164378515293273, 'reg_lambda': 9.374435892328712, 'gamma': 1.8806324635930358}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:55,135] Trial 66 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.10156907925585251, 'n_estimators': 429, 'subsample': 0.6868715090295603, 'colsample_bytree': 0.5338382931175741, 'reg_alpha': 4.819818777551217, 'reg_lambda': 8.217814619808776, 'gamma': 2.353979700091491}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:55,482] Trial 67 finished with value: 0.7164 and parameters: {'max_depth': 5, 'learning_rate': 0.12896691208061084, 'n_estimators': 357, 'subsample': 0.6229933600972806, 'colsample_bytree': 0.655950849649663, 'reg_alpha': 4.3274164361289085, 'reg_lambda': 9.311573270014186, 'gamma': 1.3670672780725281}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:55,767] Trial 68 finished with value: 0.7152 and parameters: {'max_depth': 6, 'learning_rate': 0.021277798719581076, 'n_estimators': 206, 'subsample': 0.5269502563951203, 'colsample_bytree': 0.7202312430978709, 'reg_alpha': 2.9068922596858315, 'reg_lambda': 8.84960593730248, 'gamma': 2.712623985270438}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:56,331] Trial 69 finished with value: 0.7216 and parameters: {'max_depth': 4, 'learning_rate': 0.08723940066880516, 'n_estimators': 829, 'subsample': 0.5859641219380392, 'colsample_bytree': 0.6056074749648608, 'reg_alpha': 5.568305950591696, 'reg_lambda': 7.76536686718798, 'gamma': 2.142943827272746}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:56,640] Trial 70 finished with value: 0.7072 and parameters: {'max_depth': 7, 'learning_rate': 0.19846767129436682, 'n_estimators': 289, 'subsample': 0.6428445917323541, 'colsample_bytree': 0.5664325980088689, 'reg_alpha': 3.5449089824594298, 'reg_lambda': 7.2648491177725285, 'gamma': 1.0946768282218748}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:56,938] Trial 71 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.1078149507719571, 'n_estimators': 382, 'subsample': 0.6890938878964041, 'colsample_bytree': 0.5434360212493718, 'reg_alpha': 5.202302236136879, 'reg_lambda': 8.297056626295916, 'gamma': 2.312207765515844}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:57,221] Trial 72 finished with value: 0.718 and parameters: {'max_depth': 4, 'learning_rate': 0.22780770562866073, 'n_estimators': 387, 'subsample': 0.671763828736788, 'colsample_bytree': 0.5078216383266039, 'reg_alpha': 5.196525312511221, 'reg_lambda': 8.662588750636932, 'gamma': 2.2628995157624288}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:57,490] Trial 73 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.07328454059475317, 'n_estimators': 337, 'subsample': 0.6235774349416904, 'colsample_bytree': 0.5891219607770259, 'reg_alpha': 4.954675459150071, 'reg_lambda': 9.582673054721052, 'gamma': 3.2567845579741013}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:57,911] Trial 74 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.10557417177519007, 'n_estimators': 515, 'subsample': 0.7081051148226335, 'colsample_bytree': 0.5308884069879733, 'reg_alpha': 4.067822475374606, 'reg_lambda': 8.007499218010393, 'gamma': 1.4575180014280225}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:58,245] Trial 75 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.16895375961246317, 'n_estimators': 465, 'subsample': 0.7191383034296023, 'colsample_bytree': 0.5417051073508434, 'reg_alpha': 5.770980372443624, 'reg_lambda': 6.799378529737023, 'gamma': 1.9782351980945718}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:58,459] Trial 76 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.11866466257700711, 'n_estimators': 240, 'subsample': 0.5410920278127086, 'colsample_bytree': 0.8390738887035936, 'reg_alpha': 5.358752575324135, 'reg_lambda': 7.523031463131279, 'gamma': 2.561420475197655}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:58,690] Trial 77 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.11883914505342291, 'n_estimators': 245, 'subsample': 0.5340417224493427, 'colsample_bytree': 0.595358396264847, 'reg_alpha': 5.365281350510106, 'reg_lambda': 7.5472533192689975, 'gamma': 0.37841720492352193}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:58,878] Trial 78 finished with value: 0.7264 and parameters: {'max_depth': 3, 'learning_rate': 0.15199907608737123, 'n_estimators': 204, 'subsample': 0.5433930894500103, 'colsample_bytree': 0.5653608079093162, 'reg_alpha': 6.169522570369626, 'reg_lambda': 8.962933421129469, 'gamma': 2.453210435154495}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:59,105] Trial 79 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.14173639160435383, 'n_estimators': 195, 'subsample': 0.5163156516363901, 'colsample_bytree': 0.840857621604966, 'reg_alpha': 6.288524007224661, 'reg_lambda': 9.02764013590063, 'gamma': 2.502315608104922}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:59,270] Trial 80 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.15164102541831637, 'n_estimators': 160, 'subsample': 0.5436000555479038, 'colsample_bytree': 0.9732696858044149, 'reg_alpha': 5.693142225130627, 'reg_lambda': 9.180512438292805, 'gamma': 2.6932603634216243}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:59,476] Trial 81 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.12528635662562185, 'n_estimators': 232, 'subsample': 0.5438121460421705, 'colsample_bytree': 0.5561436917778196, 'reg_alpha': 6.053870299449814, 'reg_lambda': 8.384525393787252, 'gamma': 2.380109523629236}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:48:59,629] Trial 82 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.13732607747287298, 'n_estimators': 139, 'subsample': 0.5759671771028595, 'colsample_bytree': 0.5190192115013528, 'reg_alpha': 6.574491179759109, 'reg_lambda': 8.614611805529584, 'gamma': 2.2243428794551843}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:48:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:00,060] Trial 83 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.09284245351561417, 'n_estimators': 543, 'subsample': 0.5971324150950167, 'colsample_bytree': 0.6211952304851502, 'reg_alpha': 4.881234866674256, 'reg_lambda': 9.585297613339659, 'gamma': 1.6853121000853037}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:00,300] Trial 84 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.11371651056235586, 'n_estimators': 267, 'subsample': 0.5605417090847878, 'colsample_bytree': 0.5778234645168719, 'reg_alpha': 4.387089788487824, 'reg_lambda': 8.013838111799938, 'gamma': 1.8200569554017578}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:00,797] Trial 85 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.07890741126831129, 'n_estimators': 687, 'subsample': 0.6759159499135339, 'colsample_bytree': 0.8822099178865933, 'reg_alpha': 5.395284209025843, 'reg_lambda': 7.98105638381938, 'gamma': 2.0526424876021183}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:01,100] Trial 86 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.0629852994881335, 'n_estimators': 366, 'subsample': 0.5017807725253584, 'colsample_bytree': 0.6409863613837068, 'reg_alpha': 5.108972127112994, 'reg_lambda': 9.669153404659859, 'gamma': 3.121380846088558}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:01,420] Trial 87 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.162763311566767, 'n_estimators': 400, 'subsample': 0.5486368354220524, 'colsample_bytree': 0.563271726049457, 'reg_alpha': 6.131902952870567, 'reg_lambda': 2.6818073513386356, 'gamma': 2.6007640539012744}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:01,615] Trial 88 finished with value: 0.7168 and parameters: {'max_depth': 3, 'learning_rate': 0.048759757216177015, 'n_estimators': 200, 'subsample': 0.5153115886491794, 'colsample_bytree': 0.5961876348378274, 'reg_alpha': 4.713693205989049, 'reg_lambda': 8.587742295264135, 'gamma': 3.4200149207749817}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:01,832] Trial 89 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.10595635870967866, 'n_estimators': 241, 'subsample': 0.7751925820604251, 'colsample_bytree': 0.7681036707987141, 'reg_alpha': 3.840322173847248, 'reg_lambda': 7.45323307932135, 'gamma': 2.874559151456457}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,095] Trial 90 finished with value: 0.7164 and parameters: {'max_depth': 5, 'learning_rate': 0.21411087187879457, 'n_estimators': 308, 'subsample': 0.6318719336336833, 'colsample_bytree': 0.9220812704606259, 'reg_alpha': 7.472540457368082, 'reg_lambda': 2.2455518552204152, 'gamma': 1.9304132104942164}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,285] Trial 91 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.14863671608062262, 'n_estimators': 167, 'subsample': 0.5362915626937174, 'colsample_bytree': 0.9743159314655894, 'reg_alpha': 5.722663177946752, 'reg_lambda': 9.171772294164382, 'gamma': 2.715001952616812}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,476] Trial 92 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.14639965703911986, 'n_estimators': 157, 'subsample': 0.5365842172108394, 'colsample_bytree': 0.9701108033664274, 'reg_alpha': 5.661443754757117, 'reg_lambda': 8.878671554459563, 'gamma': 2.4872938658450012}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,639] Trial 93 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.14653971243334613, 'n_estimators': 119, 'subsample': 0.5725659630961001, 'colsample_bytree': 0.9676321839520892, 'reg_alpha': 5.5720119350129504, 'reg_lambda': 8.908543639527553, 'gamma': 2.7436542787837945}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,814] Trial 94 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.1343780756514521, 'n_estimators': 163, 'subsample': 0.5403107177898266, 'colsample_bytree': 0.9950649861577138, 'reg_alpha': 5.871110598238132, 'reg_lambda': 9.16142339487323, 'gamma': 2.5930127640340332}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:02,985] Trial 95 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.17095722149516376, 'n_estimators': 153, 'subsample': 0.5155658490988219, 'colsample_bytree': 0.9915720631162389, 'reg_alpha': 6.579080907265394, 'reg_lambda': 9.407994943739808, 'gamma': 2.3574599821282702}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:03,170] Trial 96 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.15939833044714707, 'n_estimators': 178, 'subsample': 0.5357685269967439, 'colsample_bytree': 0.980775386927092, 'reg_alpha': 6.038725320849829, 'reg_lambda': 9.10815773962817, 'gamma': 3.1304706767231534}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:03,360] Trial 97 finished with value: 0.7184 and parameters: {'max_depth': 7, 'learning_rate': 0.1334366805882924, 'n_estimators': 102, 'subsample': 0.5563850058518642, 'colsample_bytree': 0.9415185506724796, 'reg_alpha': 5.810757623907693, 'reg_lambda': 1.7249138638149086, 'gamma': 2.456924604695449}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:03,524] Trial 98 finished with value: 0.7136 and parameters: {'max_depth': 3, 'learning_rate': 0.15551320149029454, 'n_estimators': 128, 'subsample': 0.7945942506038304, 'colsample_bytree': 0.9979189852718741, 'reg_alpha': 6.8836892363370445, 'reg_lambda': 9.782987603856279, 'gamma': 2.1865493823773274}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:03,721] Trial 99 finished with value: 0.7212 and parameters: {'max_depth': 10, 'learning_rate': 0.13329424657800898, 'n_estimators': 170, 'subsample': 0.5262481477672191, 'colsample_bytree': 0.9645998607174326, 'reg_alpha': 6.453549225051644, 'reg_lambda': 3.4120022279227022, 'gamma': 3.731611588237516}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:03,892] Trial 100 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.18707369070996688, 'n_estimators': 143, 'subsample': 0.5679031700910875, 'colsample_bytree': 0.955823996465623, 'reg_alpha': 6.228543218698211, 'reg_lambda': 9.450168685761547, 'gamma': 2.961763064679266}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:04,131] Trial 101 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.14149510439425764, 'n_estimators': 182, 'subsample': 0.5467643886240112, 'colsample_bytree': 0.9308244880416424, 'reg_alpha': 5.2129563176982945, 'reg_lambda': 9.214828114220948, 'gamma': 2.5924287661250682}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:04,357] Trial 102 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.12596057312714348, 'n_estimators': 219, 'subsample': 0.5123180265127826, 'colsample_bytree': 0.9765911123658316, 'reg_alpha': 5.614705922910288, 'reg_lambda': 8.904457012297547, 'gamma': 2.7819034893448222}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:04,561] Trial 103 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.12455608655422193, 'n_estimators': 214, 'subsample': 0.5814935989078437, 'colsample_bytree': 0.9876701753703515, 'reg_alpha': 5.614936934436486, 'reg_lambda': 8.998709858849782, 'gamma': 2.7994925599845257}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:04,783] Trial 104 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.15419703690627423, 'n_estimators': 219, 'subsample': 0.5095858620198913, 'colsample_bytree': 0.9789797567877478, 'reg_alpha': 4.893165693801585, 'reg_lambda': 2.089423536358637, 'gamma': 2.410510604537026}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:04,975] Trial 105 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.26932171982308256, 'n_estimators': 191, 'subsample': 0.5236152032156617, 'colsample_bytree': 0.9580755079464396, 'reg_alpha': 5.7790754172382, 'reg_lambda': 9.974370091643783, 'gamma': 2.281230982251797}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:05,441] Trial 106 finished with value: 0.7188 and parameters: {'max_depth': 3, 'learning_rate': 0.23843891257450872, 'n_estimators': 494, 'subsample': 0.6101450156227916, 'colsample_bytree': 0.9982152104477735, 'reg_alpha': 7.193635116860306, 'reg_lambda': 8.74770044236297, 'gamma': 2.1193315990606587}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:05,629] Trial 107 finished with value: 0.718 and parameters: {'max_depth': 4, 'learning_rate': 0.14130595257202538, 'n_estimators': 153, 'subsample': 0.5327266049703626, 'colsample_bytree': 0.9451536192674793, 'reg_alpha': 5.927498273772191, 'reg_lambda': 2.5111382999756064, 'gamma': 4.660893039959704}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:06,113] Trial 108 finished with value: 0.7132 and parameters: {'max_depth': 7, 'learning_rate': 0.1119684479785422, 'n_estimators': 442, 'subsample': 0.5542966159699331, 'colsample_bytree': 0.7505336991702938, 'reg_alpha': 0.749277722474341, 'reg_lambda': 9.524905877840329, 'gamma': 2.859336247637784}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:06,426] Trial 109 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.13197166504033994, 'n_estimators': 266, 'subsample': 0.5020265378556997, 'colsample_bytree': 0.9710561445949628, 'reg_alpha': 5.000656260661128, 'reg_lambda': 6.04521070483416, 'gamma': 2.4952130251484523}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:06,701] Trial 110 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.08516506720023712, 'n_estimators': 289, 'subsample': 0.592158708336089, 'colsample_bytree': 0.669367661002233, 'reg_alpha': 4.502108298293265, 'reg_lambda': 8.157843079154688, 'gamma': 2.704604833572476}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:06,924] Trial 111 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.11963067288712272, 'n_estimators': 237, 'subsample': 0.5404087527667825, 'colsample_bytree': 0.915261029284162, 'reg_alpha': 5.237384402409814, 'reg_lambda': 8.550901705570269, 'gamma': 2.5505902970417322}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:07,110] Trial 112 finished with value: 0.7128 and parameters: {'max_depth': 3, 'learning_rate': 0.11707837632345043, 'n_estimators': 201, 'subsample': 0.5199851127435149, 'colsample_bytree': 0.700162588225432, 'reg_alpha': 5.461139522109666, 'reg_lambda': 8.80534321189888, 'gamma': 4.256579110724816}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:07,280] Trial 113 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.14476845105919223, 'n_estimators': 161, 'subsample': 0.5366203440695295, 'colsample_bytree': 0.9022543950541103, 'reg_alpha': 5.3083900937845545, 'reg_lambda': 3.9156471073887777, 'gamma': 2.647705411744255}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:07,820] Trial 114 finished with value: 0.7172 and parameters: {'max_depth': 3, 'learning_rate': 0.09854126003969102, 'n_estimators': 729, 'subsample': 0.7483678618042553, 'colsample_bytree': 0.9475139211906713, 'reg_alpha': 5.524926991004975, 'reg_lambda': 2.867797934870843, 'gamma': 2.2612816811497263}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:08,042] Trial 115 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.12399705014612881, 'n_estimators': 130, 'subsample': 0.5613041201642074, 'colsample_bytree': 0.9826913602006975, 'reg_alpha': 6.354791652898388, 'reg_lambda': 9.230054805976298, 'gamma': 2.359869196919311}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:08,509] Trial 116 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.14829854421440888, 'n_estimators': 572, 'subsample': 0.5088216306224035, 'colsample_bytree': 0.8718791893241451, 'reg_alpha': 5.089439896152232, 'reg_lambda': 9.006362822702172, 'gamma': 3.0471579336802503}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:08,737] Trial 117 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.10745838036499454, 'n_estimators': 213, 'subsample': 0.8047838825330909, 'colsample_bytree': 0.9669037371329922, 'reg_alpha': 4.7624389897161326, 'reg_lambda': 5.469377512538907, 'gamma': 1.5922298298901318}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:08,951] Trial 118 finished with value: 0.7188 and parameters: {'max_depth': 3, 'learning_rate': 0.1727743784146133, 'n_estimators': 226, 'subsample': 0.5502273352276837, 'colsample_bytree': 0.5389538781245319, 'reg_alpha': 5.914274410740932, 'reg_lambda': 8.454838416254644, 'gamma': 1.7945632041280268}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:09,274] Trial 119 finished with value: 0.7264 and parameters: {'max_depth': 3, 'learning_rate': 0.16495019240348002, 'n_estimators': 419, 'subsample': 0.5665050515052709, 'colsample_bytree': 0.7263833292597367, 'reg_alpha': 5.686304120641144, 'reg_lambda': 7.745068745313148, 'gamma': 2.5530240750858395}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:09,618] Trial 120 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.13781295671623892, 'n_estimators': 423, 'subsample': 0.6050321708010126, 'colsample_bytree': 0.7199432635215387, 'reg_alpha': 5.69432813049772, 'reg_lambda': 9.740971366154435, 'gamma': 2.0932704781797935}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:09,926] Trial 121 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.11514997308573378, 'n_estimators': 376, 'subsample': 0.5652020212715376, 'colsample_bytree': 0.7096923965183431, 'reg_alpha': 6.142696703593708, 'reg_lambda': 7.737764731163174, 'gamma': 2.561791382827302}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:10,238] Trial 122 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.16490738194644888, 'n_estimators': 407, 'subsample': 0.5794103836033786, 'colsample_bytree': 0.7341829420211008, 'reg_alpha': 5.3836698796468685, 'reg_lambda': 7.190378130842427, 'gamma': 2.8060494263128337}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:10,526] Trial 123 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.10118049419923394, 'n_estimators': 352, 'subsample': 0.5307936384399, 'colsample_bytree': 0.8016796817801848, 'reg_alpha': 8.095967390113842, 'reg_lambda': 8.286418739289854, 'gamma': 2.488680367994131}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:10,754] Trial 124 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.12881803751902082, 'n_estimators': 254, 'subsample': 0.5431522369346474, 'colsample_bytree': 0.6814160473703883, 'reg_alpha': 6.651448622552451, 'reg_lambda': 6.96023808014045, 'gamma': 2.218129629998787}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:11,052] Trial 125 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.17838202171221268, 'n_estimators': 395, 'subsample': 0.7304211210979347, 'colsample_bytree': 0.7450482282926364, 'reg_alpha': 5.0136909934878755, 'reg_lambda': 6.363605499719251, 'gamma': 2.9147347841284095}. Best is trial 14 with value: 0.7272.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:11,296] Trial 126 finished with value: 0.728 and parameters: {'max_depth': 4, 'learning_rate': 0.15580164529750914, 'n_estimators': 279, 'subsample': 0.5138522649059976, 'colsample_bytree': 0.5551619430767873, 'reg_alpha': 4.528237207901916, 'reg_lambda': 7.909554713876909, 'gamma': 2.7204146903895916}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:11,602] Trial 127 finished with value: 0.7252 and parameters: {'max_depth': 4, 'learning_rate': 0.1532853571679608, 'n_estimators': 335, 'subsample': 0.5180818212148957, 'colsample_bytree': 0.515551112689123, 'reg_alpha': 4.5526904486539985, 'reg_lambda': 7.918890547598144, 'gamma': 2.705458040346935}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:11,890] Trial 128 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.15843240910538509, 'n_estimators': 312, 'subsample': 0.5110939406618225, 'colsample_bytree': 0.547354214561805, 'reg_alpha': 4.283328074485612, 'reg_lambda': 8.715418656569422, 'gamma': 2.4037462330901436}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:12,237] Trial 129 finished with value: 0.7184 and parameters: {'max_depth': 4, 'learning_rate': 0.2950889586641902, 'n_estimators': 478, 'subsample': 0.5004825800826109, 'colsample_bytree': 0.5552568239023892, 'reg_alpha': 4.747146799892178, 'reg_lambda': 8.163117142166051, 'gamma': 3.16668025349923}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:12,460] Trial 130 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.16673440635904715, 'n_estimators': 284, 'subsample': 0.7648178196214868, 'colsample_bytree': 0.5762810017920549, 'reg_alpha': 3.972273203933333, 'reg_lambda': 2.9645446302257987, 'gamma': 4.04265408806333}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:12,646] Trial 131 finished with value: 0.726 and parameters: {'max_depth': 3, 'learning_rate': 0.13664524773858408, 'n_estimators': 183, 'subsample': 0.5260100990753034, 'colsample_bytree': 0.9757389999422581, 'reg_alpha': 5.606971089378125, 'reg_lambda': 7.505229232058947, 'gamma': 2.6152976009589715}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:12,852] Trial 132 finished with value: 0.7244 and parameters: {'max_depth': 7, 'learning_rate': 0.1356252605693685, 'n_estimators': 184, 'subsample': 0.525147086880906, 'colsample_bytree': 0.9761189514147005, 'reg_alpha': 5.54408098106515, 'reg_lambda': 9.294390683690674, 'gamma': 2.782799833818741}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:13,024] Trial 133 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.15023830501682922, 'n_estimators': 166, 'subsample': 0.5551674199432538, 'colsample_bytree': 0.5265369193396445, 'reg_alpha': 5.894746730891898, 'reg_lambda': 3.200795477649563, 'gamma': 2.66379418775232}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:13,163] Trial 134 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.25785954205147577, 'n_estimators': 111, 'subsample': 0.5343927076299305, 'colsample_bytree': 0.9870811333107488, 'reg_alpha': 5.691328866293012, 'reg_lambda': 9.054671133653137, 'gamma': 2.455963429138721}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:13,363] Trial 135 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.19721787971488888, 'n_estimators': 201, 'subsample': 0.5188481518570258, 'colsample_bytree': 0.9892350850195373, 'reg_alpha': 6.070692110448542, 'reg_lambda': 7.884121259119721, 'gamma': 2.6122261607819413}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:13,698] Trial 136 finished with value: 0.7152 and parameters: {'max_depth': 3, 'learning_rate': 0.14657639695643537, 'n_estimators': 369, 'subsample': 0.5727232996303007, 'colsample_bytree': 0.9605146070132422, 'reg_alpha': 0.06995237056709236, 'reg_lambda': 2.583675208255205, 'gamma': 2.328389979824611}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:14,240] Trial 137 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.025334785521935223, 'n_estimators': 626, 'subsample': 0.6929350352893191, 'colsample_bytree': 0.726290510506954, 'reg_alpha': 6.414751402569443, 'reg_lambda': 7.439304937893995, 'gamma': 1.9973300644534207}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:14,411] Trial 138 finished with value: 0.6908 and parameters: {'max_depth': 3, 'learning_rate': 0.013609331596813323, 'n_estimators': 141, 'subsample': 0.547018274282681, 'colsample_bytree': 0.9977015535078184, 'reg_alpha': 5.161452593982467, 'reg_lambda': 2.2333708175989466, 'gamma': 2.9498851399230026}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:14,611] Trial 139 finished with value: 0.7204 and parameters: {'max_depth': 4, 'learning_rate': 0.14148950740922084, 'n_estimators': 170, 'subsample': 0.5304235719372719, 'colsample_bytree': 0.6952126381285499, 'reg_alpha': 6.230272913052592, 'reg_lambda': 8.43822892988935, 'gamma': 2.1810466590607547}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:14,988] Trial 140 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.09013364980258491, 'n_estimators': 455, 'subsample': 0.7849927700753635, 'colsample_bytree': 0.7741808044076547, 'reg_alpha': 4.436216333023982, 'reg_lambda': 8.937596939684111, 'gamma': 1.8841512167960155}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:15,222] Trial 141 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.1279830652288516, 'n_estimators': 243, 'subsample': 0.5394664951444776, 'colsample_bytree': 0.7568388963448135, 'reg_alpha': 5.372752931999088, 'reg_lambda': 7.662444430965682, 'gamma': 2.5370787067711635}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:15,453] Trial 142 finished with value: 0.7188 and parameters: {'max_depth': 3, 'learning_rate': 0.12351920152995462, 'n_estimators': 230, 'subsample': 0.5631301334149369, 'colsample_bytree': 0.6304171749927492, 'reg_alpha': 4.892187466004058, 'reg_lambda': 7.423367589881531, 'gamma': 2.6253277276025195}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:15,727] Trial 143 finished with value: 0.7236 and parameters: {'max_depth': 8, 'learning_rate': 0.11147388258658336, 'n_estimators': 274, 'subsample': 0.5220006816620552, 'colsample_bytree': 0.5569838723440319, 'reg_alpha': 5.705787297469542, 'reg_lambda': 1.8138197057228749, 'gamma': 2.341390607209005}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:16,060] Trial 144 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.2204672640588824, 'n_estimators': 434, 'subsample': 0.5088546704299326, 'colsample_bytree': 0.8338985420902737, 'reg_alpha': 5.343032738393824, 'reg_lambda': 5.162256478848438, 'gamma': 2.7715176255289333}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:16,260] Trial 145 finished with value: 0.7192 and parameters: {'max_depth': 3, 'learning_rate': 0.15927276529713766, 'n_estimators': 205, 'subsample': 0.5452146320856198, 'colsample_bytree': 0.9745432899167905, 'reg_alpha': 4.656199919662944, 'reg_lambda': 8.116882877196986, 'gamma': 2.4877409614806925}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:16,497] Trial 146 finished with value: 0.7132 and parameters: {'max_depth': 3, 'learning_rate': 0.09519733211150673, 'n_estimators': 257, 'subsample': 0.8955003177211383, 'colsample_bytree': 0.5882159907773947, 'reg_alpha': 5.910394347465449, 'reg_lambda': 6.882975130355229, 'gamma': 2.561477476091932}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:16,934] Trial 147 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.10279797101939203, 'n_estimators': 596, 'subsample': 0.5556327392951098, 'colsample_bytree': 0.954593173204423, 'reg_alpha': 5.115431253570134, 'reg_lambda': 4.618936159341751, 'gamma': 2.8827823480129138}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:17,101] Trial 148 finished with value: 0.7172 and parameters: {'max_depth': 4, 'learning_rate': 0.1370702319742956, 'n_estimators': 149, 'subsample': 0.8327751996477926, 'colsample_bytree': 0.930568401252791, 'reg_alpha': 5.521840046083997, 'reg_lambda': 6.690622812012756, 'gamma': 2.413448100788789}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:17,558] Trial 149 finished with value: 0.7224 and parameters: {'max_depth': 7, 'learning_rate': 0.08061958125710392, 'n_estimators': 550, 'subsample': 0.5305543781718232, 'colsample_bytree': 0.5344209675025882, 'reg_alpha': 4.126226899572165, 'reg_lambda': 8.661713732674357, 'gamma': 2.286344064733484}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:18,230] Trial 150 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.12151431928633427, 'n_estimators': 920, 'subsample': 0.5148638268911722, 'colsample_bytree': 0.9812695689441296, 'reg_alpha': 4.936897326801594, 'reg_lambda': 5.88121430450589, 'gamma': 2.703604705060466}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:18,444] Trial 151 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.15486886062562433, 'n_estimators': 215, 'subsample': 0.5100624226540599, 'colsample_bytree': 0.9996977074301061, 'reg_alpha': 4.8071596120537095, 'reg_lambda': 1.4814015240730019, 'gamma': 2.410720520831683}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:18,640] Trial 152 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.1544702394273624, 'n_estimators': 186, 'subsample': 0.5000660962815408, 'colsample_bytree': 0.9747732329097102, 'reg_alpha': 5.295512054128164, 'reg_lambda': 9.477226227673857, 'gamma': 2.1204049885393674}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:18,861] Trial 153 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.14393468355487837, 'n_estimators': 231, 'subsample': 0.5395668402343355, 'colsample_bytree': 0.9663025317284375, 'reg_alpha': 5.732007594167994, 'reg_lambda': 2.14634010266344, 'gamma': 2.5597772770703617}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:19,057] Trial 154 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.1309462876682628, 'n_estimators': 192, 'subsample': 0.5271224226797858, 'colsample_bytree': 0.9535876787329204, 'reg_alpha': 4.579025743858811, 'reg_lambda': 1.9481555395103929, 'gamma': 2.448858966315342}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:19,272] Trial 155 finished with value: 0.714 and parameters: {'max_depth': 3, 'learning_rate': 0.06693185901987143, 'n_estimators': 218, 'subsample': 0.8591841076868741, 'colsample_bytree': 0.9854519916353117, 'reg_alpha': 5.482511723599732, 'reg_lambda': 7.317652385809373, 'gamma': 2.2410732819072}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:19,579] Trial 156 finished with value: 0.7144 and parameters: {'max_depth': 4, 'learning_rate': 0.14801824305118774, 'n_estimators': 320, 'subsample': 0.5107162563892264, 'colsample_bytree': 0.6609984810014071, 'reg_alpha': 5.110122186994961, 'reg_lambda': 2.369123726988088, 'gamma': 1.4443745174038485}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:20,117] Trial 157 finished with value: 0.7184 and parameters: {'max_depth': 3, 'learning_rate': 0.1081623851120886, 'n_estimators': 809, 'subsample': 0.5488542884238288, 'colsample_bytree': 0.7131531215673192, 'reg_alpha': 5.999076190547683, 'reg_lambda': 1.2055198207486943, 'gamma': 2.6765704770964693}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:20,284] Trial 158 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.17462396299347005, 'n_estimators': 167, 'subsample': 0.7202610914686324, 'colsample_bytree': 0.9423260756649834, 'reg_alpha': 4.9534147062827865, 'reg_lambda': 9.14972697118095, 'gamma': 3.004384104724914}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:20,607] Trial 159 finished with value: 0.7196 and parameters: {'max_depth': 4, 'learning_rate': 0.13729225956516705, 'n_estimators': 417, 'subsample': 0.5199888604144761, 'colsample_bytree': 0.7437794445280053, 'reg_alpha': 7.033535992163129, 'reg_lambda': 7.06395099341303, 'gamma': 2.8321001198912885}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:20,883] Trial 160 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.16467150101764483, 'n_estimators': 299, 'subsample': 0.5668764277565501, 'colsample_bytree': 0.977103075860424, 'reg_alpha': 5.2652010660329145, 'reg_lambda': 7.678401671489525, 'gamma': 2.354695727386229}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:21,134] Trial 161 finished with value: 0.7204 and parameters: {'max_depth': 4, 'learning_rate': 0.15734656426355526, 'n_estimators': 332, 'subsample': 0.9946814956584625, 'colsample_bytree': 0.502953100977574, 'reg_alpha': 4.482938239247127, 'reg_lambda': 7.9861552978945385, 'gamma': 2.6237548668501605}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:21,433] Trial 162 finished with value: 0.7152 and parameters: {'max_depth': 4, 'learning_rate': 0.15065622441044213, 'n_estimators': 354, 'subsample': 0.515144870376135, 'colsample_bytree': 0.5418786745569253, 'reg_alpha': 1.9770802650721797, 'reg_lambda': 7.823017205784126, 'gamma': 2.7636051380631343}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:21,702] Trial 163 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.15264665787112977, 'n_estimators': 337, 'subsample': 0.5320923690654552, 'colsample_bytree': 0.5121626582675789, 'reg_alpha': 4.68845884407718, 'reg_lambda': 8.339556290330512, 'gamma': 3.369878121567674}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:21,987] Trial 164 finished with value: 0.7216 and parameters: {'max_depth': 4, 'learning_rate': 0.2436548057372038, 'n_estimators': 373, 'subsample': 0.5362914561397715, 'colsample_bytree': 0.5126226999156847, 'reg_alpha': 4.805468130694125, 'reg_lambda': 8.331851293242552, 'gamma': 3.3782337894039625}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:22,277] Trial 165 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.18556364978095577, 'n_estimators': 392, 'subsample': 0.527083398008961, 'colsample_bytree': 0.5752546365937672, 'reg_alpha': 5.498492601887882, 'reg_lambda': 8.734333960655288, 'gamma': 3.9434705811853195}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:22,490] Trial 166 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.1168567277880781, 'n_estimators': 250, 'subsample': 0.8144922652261546, 'colsample_bytree': 0.5247645228062078, 'reg_alpha': 7.9066378202322944, 'reg_lambda': 8.52721111190717, 'gamma': 3.5444067077059724}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:22,754] Trial 167 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.14093352466191683, 'n_estimators': 278, 'subsample': 0.5543030086105801, 'colsample_bytree': 0.5570316044688314, 'reg_alpha': 4.293844261141234, 'reg_lambda': 1.647833969262971, 'gamma': 2.055370198792142}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:22,910] Trial 168 finished with value: 0.7276 and parameters: {'max_depth': 3, 'learning_rate': 0.1332984437082759, 'n_estimators': 127, 'subsample': 0.5393116391179313, 'colsample_bytree': 0.9909009631469518, 'reg_alpha': 5.835919032130415, 'reg_lambda': 8.881695637428136, 'gamma': 2.5144914317981324}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:23,079] Trial 169 finished with value: 0.7204 and parameters: {'max_depth': 4, 'learning_rate': 0.1296056214965155, 'n_estimators': 127, 'subsample': 0.5850183719747574, 'colsample_bytree': 0.5980951963785847, 'reg_alpha': 6.2321716603976185, 'reg_lambda': 8.845844117409865, 'gamma': 3.7068275148049556}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:23,437] Trial 170 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.1214851965401322, 'n_estimators': 507, 'subsample': 0.5403836217049237, 'colsample_bytree': 0.9905025736847242, 'reg_alpha': 5.7155600248568526, 'reg_lambda': 9.338411400903613, 'gamma': 4.284697920585719}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:23,637] Trial 171 finished with value: 0.7164 and parameters: {'max_depth': 3, 'learning_rate': 0.037495766304612425, 'n_estimators': 183, 'subsample': 0.5324257469165214, 'colsample_bytree': 0.9649107376619295, 'reg_alpha': 5.841535686471243, 'reg_lambda': 2.0567471901097285, 'gamma': 2.4926960825332007}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:23,806] Trial 172 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.1442563881366218, 'n_estimators': 145, 'subsample': 0.523680940151114, 'colsample_bytree': 0.9854119337362897, 'reg_alpha': 5.067914280894375, 'reg_lambda': 9.690456359413293, 'gamma': 2.5495741924151334}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:24,012] Trial 173 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.13555048908481293, 'n_estimators': 210, 'subsample': 0.6629943964864997, 'colsample_bytree': 0.9720658178145002, 'reg_alpha': 5.619946933168915, 'reg_lambda': 9.085284454060885, 'gamma': 2.3838060967539922}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:24,190] Trial 174 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.16880926181476297, 'n_estimators': 160, 'subsample': 0.5453671926868019, 'colsample_bytree': 0.9937246989943556, 'reg_alpha': 6.04156156707362, 'reg_lambda': 8.270798790994053, 'gamma': 2.2181265836481097}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:24,337] Trial 175 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.14943891379965923, 'n_estimators': 113, 'subsample': 0.5093178509928805, 'colsample_bytree': 0.6490005516298633, 'reg_alpha': 4.669050181025378, 'reg_lambda': 2.667769489200398, 'gamma': 2.675082764960185}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:24,614] Trial 176 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.12700149407259512, 'n_estimators': 343, 'subsample': 0.5614680013371699, 'colsample_bytree': 0.6152838236383179, 'reg_alpha': 5.225739719849909, 'reg_lambda': 7.5708834924753345, 'gamma': 2.4411867033563626}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:24,812] Trial 177 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.15765103262618332, 'n_estimators': 196, 'subsample': 0.5376289264676389, 'colsample_bytree': 0.9999091574720774, 'reg_alpha': 5.417474710447474, 'reg_lambda': 8.523791342441791, 'gamma': 2.876671271284961}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:25,142] Trial 178 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.09965538059808822, 'n_estimators': 389, 'subsample': 0.5001252354043559, 'colsample_bytree': 0.5638379003150094, 'reg_alpha': 3.635177554035349, 'reg_lambda': 8.818094439038912, 'gamma': 2.3019176830538823}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:25,362] Trial 179 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.13304907709626032, 'n_estimators': 221, 'subsample': 0.7405134671184275, 'colsample_bytree': 0.5480587170414288, 'reg_alpha': 6.745933027857864, 'reg_lambda': 8.12053429427481, 'gamma': 1.7484256517456431}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:25,938] Trial 180 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.11106391112448788, 'n_estimators': 856, 'subsample': 0.5516737536382444, 'colsample_bytree': 0.9804582036095708, 'reg_alpha': 4.880360220478479, 'reg_lambda': 9.285773301504104, 'gamma': 3.218212394773533}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:26,121] Trial 181 finished with value: 0.7264 and parameters: {'max_depth': 3, 'learning_rate': 0.1125630011340143, 'n_estimators': 176, 'subsample': 0.5517362651666383, 'colsample_bytree': 0.9798331314480809, 'reg_alpha': 4.943635853469115, 'reg_lambda': 9.212108176351615, 'gamma': 3.2243992481541968}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:26,621] Trial 182 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.11089347649840799, 'n_estimators': 740, 'subsample': 0.5516569200696759, 'colsample_bytree': 0.9802275401478787, 'reg_alpha': 4.973612203175738, 'reg_lambda': 9.457341501083452, 'gamma': 3.8090539648564756}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:27,148] Trial 183 finished with value: 0.7232 and parameters: {'max_depth': 7, 'learning_rate': 0.11422350558885451, 'n_estimators': 779, 'subsample': 0.5739753938852736, 'colsample_bytree': 0.9633959014554472, 'reg_alpha': 5.613582039736317, 'reg_lambda': 9.05118913412286, 'gamma': 3.274315368380608}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:27,808] Trial 184 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.09413447260585066, 'n_estimators': 980, 'subsample': 0.5650845837704884, 'colsample_bytree': 0.9895667460157971, 'reg_alpha': 7.428905740682128, 'reg_lambda': 9.27970937206032, 'gamma': 3.4483215792438973}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:28,384] Trial 185 finished with value: 0.7268 and parameters: {'max_depth': 3, 'learning_rate': 0.10832249693426899, 'n_estimators': 867, 'subsample': 0.542186605781536, 'colsample_bytree': 0.7892677599530479, 'reg_alpha': 5.853864940870135, 'reg_lambda': 9.82697887042663, 'gamma': 3.113722425445757}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:28,945] Trial 186 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.10722642493783914, 'n_estimators': 856, 'subsample': 0.5537881410138912, 'colsample_bytree': 0.7928314016070019, 'reg_alpha': 5.89038722092249, 'reg_lambda': 9.789768785367684, 'gamma': 3.181425355643019}. Best is trial 126 with value: 0.728.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:29,513] Trial 187 finished with value: 0.7296 and parameters: {'max_depth': 3, 'learning_rate': 0.10226065196480402, 'n_estimators': 852, 'subsample': 0.528658853235721, 'colsample_bytree': 0.9508675547237393, 'reg_alpha': 6.263570072985001, 'reg_lambda': 9.947507304451797, 'gamma': 3.3414975481072107}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:30,079] Trial 188 finished with value: 0.7272 and parameters: {'max_depth': 6, 'learning_rate': 0.08713270526460459, 'n_estimators': 841, 'subsample': 0.5277449648810842, 'colsample_bytree': 0.9501648820222794, 'reg_alpha': 6.490493796859992, 'reg_lambda': 9.920086807776674, 'gamma': 3.4379241131905554}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:30,667] Trial 189 finished with value: 0.7188 and parameters: {'max_depth': 6, 'learning_rate': 0.10296679430808804, 'n_estimators': 840, 'subsample': 0.7728968072681026, 'colsample_bytree': 0.9431465818524083, 'reg_alpha': 6.35563072112967, 'reg_lambda': 9.9693431547668, 'gamma': 3.2760908175973666}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:31,300] Trial 190 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.07466314858157051, 'n_estimators': 893, 'subsample': 0.5242907945430088, 'colsample_bytree': 0.9539143769853375, 'reg_alpha': 6.536587448366641, 'reg_lambda': 9.642043627130786, 'gamma': 3.116444871871152}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:31,916] Trial 191 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.08486076660419832, 'n_estimators': 902, 'subsample': 0.5342916846617325, 'colsample_bytree': 0.9799505629410916, 'reg_alpha': 5.993996430570036, 'reg_lambda': 9.616480608082457, 'gamma': 3.3550760292757182}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:32,513] Trial 192 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.08995849500334492, 'n_estimators': 869, 'subsample': 0.5462602805032966, 'colsample_bytree': 0.9718225331108344, 'reg_alpha': 6.12050058356683, 'reg_lambda': 9.783782411223166, 'gamma': 3.604645587079108}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:33,083] Trial 193 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.10068691734347135, 'n_estimators': 841, 'subsample': 0.7038397014119776, 'colsample_bytree': 0.9632538210684553, 'reg_alpha': 6.355652319916549, 'reg_lambda': 9.441161132160664, 'gamma': 3.4708441310357383}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:33,669] Trial 194 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.09503157170960973, 'n_estimators': 864, 'subsample': 0.5280430840682572, 'colsample_bytree': 0.9349211524517541, 'reg_alpha': 5.823574387186101, 'reg_lambda': 9.975914352490163, 'gamma': 3.278465333924873}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:34,239] Trial 195 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.08314085923893251, 'n_estimators': 825, 'subsample': 0.5192890824589507, 'colsample_bytree': 0.9560838464444865, 'reg_alpha': 6.158905483627308, 'reg_lambda': 9.360275684582101, 'gamma': 3.01613416568012}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:34,792] Trial 196 finished with value: 0.7192 and parameters: {'max_depth': 3, 'learning_rate': 0.10538153154856775, 'n_estimators': 883, 'subsample': 0.8727596032574413, 'colsample_bytree': 0.9718517158529053, 'reg_alpha': 5.791861328480637, 'reg_lambda': 9.187279218989504, 'gamma': 3.1854593107954368}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:35,328] Trial 197 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.09557948279230359, 'n_estimators': 794, 'subsample': 0.5379848215739339, 'colsample_bytree': 0.985821332566364, 'reg_alpha': 5.567809465727508, 'reg_lambda': 9.594677072468581, 'gamma': 3.4162999756196766}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:35,508] Trial 198 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.08816783512214524, 'n_estimators': 158, 'subsample': 0.5190501014760871, 'colsample_bytree': 0.9499088404211696, 'reg_alpha': 6.295985180664163, 'reg_lambda': 9.856657946688767, 'gamma': 3.0765544450270945}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:35,680] Trial 199 finished with value: 0.7264 and parameters: {'max_depth': 4, 'learning_rate': 0.11314572275417957, 'n_estimators': 133, 'subsample': 0.5484060316492222, 'colsample_bytree': 0.9999048030916751, 'reg_alpha': 6.490357133992185, 'reg_lambda': 8.904921502521045, 'gamma': 3.366395434013614}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:35,834] Trial 200 finished with value: 0.7156 and parameters: {'max_depth': 3, 'learning_rate': 0.11304514794413412, 'n_estimators': 114, 'subsample': 0.5578510878637232, 'colsample_bytree': 0.9924374747437965, 'reg_alpha': 6.6627551937101845, 'reg_lambda': 8.956975646967445, 'gamma': 3.5287823926420616}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:36,419] Trial 201 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.10937474759796952, 'n_estimators': 851, 'subsample': 0.5486786635994212, 'colsample_bytree': 0.9981768444287388, 'reg_alpha': 6.910599295789734, 'reg_lambda': 9.293529740005956, 'gamma': 3.32651632484776}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:37,019] Trial 202 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.12161349468738104, 'n_estimators': 917, 'subsample': 0.5311020805944213, 'colsample_bytree': 0.98470219323204, 'reg_alpha': 6.191612619121581, 'reg_lambda': 8.912873136524471, 'gamma': 3.6382201470729485}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:37,182] Trial 203 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.10180581947930951, 'n_estimators': 133, 'subsample': 0.5412222404233826, 'colsample_bytree': 0.5337774704760361, 'reg_alpha': 5.8459724617827025, 'reg_lambda': 9.180540603127596, 'gamma': 3.219798090463939}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:37,359] Trial 204 finished with value: 0.7188 and parameters: {'max_depth': 4, 'learning_rate': 0.11660704244307703, 'n_estimators': 148, 'subsample': 0.5306764038230898, 'colsample_bytree': 0.9771286445543877, 'reg_alpha': 6.014287880189595, 'reg_lambda': 8.71457206983376, 'gamma': 3.349834621280559}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:37,900] Trial 205 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.10366578509478637, 'n_estimators': 823, 'subsample': 0.6817558208976146, 'colsample_bytree': 0.63427952355713, 'reg_alpha': 6.5996484625366705, 'reg_lambda': 9.624542411865566, 'gamma': 3.142073752675473}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:38,092] Trial 206 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.1251343361676986, 'n_estimators': 173, 'subsample': 0.5138629276567661, 'colsample_bytree': 0.9639701653135136, 'reg_alpha': 6.47877507364604, 'reg_lambda': 9.999249532161437, 'gamma': 3.493266618498661}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:38,299] Trial 207 finished with value: 0.722 and parameters: {'max_depth': 7, 'learning_rate': 0.14135896445799429, 'n_estimators': 181, 'subsample': 0.5409313620948302, 'colsample_bytree': 0.9871041342204618, 'reg_alpha': 5.198844706374026, 'reg_lambda': 9.408436223404983, 'gamma': 2.9496694749987116}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:38,455] Trial 208 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.27391125827985624, 'n_estimators': 130, 'subsample': 0.559675413291748, 'colsample_bytree': 0.9759960873813722, 'reg_alpha': 5.4606581114900825, 'reg_lambda': 9.068475005614177, 'gamma': 3.382094731530151}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:38,776] Trial 209 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.09706896189488196, 'n_estimators': 364, 'subsample': 0.7549684405083364, 'colsample_bytree': 0.5799951186387814, 'reg_alpha': 5.669792203891258, 'reg_lambda': 8.597621222160106, 'gamma': 2.8030890674235724}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:39,104] Trial 210 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.11070644059922283, 'n_estimators': 413, 'subsample': 0.5261873004270554, 'colsample_bytree': 0.6895996113823589, 'reg_alpha': 4.819816451444599, 'reg_lambda': 8.871529391724263, 'gamma': 3.252831293628278}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:39,682] Trial 211 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.0958820699826993, 'n_estimators': 850, 'subsample': 0.5261883793588055, 'colsample_bytree': 0.9647818456309714, 'reg_alpha': 5.9526925178584955, 'reg_lambda': 9.989563993472576, 'gamma': 3.2531103094491693}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:40,270] Trial 212 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.09129836753968269, 'n_estimators': 874, 'subsample': 0.5485349044378366, 'colsample_bytree': 0.9998571516323173, 'reg_alpha': 5.693741859778769, 'reg_lambda': 9.8145756523962, 'gamma': 3.072840503487238}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:40,866] Trial 213 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.08797540624777102, 'n_estimators': 875, 'subsample': 0.5471148882111101, 'colsample_bytree': 0.9990699922853683, 'reg_alpha': 5.355480725211662, 'reg_lambda': 9.738614046142462, 'gamma': 3.0277881520161416}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:41,524] Trial 214 finished with value: 0.7204 and parameters: {'max_depth': 8, 'learning_rate': 0.08384041971517565, 'n_estimators': 910, 'subsample': 0.5554750108108353, 'colsample_bytree': 0.9810405335507698, 'reg_alpha': 5.753568310979789, 'reg_lambda': 9.61032418165926, 'gamma': 2.7216358628526667}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:41,709] Trial 215 finished with value: 0.7232 and parameters: {'max_depth': 3, 'learning_rate': 0.11836852671500216, 'n_estimators': 164, 'subsample': 0.6444465742071499, 'colsample_bytree': 0.9963997046294845, 'reg_alpha': 6.049346717177109, 'reg_lambda': 9.416972372046533, 'gamma': 2.5961221947471187}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:42,325] Trial 216 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.07985981796657016, 'n_estimators': 878, 'subsample': 0.569725458570544, 'colsample_bytree': 0.9911943244478523, 'reg_alpha': 5.616618975181889, 'reg_lambda': 9.18558076638137, 'gamma': 3.096982780810613}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:42,484] Trial 217 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.147189321971816, 'n_estimators': 143, 'subsample': 0.5418539250585838, 'colsample_bytree': 0.5199813954791961, 'reg_alpha': 5.102111089547681, 'reg_lambda': 9.80209381604013, 'gamma': 3.426175207419601}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:43,136] Trial 218 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.09037128807556892, 'n_estimators': 935, 'subsample': 0.5119006879523835, 'colsample_bytree': 0.5445394969450132, 'reg_alpha': 6.2529462887612555, 'reg_lambda': 8.384825877915137, 'gamma': 2.911002141465876}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:43,348] Trial 219 finished with value: 0.7192 and parameters: {'max_depth': 3, 'learning_rate': 0.09148892769541606, 'n_estimators': 192, 'subsample': 0.511125967855055, 'colsample_bytree': 0.5536130641780495, 'reg_alpha': 6.412004183545065, 'reg_lambda': 9.55039392611168, 'gamma': 2.881094973185474}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:44,036] Trial 220 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.07553672831323555, 'n_estimators': 978, 'subsample': 0.5143813205183503, 'colsample_bytree': 0.5673210495479007, 'reg_alpha': 6.214611348350491, 'reg_lambda': 8.758299850302507, 'gamma': 2.939323319755628}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:44,680] Trial 221 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.10586890051701463, 'n_estimators': 970, 'subsample': 0.535357878711672, 'colsample_bytree': 0.5426689342271837, 'reg_alpha': 6.776628928849294, 'reg_lambda': 8.411210609176141, 'gamma': 2.781216303144002}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:45,323] Trial 222 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.09175822545398571, 'n_estimators': 934, 'subsample': 0.5218974523919745, 'colsample_bytree': 0.53009893098413, 'reg_alpha': 6.007186306297028, 'reg_lambda': 0.4366826222930076, 'gamma': 3.032512134692177}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:45,747] Trial 223 finished with value: 0.722 and parameters: {'max_depth': 4, 'learning_rate': 0.09833750152315063, 'n_estimators': 528, 'subsample': 0.5051043158227735, 'colsample_bytree': 0.5483316385356177, 'reg_alpha': 5.74728446336621, 'reg_lambda': 4.179421712426346, 'gamma': 2.6694067920266686}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:46,458] Trial 224 finished with value: 0.7176 and parameters: {'max_depth': 4, 'learning_rate': 0.1322114772529658, 'n_estimators': 948, 'subsample': 0.5477166643307165, 'colsample_bytree': 0.9708782961124114, 'reg_alpha': 5.425776720897772, 'reg_lambda': 8.278286791532453, 'gamma': 2.5151342283752083}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:46,608] Trial 225 finished with value: 0.7272 and parameters: {'max_depth': 4, 'learning_rate': 0.1531208111230099, 'n_estimators': 103, 'subsample': 0.5340545274544001, 'colsample_bytree': 0.9877160305120416, 'reg_alpha': 4.649533281612421, 'reg_lambda': 8.952259571451346, 'gamma': 3.158798365642573}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:46,821] Trial 226 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.16212263363606538, 'n_estimators': 102, 'subsample': 0.5354378674738243, 'colsample_bytree': 0.9863274503786996, 'reg_alpha': 6.1617681629421455, 'reg_lambda': 9.001699172091618, 'gamma': 3.1751222445438714}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:47,003] Trial 227 finished with value: 0.722 and parameters: {'max_depth': 4, 'learning_rate': 0.13828219924900914, 'n_estimators': 121, 'subsample': 0.5185121496245283, 'colsample_bytree': 0.999565729131623, 'reg_alpha': 5.891302332742985, 'reg_lambda': 9.205407151415683, 'gamma': 3.064053081675796}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:47,718] Trial 228 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.08699392288890853, 'n_estimators': 890, 'subsample': 0.5518896942501221, 'colsample_bytree': 0.9772034571467906, 'reg_alpha': 6.393258707429957, 'reg_lambda': 8.655935416795316, 'gamma': 2.6220297857722565}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:47,896] Trial 229 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.10843719527123563, 'n_estimators': 150, 'subsample': 0.5226443259845722, 'colsample_bytree': 0.6735007637588428, 'reg_alpha': 5.589179825353221, 'reg_lambda': 9.437462766020289, 'gamma': 2.844784350336764}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:48,099] Trial 230 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.10297261178286016, 'n_estimators': 128, 'subsample': 0.5650821245793932, 'colsample_bytree': 0.9847747846269937, 'reg_alpha': 4.569389342907068, 'reg_lambda': 9.01431783368223, 'gamma': 2.941621591460607}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:48,283] Trial 231 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.1014779748665472, 'n_estimators': 134, 'subsample': 0.5655035495785736, 'colsample_bytree': 0.9904536919500946, 'reg_alpha': 4.480938174937467, 'reg_lambda': 8.944474641050412, 'gamma': 2.924452778468759}. Best is trial 187 with value: 0.7296.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:48,475] Trial 232 finished with value: 0.73 and parameters: {'max_depth': 6, 'learning_rate': 0.11227754462348503, 'n_estimators': 116, 'subsample': 0.5453837519895274, 'colsample_bytree': 0.9814040401176601, 'reg_alpha': 4.738932269766239, 'reg_lambda': 9.025288116908948, 'gamma': 2.7503684466897362}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:48,646] Trial 233 finished with value: 0.7192 and parameters: {'max_depth': 7, 'learning_rate': 0.10434258970726364, 'n_estimators': 103, 'subsample': 0.5491252846182784, 'colsample_bytree': 0.9845951248932512, 'reg_alpha': 4.741223302009684, 'reg_lambda': 9.171037908395345, 'gamma': 3.103903522580355}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:48,853] Trial 234 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.0975102192229627, 'n_estimators': 118, 'subsample': 0.5756277620181597, 'colsample_bytree': 0.9678116711082455, 'reg_alpha': 4.402645490091665, 'reg_lambda': 9.740969026969763, 'gamma': 2.716262436064352}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,040] Trial 235 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11258544408990966, 'n_estimators': 133, 'subsample': 0.5595222562021968, 'colsample_bytree': 0.9835665798257448, 'reg_alpha': 4.953266474562209, 'reg_lambda': 9.308524763405483, 'gamma': 2.533336870325229}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,213] Trial 236 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.0923736666927025, 'n_estimators': 120, 'subsample': 0.5434670411802154, 'colsample_bytree': 0.9922869578907231, 'reg_alpha': 4.07874545851811, 'reg_lambda': 9.020986078681368, 'gamma': 3.1972429291451663}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,424] Trial 237 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.10590517523542368, 'n_estimators': 160, 'subsample': 0.5343605950900658, 'colsample_bytree': 0.9996172417701028, 'reg_alpha': 4.579704976394962, 'reg_lambda': 8.713401839136258, 'gamma': 2.6104735258632026}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,611] Trial 238 finished with value: 0.7172 and parameters: {'max_depth': 6, 'learning_rate': 0.08033453232201251, 'n_estimators': 102, 'subsample': 0.6150783763703566, 'colsample_bytree': 0.9782756861626374, 'reg_alpha': 4.798141973492485, 'reg_lambda': 9.575552584246411, 'gamma': 1.2428295880255686}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,797] Trial 239 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.11204447369710048, 'n_estimators': 150, 'subsample': 0.594306192885529, 'colsample_bytree': 0.9578473730802903, 'reg_alpha': 4.277094280542819, 'reg_lambda': 7.809810104324836, 'gamma': 2.9646037316546816}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:49,979] Trial 240 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.289766606290057, 'n_estimators': 174, 'subsample': 0.5587454351238924, 'colsample_bytree': 0.5597196678636259, 'reg_alpha': 4.978601009304928, 'reg_lambda': 8.524122287893354, 'gamma': 2.7510589771733893}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:50,462] Trial 241 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.11638951122698234, 'n_estimators': 662, 'subsample': 0.5378306987802368, 'colsample_bytree': 0.9727433334501219, 'reg_alpha': 5.235744665678923, 'reg_lambda': 8.902083507638379, 'gamma': 2.834004187348559}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:51,100] Trial 242 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.12664164352989035, 'n_estimators': 864, 'subsample': 0.5288729558957137, 'colsample_bytree': 0.8141613663000982, 'reg_alpha': 4.667959588656069, 'reg_lambda': 9.10439465191751, 'gamma': 2.4738953475051066}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:51,284] Trial 243 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.1464038980005778, 'n_estimators': 133, 'subsample': 0.7967430182029047, 'colsample_bytree': 0.9864963099434385, 'reg_alpha': 5.843188222547924, 'reg_lambda': 8.81483183824519, 'gamma': 2.717531958196474}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:51,529] Trial 244 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.10006358620978117, 'n_estimators': 178, 'subsample': 0.5461768786812717, 'colsample_bytree': 0.9732373781217565, 'reg_alpha': 6.130165755552199, 'reg_lambda': 9.312091092403522, 'gamma': 2.9808517578307767}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:51,762] Trial 245 finished with value: 0.72 and parameters: {'max_depth': 7, 'learning_rate': 0.12264766657041368, 'n_estimators': 200, 'subsample': 0.5087654975832365, 'colsample_bytree': 0.9824505038964255, 'reg_alpha': 7.239701634926856, 'reg_lambda': 9.820882801944437, 'gamma': 2.5770374587332565}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:52,350] Trial 246 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.1523453515964013, 'n_estimators': 842, 'subsample': 0.5214366176829451, 'colsample_bytree': 0.9609627573505592, 'reg_alpha': 5.329317138269463, 'reg_lambda': 9.041675603084459, 'gamma': 2.8147521670220543}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:52,548] Trial 247 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.10882020589985626, 'n_estimators': 146, 'subsample': 0.5515773388638829, 'colsample_bytree': 0.9916703138770119, 'reg_alpha': 5.593015412415901, 'reg_lambda': 8.070577666756478, 'gamma': 3.3282957248277834}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:52,713] Trial 248 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.0900207317962115, 'n_estimators': 117, 'subsample': 0.537130949359177, 'colsample_bytree': 0.9994449164702368, 'reg_alpha': 5.1424006935128075, 'reg_lambda': 8.817098550423433, 'gamma': 3.1171559915269587}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:53,035] Trial 249 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.11801006747437202, 'n_estimators': 383, 'subsample': 0.5666194725065351, 'colsample_bytree': 0.970294734037734, 'reg_alpha': 4.554865921177844, 'reg_lambda': 9.420333104729751, 'gamma': 2.6375276885850694}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:53,255] Trial 250 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.14308830292828673, 'n_estimators': 167, 'subsample': 0.5268528674587607, 'colsample_bytree': 0.9782657246407955, 'reg_alpha': 4.911898244386172, 'reg_lambda': 4.899511757289681, 'gamma': 0.6409682475596097}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:53,836] Trial 251 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.13460134501710752, 'n_estimators': 805, 'subsample': 0.542690990433759, 'colsample_bytree': 0.9888853833518022, 'reg_alpha': 5.9123102850171625, 'reg_lambda': 9.190354833581946, 'gamma': 3.2062967585063955}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:54,413] Trial 252 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.09651753640579573, 'n_estimators': 824, 'subsample': 0.8462062821100206, 'colsample_bytree': 0.5414768516024447, 'reg_alpha': 5.6547553725617465, 'reg_lambda': 8.629476432359152, 'gamma': 2.4000288794202755}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:54,585] Trial 253 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.10351181427151003, 'n_estimators': 136, 'subsample': 0.5149073924131958, 'colsample_bytree': 0.8670805864554246, 'reg_alpha': 6.289099937239724, 'reg_lambda': 9.532860676993526, 'gamma': 2.908522991717953}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:54,805] Trial 254 finished with value: 0.7264 and parameters: {'max_depth': 4, 'learning_rate': 0.15633745126924423, 'n_estimators': 187, 'subsample': 0.5538401863262924, 'colsample_bytree': 0.964302814425716, 'reg_alpha': 6.529455317425879, 'reg_lambda': 8.964886618072127, 'gamma': 2.6968096988165864}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:55,055] Trial 255 finished with value: 0.712 and parameters: {'max_depth': 4, 'learning_rate': 0.15840487978473847, 'n_estimators': 190, 'subsample': 0.5548008447474183, 'colsample_bytree': 0.9505323311701896, 'reg_alpha': 6.953822771000074, 'reg_lambda': 9.83443598230478, 'gamma': 0.02593078537868765}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:55,471] Trial 256 finished with value: 0.7196 and parameters: {'max_depth': 4, 'learning_rate': 0.16144779670312837, 'n_estimators': 467, 'subsample': 0.5748014951877682, 'colsample_bytree': 0.9563920458174261, 'reg_alpha': 6.443868792579268, 'reg_lambda': 9.060948458365175, 'gamma': 1.9233545543052746}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:55,687] Trial 257 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.15062302296919874, 'n_estimators': 153, 'subsample': 0.5614460517664273, 'colsample_bytree': 0.9633033742143744, 'reg_alpha': 6.613126469678659, 'reg_lambda': 9.298681442567144, 'gamma': 1.6202608607972884}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:56,060] Trial 258 finished with value: 0.7196 and parameters: {'max_depth': 4, 'learning_rate': 0.15438783954331356, 'n_estimators': 402, 'subsample': 0.5843014579135166, 'colsample_bytree': 0.9386814152027733, 'reg_alpha': 6.107084624782974, 'reg_lambda': 8.886355766722001, 'gamma': 2.4751360811159224}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:56,228] Trial 259 finished with value: 0.718 and parameters: {'max_depth': 4, 'learning_rate': 0.08586179842354594, 'n_estimators': 100, 'subsample': 0.5428941193343151, 'colsample_bytree': 0.5672948942014535, 'reg_alpha': 6.473708480522652, 'reg_lambda': 5.712910094833234, 'gamma': 2.675438175497039}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:56,457] Trial 260 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.16881180609080434, 'n_estimators': 171, 'subsample': 0.5315561820989982, 'colsample_bytree': 0.982659768664232, 'reg_alpha': 6.748665622171119, 'reg_lambda': 8.451587674922878, 'gamma': 3.2802148346275235}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:56,861] Trial 261 finished with value: 0.7236 and parameters: {'max_depth': 7, 'learning_rate': 0.09484901284916415, 'n_estimators': 433, 'subsample': 0.5527824143682356, 'colsample_bytree': 0.991368184703312, 'reg_alpha': 6.288547701927413, 'reg_lambda': 9.622467066384372, 'gamma': 2.3290777844797956}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:57,474] Trial 262 finished with value: 0.7192 and parameters: {'max_depth': 4, 'learning_rate': 0.14479117664485405, 'n_estimators': 895, 'subsample': 0.9316163164603445, 'colsample_bytree': 0.9740287208321573, 'reg_alpha': 7.486805046590372, 'reg_lambda': 9.227678625450718, 'gamma': 2.54922393270864}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:57,641] Trial 263 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.20874346880312344, 'n_estimators': 124, 'subsample': 0.6337789379326572, 'colsample_bytree': 0.5498506060672046, 'reg_alpha': 4.740946517819191, 'reg_lambda': 7.942183874274199, 'gamma': 3.028321684413741}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:58,287] Trial 264 finished with value: 0.7204 and parameters: {'max_depth': 10, 'learning_rate': 0.10029129161246308, 'n_estimators': 942, 'subsample': 0.7279748281771222, 'colsample_bytree': 0.9666132204624918, 'reg_alpha': 4.383479964493793, 'reg_lambda': 9.96681448515299, 'gamma': 2.7496256817259215}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:58,829] Trial 265 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.23511345082266422, 'n_estimators': 858, 'subsample': 0.5400446233159926, 'colsample_bytree': 0.6596431712093314, 'reg_alpha': 5.973692900659919, 'reg_lambda': 9.466884663209303, 'gamma': 3.5467673545393428}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:59,529] Trial 266 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.10814369598500558, 'n_estimators': 996, 'subsample': 0.5596807601923325, 'colsample_bytree': 0.7753905685854308, 'reg_alpha': 5.12951612285447, 'reg_lambda': 8.719652555735673, 'gamma': 2.179684015102704}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:59,726] Trial 267 finished with value: 0.7288 and parameters: {'max_depth': 3, 'learning_rate': 0.1616184396932056, 'n_estimators': 159, 'subsample': 0.5491407979282702, 'colsample_bytree': 0.9275414650734762, 'reg_alpha': 5.420987642037453, 'reg_lambda': 9.01093419913269, 'gamma': 2.6321562014486135}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:49:59,912] Trial 268 finished with value: 0.7172 and parameters: {'max_depth': 9, 'learning_rate': 0.24844532301403863, 'n_estimators': 156, 'subsample': 0.7148836856870079, 'colsample_bytree': 0.945101185463825, 'reg_alpha': 5.396288092501356, 'reg_lambda': 9.059867116394667, 'gamma': 2.6334230659295614}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:49:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:00,096] Trial 269 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.1658134979546285, 'n_estimators': 135, 'subsample': 0.549571603019614, 'colsample_bytree': 0.9266683748907333, 'reg_alpha': 4.951270273116705, 'reg_lambda': 8.93023687372191, 'gamma': 2.480567556939673}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:00,320] Trial 270 finished with value: 0.7276 and parameters: {'max_depth': 3, 'learning_rate': 0.15907192883027924, 'n_estimators': 177, 'subsample': 0.5687342582766672, 'colsample_bytree': 0.9169207906311139, 'reg_alpha': 5.719525838979714, 'reg_lambda': 9.29930205253147, 'gamma': 2.8742034075283542}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:00,513] Trial 271 finished with value: 0.7268 and parameters: {'max_depth': 3, 'learning_rate': 0.1605254121243663, 'n_estimators': 176, 'subsample': 0.572678618785702, 'colsample_bytree': 0.9100410702741116, 'reg_alpha': 5.783775871580332, 'reg_lambda': 9.348614117502152, 'gamma': 2.893114588671837}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:00,696] Trial 272 finished with value: 0.722 and parameters: {'max_depth': 3, 'learning_rate': 0.16245203569820482, 'n_estimators': 169, 'subsample': 0.5784627829257635, 'colsample_bytree': 0.8901236145999332, 'reg_alpha': 5.798056281890575, 'reg_lambda': 9.24411799313524, 'gamma': 2.8421620204318767}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:00,871] Trial 273 finished with value: 0.7208 and parameters: {'max_depth': 3, 'learning_rate': 0.17292284732688337, 'n_estimators': 153, 'subsample': 0.5638296636163268, 'colsample_bytree': 0.9225765686583075, 'reg_alpha': 6.047736001200702, 'reg_lambda': 9.411185059393938, 'gamma': 2.920399066595828}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:01,031] Trial 274 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.1590116811004976, 'n_estimators': 119, 'subsample': 0.5686595926041346, 'colsample_bytree': 0.9124531698461332, 'reg_alpha': 5.795914603225416, 'reg_lambda': 9.748469620973193, 'gamma': 3.0619292748986062}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:01,231] Trial 275 finished with value: 0.7188 and parameters: {'max_depth': 3, 'learning_rate': 0.16767389059739937, 'n_estimators': 183, 'subsample': 0.7652372313011788, 'colsample_bytree': 0.9030041681916517, 'reg_alpha': 6.2381660728834625, 'reg_lambda': 9.570188183940603, 'gamma': 3.1462504639139475}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:01,407] Trial 276 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.1769591177674384, 'n_estimators': 136, 'subsample': 0.5917171300727015, 'colsample_bytree': 0.9313426709907787, 'reg_alpha': 5.46375971863559, 'reg_lambda': 9.126896136921243, 'gamma': 2.92795996537768}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:02,018] Trial 277 finished with value: 0.7264 and parameters: {'max_depth': 3, 'learning_rate': 0.15698103077965872, 'n_estimators': 879, 'subsample': 0.5787619736127712, 'colsample_bytree': 0.9388872234841277, 'reg_alpha': 5.980676548338783, 'reg_lambda': 9.310008745196319, 'gamma': 3.0171448121295414}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:02,220] Trial 278 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.16317762960912774, 'n_estimators': 199, 'subsample': 0.7469490182744817, 'colsample_bytree': 0.9170886009852445, 'reg_alpha': 6.539425011292928, 'reg_lambda': 8.827936092145109, 'gamma': 2.7620095356328735}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:02,411] Trial 279 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.15027493786328125, 'n_estimators': 162, 'subsample': 0.5698077591605881, 'colsample_bytree': 0.9142473824190058, 'reg_alpha': 5.792475009309596, 'reg_lambda': 9.04328019134718, 'gamma': 2.8625275582079936}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:02,607] Trial 280 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.15735020229591207, 'n_estimators': 149, 'subsample': 0.556889712144802, 'colsample_bytree': 0.8533709053030996, 'reg_alpha': 6.243132668010386, 'reg_lambda': 8.61405168735351, 'gamma': 3.2479649833705646}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:03,064] Trial 281 finished with value: 0.7264 and parameters: {'max_depth': 3, 'learning_rate': 0.15393184033806392, 'n_estimators': 589, 'subsample': 0.6007184943230395, 'colsample_bytree': 0.9524703030512262, 'reg_alpha': 5.5442171413158485, 'reg_lambda': 9.672930447419143, 'gamma': 3.359465247933026}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:03,680] Trial 282 finished with value: 0.7196 and parameters: {'max_depth': 3, 'learning_rate': 0.16266659730129399, 'n_estimators': 841, 'subsample': 0.5499418715355693, 'colsample_bytree': 0.5355168484050852, 'reg_alpha': 5.236859378682047, 'reg_lambda': 9.425844818476744, 'gamma': 3.0953771712700306}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:04,085] Trial 283 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.1726594210167317, 'n_estimators': 487, 'subsample': 0.5705278287979733, 'colsample_bytree': 0.9456669051233587, 'reg_alpha': 5.685259484955521, 'reg_lambda': 9.179153630900935, 'gamma': 2.734374458914046}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:04,267] Trial 284 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.1511105815084946, 'n_estimators': 114, 'subsample': 0.5604215773134809, 'colsample_bytree': 0.9312009057734623, 'reg_alpha': 6.027643609979406, 'reg_lambda': 8.905091581500438, 'gamma': 2.971668350299119}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:04,507] Trial 285 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.16691666834994884, 'n_estimators': 177, 'subsample': 0.544825514948569, 'colsample_bytree': 0.9614967878922094, 'reg_alpha': 6.406055340601449, 'reg_lambda': 9.995210179777786, 'gamma': 2.011425569726926}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:05,191] Trial 286 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.15946894682096052, 'n_estimators': 962, 'subsample': 0.6553003356819093, 'colsample_bytree': 0.8278826421863288, 'reg_alpha': 4.615357030238863, 'reg_lambda': 8.511541269010575, 'gamma': 2.847693104912079}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:05,850] Trial 287 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.11462381029734282, 'n_estimators': 917, 'subsample': 0.5372088962950011, 'colsample_bytree': 0.5500189046202089, 'reg_alpha': 5.344627319173593, 'reg_lambda': 9.521602815406348, 'gamma': 3.4578931094709886}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:06,081] Trial 288 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.10542932174849239, 'n_estimators': 137, 'subsample': 0.5507623625334958, 'colsample_bytree': 0.9012826032090482, 'reg_alpha': 6.819079072799858, 'reg_lambda': 9.289079187951847, 'gamma': 3.195500942752605}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:06,263] Trial 289 finished with value: 0.7164 and parameters: {'max_depth': 4, 'learning_rate': 0.14691200697313583, 'n_estimators': 101, 'subsample': 0.5854198442168456, 'colsample_bytree': 0.5570943771868005, 'reg_alpha': 4.195622043432627, 'reg_lambda': 8.768650666679378, 'gamma': 2.0858777733310965}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:06,486] Trial 290 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.15781579260158177, 'n_estimators': 205, 'subsample': 0.5635289711334699, 'colsample_bytree': 0.9914118195299949, 'reg_alpha': 5.785548615750857, 'reg_lambda': 9.707879029661969, 'gamma': 2.6647132048787703}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:06,688] Trial 291 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.1683602202003565, 'n_estimators': 163, 'subsample': 0.5406188700286195, 'colsample_bytree': 0.9502310820305853, 'reg_alpha': 6.113634125433757, 'reg_lambda': 8.950912695215223, 'gamma': 2.78640162221378}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:06,894] Trial 292 finished with value: 0.7172 and parameters: {'max_depth': 4, 'learning_rate': 0.153897859037921, 'n_estimators': 189, 'subsample': 0.7742641237739943, 'colsample_bytree': 0.911354030770444, 'reg_alpha': 5.56640245074607, 'reg_lambda': 9.108826465683451, 'gamma': 3.292936747634865}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:07,073] Trial 293 finished with value: 0.72 and parameters: {'max_depth': 3, 'learning_rate': 0.18043113906378724, 'n_estimators': 143, 'subsample': 0.5319184503805189, 'colsample_bytree': 0.5721111690658064, 'reg_alpha': 4.85353377193195, 'reg_lambda': 8.264640750223894, 'gamma': 2.2836400036556666}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:07,689] Trial 294 finished with value: 0.7276 and parameters: {'max_depth': 4, 'learning_rate': 0.09167295160486266, 'n_estimators': 866, 'subsample': 0.5548325631915921, 'colsample_bytree': 0.9687782807592341, 'reg_alpha': 6.555787245311796, 'reg_lambda': 9.392584199514854, 'gamma': 2.981159088684189}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:08,308] Trial 295 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.08886781285488024, 'n_estimators': 868, 'subsample': 0.5693784577789773, 'colsample_bytree': 0.9992305368267781, 'reg_alpha': 5.907795061457832, 'reg_lambda': 9.769680208726045, 'gamma': 3.013309389216438}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:08,958] Trial 296 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.0943404624308111, 'n_estimators': 902, 'subsample': 0.5430897721074018, 'colsample_bytree': 0.9815328946015833, 'reg_alpha': 5.122955909377132, 'reg_lambda': 9.456191816205356, 'gamma': 3.1989694484753484}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:09,565] Trial 297 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.09850277195634637, 'n_estimators': 851, 'subsample': 0.5554759258191848, 'colsample_bytree': 0.972064105491781, 'reg_alpha': 5.417445078690515, 'reg_lambda': 9.29164555781637, 'gamma': 3.1105194293305383}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:10,180] Trial 298 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.11149689641320341, 'n_estimators': 883, 'subsample': 0.5323559988449869, 'colsample_bytree': 0.8774736780577316, 'reg_alpha': 6.197234717913151, 'reg_lambda': 9.621569342448234, 'gamma': 2.8966674271883073}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:10,774] Trial 299 finished with value: 0.712 and parameters: {'max_depth': 4, 'learning_rate': 0.0827203357100637, 'n_estimators': 623, 'subsample': 0.6702712944544285, 'colsample_bytree': 0.5416373022569773, 'reg_alpha': 5.695897730746691, 'reg_lambda': 9.387105992730463, 'gamma': 0.2569262284006282}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:11,341] Trial 300 finished with value: 0.7272 and parameters: {'max_depth': 3, 'learning_rate': 0.10219400625106702, 'n_estimators': 813, 'subsample': 0.5799241225688703, 'colsample_bytree': 0.5890468893216398, 'reg_alpha': 4.451232290049032, 'reg_lambda': 9.83211632084422, 'gamma': 3.008151164939146}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:11,968] Trial 301 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.09271179044818934, 'n_estimators': 835, 'subsample': 0.5790934677951037, 'colsample_bytree': 0.5863956777414141, 'reg_alpha': 4.453344227478631, 'reg_lambda': 9.983066176766163, 'gamma': 3.010748781088285}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:12,395] Trial 302 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.10243411093724566, 'n_estimators': 555, 'subsample': 0.5679565005636028, 'colsample_bytree': 0.5613833340571585, 'reg_alpha': 4.642235561280731, 'reg_lambda': 9.739670635861794, 'gamma': 2.876472649210354}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:13,023] Trial 303 finished with value: 0.7256 and parameters: {'max_depth': 3, 'learning_rate': 0.09945270816018217, 'n_estimators': 827, 'subsample': 0.5796430269912309, 'colsample_bytree': 0.6203129639051371, 'reg_alpha': 4.528176637807544, 'reg_lambda': 9.808460936532386, 'gamma': 3.0595028898504752}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:13,654] Trial 304 finished with value: 0.7236 and parameters: {'max_depth': 3, 'learning_rate': 0.08707043930289717, 'n_estimators': 857, 'subsample': 0.6135176837800804, 'colsample_bytree': 0.572130553992811, 'reg_alpha': 4.318105553864485, 'reg_lambda': 9.553485020198439, 'gamma': 2.9583036193355867}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:14,283] Trial 305 finished with value: 0.7204 and parameters: {'max_depth': 3, 'learning_rate': 0.09202614485349277, 'n_estimators': 813, 'subsample': 0.5254725513880314, 'colsample_bytree': 0.5578661392168615, 'reg_alpha': 4.815506746812738, 'reg_lambda': 9.794535334669195, 'gamma': 2.4082127684692014}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:14,833] Trial 306 finished with value: 0.7244 and parameters: {'max_depth': 3, 'learning_rate': 0.07294978766882596, 'n_estimators': 763, 'subsample': 0.5873421574700057, 'colsample_bytree': 0.5256912001217288, 'reg_alpha': 5.070721016377173, 'reg_lambda': 9.555131291893192, 'gamma': 3.111842788536213}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:15,645] Trial 307 finished with value: 0.7248 and parameters: {'max_depth': 3, 'learning_rate': 0.10689448933771559, 'n_estimators': 878, 'subsample': 0.5600781078617108, 'colsample_bytree': 0.936618627727545, 'reg_alpha': 5.51421693716915, 'reg_lambda': 9.134350876083197, 'gamma': 2.5427568780432597}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:16,439] Trial 308 finished with value: 0.7184 and parameters: {'max_depth': 3, 'learning_rate': 0.10146226362609356, 'n_estimators': 854, 'subsample': 0.5435779230347401, 'colsample_bytree': 0.9566701959936303, 'reg_alpha': 5.862535289951826, 'reg_lambda': 9.370288467883586, 'gamma': 2.8352326339381193}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:16,931] Trial 309 finished with value: 0.7252 and parameters: {'max_depth': 3, 'learning_rate': 0.09600669477494705, 'n_estimators': 533, 'subsample': 0.5356743101624342, 'colsample_bytree': 0.9254834869965509, 'reg_alpha': 5.261158138994032, 'reg_lambda': 9.823023044672754, 'gamma': 3.1535923412361564}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:17,285] Trial 310 finished with value: 0.7212 and parameters: {'max_depth': 3, 'learning_rate': 0.14050840793910252, 'n_estimators': 312, 'subsample': 0.5199040236124237, 'colsample_bytree': 0.585818179778698, 'reg_alpha': 3.8041819549497364, 'reg_lambda': 9.266560126705855, 'gamma': 2.936632894522558}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:17,936] Trial 311 finished with value: 0.7172 and parameters: {'max_depth': 3, 'learning_rate': 0.14897379141067607, 'n_estimators': 817, 'subsample': 0.5708989047350201, 'colsample_bytree': 0.8907662170743907, 'reg_alpha': 4.122347510224546, 'reg_lambda': 9.997518596780099, 'gamma': 2.7400295578191156}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:18,355] Trial 312 finished with value: 0.7244 and parameters: {'max_depth': 6, 'learning_rate': 0.10611305106720426, 'n_estimators': 453, 'subsample': 0.6916444047863082, 'colsample_bytree': 0.5966874769218956, 'reg_alpha': 4.720553760168412, 'reg_lambda': 9.530513128114187, 'gamma': 2.578151921757694}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:19,021] Trial 313 finished with value: 0.7228 and parameters: {'max_depth': 3, 'learning_rate': 0.08495760274640657, 'n_estimators': 798, 'subsample': 0.5541560298719767, 'colsample_bytree': 0.6088568193547504, 'reg_alpha': 4.991206156493373, 'reg_lambda': 9.13568999863603, 'gamma': 2.157894701410421}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:19,739] Trial 314 finished with value: 0.724 and parameters: {'max_depth': 3, 'learning_rate': 0.0787514617978357, 'n_estimators': 923, 'subsample': 0.5288901907526165, 'colsample_bytree': 0.9698605605141013, 'reg_alpha': 6.047021783216577, 'reg_lambda': 8.517074907937387, 'gamma': 3.0340104319825034}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:20,368] Trial 315 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.16374501564240035, 'n_estimators': 835, 'subsample': 0.5607695581871993, 'colsample_bytree': 0.5794458982212796, 'reg_alpha': 4.3443270138678205, 'reg_lambda': 8.664937525740479, 'gamma': 2.431916431844638}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:21,008] Trial 316 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.09138001170219655, 'n_estimators': 890, 'subsample': 0.599049586385075, 'colsample_bytree': 0.9800499628970343, 'reg_alpha': 5.709789073919504, 'reg_lambda': 9.696942806036047, 'gamma': 2.814020038993529}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:21,606] Trial 317 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.11847823616538722, 'n_estimators': 860, 'subsample': 0.7554314609119049, 'colsample_bytree': 0.5470847142432164, 'reg_alpha': 5.533017057678408, 'reg_lambda': 9.388741126274756, 'gamma': 2.314364726802795}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:21,778] Trial 318 finished with value: 0.7216 and parameters: {'max_depth': 3, 'learning_rate': 0.09776793481200231, 'n_estimators': 118, 'subsample': 0.5478552783685886, 'colsample_bytree': 0.5353004586671751, 'reg_alpha': 3.963916958372285, 'reg_lambda': 8.19780127237733, 'gamma': 3.2319249724580197}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:22,448] Trial 319 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10980378850235267, 'n_estimators': 873, 'subsample': 0.5372686635773567, 'colsample_bytree': 0.985232077451082, 'reg_alpha': 4.848121406071173, 'reg_lambda': 9.054105031784625, 'gamma': 2.947978305441478}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:22,771] Trial 320 finished with value: 0.7224 and parameters: {'max_depth': 3, 'learning_rate': 0.14294314347063375, 'n_estimators': 357, 'subsample': 0.5032176658954693, 'colsample_bytree': 0.9056962312615106, 'reg_alpha': 5.29207572921369, 'reg_lambda': 9.59021729727898, 'gamma': 2.6401829972644864}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:23,379] Trial 321 finished with value: 0.7196 and parameters: {'max_depth': 3, 'learning_rate': 0.10331179248384079, 'n_estimators': 782, 'subsample': 0.5220297455401022, 'colsample_bytree': 0.5630991131666091, 'reg_alpha': 4.553906024650843, 'reg_lambda': 8.768662909769763, 'gamma': 1.8785661153384872}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:23,780] Trial 322 finished with value: 0.7284 and parameters: {'max_depth': 4, 'learning_rate': 0.16285439030068363, 'n_estimators': 501, 'subsample': 0.5452426157649689, 'colsample_bytree': 0.9624574479754857, 'reg_alpha': 6.296230298850782, 'reg_lambda': 9.263343409823994, 'gamma': 3.121183600940146}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:24,178] Trial 323 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.16781654624977055, 'n_estimators': 497, 'subsample': 0.5419511610169437, 'colsample_bytree': 0.9406842805601495, 'reg_alpha': 6.3111477673988, 'reg_lambda': 9.409772483616589, 'gamma': 3.074652213828433}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:24,810] Trial 324 finished with value: 0.712 and parameters: {'max_depth': 4, 'learning_rate': 0.16174376857223663, 'n_estimators': 841, 'subsample': 0.9653808923042815, 'colsample_bytree': 0.9671395079649375, 'reg_alpha': 6.703211057025907, 'reg_lambda': 9.80955223684871, 'gamma': 2.892663767987619}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:25,259] Trial 325 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.17080003696570037, 'n_estimators': 565, 'subsample': 0.530623198428059, 'colsample_bytree': 0.950386192329282, 'reg_alpha': 5.998772192507635, 'reg_lambda': 9.270293442216154, 'gamma': 2.748077903519367}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:25,912] Trial 326 finished with value: 0.7224 and parameters: {'max_depth': 4, 'learning_rate': 0.15299315770649655, 'n_estimators': 898, 'subsample': 0.5745703635914307, 'colsample_bytree': 0.9590254400663224, 'reg_alpha': 6.16980654408842, 'reg_lambda': 8.971388569963251, 'gamma': 2.515534001342244}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:26,283] Trial 327 finished with value: 0.7288 and parameters: {'max_depth': 4, 'learning_rate': 0.14788174912783328, 'n_estimators': 446, 'subsample': 0.5604013405842218, 'colsample_bytree': 0.9467451742867753, 'reg_alpha': 5.904025713644253, 'reg_lambda': 9.614465246354653, 'gamma': 2.966607327055366}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:26,765] Trial 328 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.14731962025986783, 'n_estimators': 526, 'subsample': 0.5505681636854074, 'colsample_bytree': 0.9427581369141516, 'reg_alpha': 5.945777826262568, 'reg_lambda': 0.8201442156097074, 'gamma': 2.9842763051112584}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:27,160] Trial 329 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.1397249857804637, 'n_estimators': 484, 'subsample': 0.5155978789876561, 'colsample_bytree': 0.9627979963918627, 'reg_alpha': 6.332814814786806, 'reg_lambda': 9.568202032438514, 'gamma': 3.1256525512903734}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:27,331] Trial 330 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.1512684326292213, 'n_estimators': 118, 'subsample': 0.5590363611175947, 'colsample_bytree': 0.9484026164135507, 'reg_alpha': 5.84534646561617, 'reg_lambda': 9.997412475063152, 'gamma': 3.0454722787119075}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:27,727] Trial 331 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.14539550061077303, 'n_estimators': 472, 'subsample': 0.7394055546750652, 'colsample_bytree': 0.9353125813858902, 'reg_alpha': 5.847985553634107, 'reg_lambda': 9.86148832204526, 'gamma': 2.987151912159103}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:28,143] Trial 332 finished with value: 0.7284 and parameters: {'max_depth': 4, 'learning_rate': 0.15241881400906665, 'n_estimators': 503, 'subsample': 0.5626245759964873, 'colsample_bytree': 0.9500808857672538, 'reg_alpha': 5.743740215474759, 'reg_lambda': 9.962518072017586, 'gamma': 3.0832699298556023}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:28,559] Trial 333 finished with value: 0.7224 and parameters: {'max_depth': 4, 'learning_rate': 0.15370593258861448, 'n_estimators': 441, 'subsample': 0.5647483205105425, 'colsample_bytree': 0.9243611184664707, 'reg_alpha': 5.7039342826686195, 'reg_lambda': 9.751549663928609, 'gamma': 3.0740071988110014}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:28,953] Trial 334 finished with value: 0.7272 and parameters: {'max_depth': 4, 'learning_rate': 0.14849600199110635, 'n_estimators': 462, 'subsample': 0.5600988139678565, 'colsample_bytree': 0.9486353112251722, 'reg_alpha': 5.891649346100081, 'reg_lambda': 9.979248904121876, 'gamma': 3.1281976488784635}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:29,376] Trial 335 finished with value: 0.726 and parameters: {'max_depth': 4, 'learning_rate': 0.158129466322039, 'n_estimators': 519, 'subsample': 0.5776455727017231, 'colsample_bytree': 0.9394769140234176, 'reg_alpha': 6.088698147721521, 'reg_lambda': 9.978817196174829, 'gamma': 3.1660381834741265}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:29,755] Trial 336 finished with value: 0.7224 and parameters: {'max_depth': 4, 'learning_rate': 0.14587632533764178, 'n_estimators': 451, 'subsample': 0.5902290803863159, 'colsample_bytree': 0.9489464522141889, 'reg_alpha': 5.5622942856904, 'reg_lambda': 9.820561758197488, 'gamma': 3.307615137401427}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:30,207] Trial 337 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.13672765996766292, 'n_estimators': 511, 'subsample': 0.5586498313981945, 'colsample_bytree': 0.9562204104521045, 'reg_alpha': 5.930686124473855, 'reg_lambda': 9.664696968481396, 'gamma': 2.9049576803500727}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:30,627] Trial 338 finished with value: 0.7276 and parameters: {'max_depth': 4, 'learning_rate': 0.1310168429590854, 'n_estimators': 498, 'subsample': 0.5698251254018356, 'colsample_bytree': 0.9292665037554526, 'reg_alpha': 6.267258471321792, 'reg_lambda': 9.64926835780824, 'gamma': 3.166149451057658}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:31,038] Trial 339 finished with value: 0.722 and parameters: {'max_depth': 4, 'learning_rate': 0.1312346241569145, 'n_estimators': 500, 'subsample': 0.5475092503618825, 'colsample_bytree': 0.931673316333425, 'reg_alpha': 6.488018709334214, 'reg_lambda': 9.876223981544477, 'gamma': 3.1968359753932245}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:31,464] Trial 340 finished with value: 0.7272 and parameters: {'max_depth': 4, 'learning_rate': 0.12794201221957296, 'n_estimators': 498, 'subsample': 0.5634460391510535, 'colsample_bytree': 0.9526598128106901, 'reg_alpha': 6.198320601814968, 'reg_lambda': 9.98253969676944, 'gamma': 3.3133275673083245}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:31,984] Trial 341 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.12676383164103255, 'n_estimators': 486, 'subsample': 0.5608503850036191, 'colsample_bytree': 0.9478084955940415, 'reg_alpha': 1.388718721319254, 'reg_lambda': 9.996222152971837, 'gamma': 3.428859398536394}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:32,388] Trial 342 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.13344049354099946, 'n_estimators': 508, 'subsample': 0.568966677979812, 'colsample_bytree': 0.9552975912539193, 'reg_alpha': 6.62257479011125, 'reg_lambda': 9.693327956784382, 'gamma': 3.3008775704852615}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:32,759] Trial 343 finished with value: 0.7212 and parameters: {'max_depth': 4, 'learning_rate': 0.13881388200495529, 'n_estimators': 468, 'subsample': 0.5821427979961848, 'colsample_bytree': 0.9332943872895991, 'reg_alpha': 6.277873375709666, 'reg_lambda': 9.843897600786773, 'gamma': 3.2507123686707016}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:33,175] Trial 344 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.12922109580162905, 'n_estimators': 529, 'subsample': 0.5521252038115327, 'colsample_bytree': 0.9592807876589075, 'reg_alpha': 6.209582405176734, 'reg_lambda': 9.655289316741348, 'gamma': 3.149946158810878}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:33,571] Trial 345 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.12629191941040435, 'n_estimators': 502, 'subsample': 0.5547835763832593, 'colsample_bytree': 0.9565466661757925, 'reg_alpha': 9.455135759090497, 'reg_lambda': 9.609287794610733, 'gamma': 3.3399144551055744}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:33,975] Trial 346 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.13272529866251975, 'n_estimators': 535, 'subsample': 0.5696061383590774, 'colsample_bytree': 0.9452502272271829, 'reg_alpha': 6.167989824741851, 'reg_lambda': 9.543559752489921, 'gamma': 3.4658872379884436}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:34,400] Trial 347 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1414026908815311, 'n_estimators': 551, 'subsample': 0.5517627648354284, 'colsample_bytree': 0.9645402094484462, 'reg_alpha': 6.359910991300432, 'reg_lambda': 9.665520544650622, 'gamma': 3.166240694473431}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:34,810] Trial 348 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.1325365362050528, 'n_estimators': 498, 'subsample': 0.5643364485536428, 'colsample_bytree': 0.9697014490482919, 'reg_alpha': 6.988060062115934, 'reg_lambda': 9.862289133186822, 'gamma': 3.2359130377068492}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:35,241] Trial 349 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.13328310013143602, 'n_estimators': 513, 'subsample': 0.5617552409093136, 'colsample_bytree': 0.9700849649471682, 'reg_alpha': 6.986304319507625, 'reg_lambda': 9.978013663225429, 'gamma': 3.3193629672175264}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:35,678] Trial 350 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.12822433987946363, 'n_estimators': 537, 'subsample': 0.5578654941912805, 'colsample_bytree': 0.958531186017716, 'reg_alpha': 6.822376657534249, 'reg_lambda': 9.962912056123827, 'gamma': 3.375445086878454}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:36,087] Trial 351 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.13024536422752667, 'n_estimators': 514, 'subsample': 0.5795801230660891, 'colsample_bytree': 0.9744975505910679, 'reg_alpha': 6.728171495145926, 'reg_lambda': 9.719694662060874, 'gamma': 3.316838184289008}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:36,472] Trial 352 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.13726109702340192, 'n_estimators': 481, 'subsample': 0.5449277033003376, 'colsample_bytree': 0.9228760561019443, 'reg_alpha': 6.487196110612948, 'reg_lambda': 9.435399167997089, 'gamma': 3.6777618417556512}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:36,901] Trial 353 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.1222926986867986, 'n_estimators': 522, 'subsample': 0.5688960240256928, 'colsample_bytree': 0.9418739516638608, 'reg_alpha': 6.055488713021911, 'reg_lambda': 9.970221286927941, 'gamma': 3.5604672634231673}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:37,313] Trial 354 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.13900611058675907, 'n_estimators': 495, 'subsample': 0.5369864030288228, 'colsample_bytree': 0.9634788987385056, 'reg_alpha': 6.366191044164685, 'reg_lambda': 9.534858898648126, 'gamma': 3.1348729457751325}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:37,726] Trial 355 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.14884704888737735, 'n_estimators': 470, 'subsample': 0.5513773327273751, 'colsample_bytree': 0.9520617251549129, 'reg_alpha': 7.201340395824716, 'reg_lambda': 9.744279261063774, 'gamma': 3.4120574007027398}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:38,154] Trial 356 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.1430694515798086, 'n_estimators': 516, 'subsample': 0.5633087520635027, 'colsample_bytree': 0.9734131148157356, 'reg_alpha': 6.606542411510352, 'reg_lambda': 9.481070664669831, 'gamma': 3.0463252785766786}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:38,604] Trial 357 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.12247213864618565, 'n_estimators': 537, 'subsample': 0.5755471038796148, 'colsample_bytree': 0.9673253296950042, 'reg_alpha': 7.032080381185316, 'reg_lambda': 9.70295843919146, 'gamma': 3.276836869575565}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:38,993] Trial 358 finished with value: 0.728 and parameters: {'max_depth': 6, 'learning_rate': 0.13432633483092843, 'n_estimators': 484, 'subsample': 0.5424449864638419, 'colsample_bytree': 0.9396275496716134, 'reg_alpha': 6.1166013609540135, 'reg_lambda': 9.98945923239374, 'gamma': 3.1866260569492177}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:39,445] Trial 359 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.1447391390522832, 'n_estimators': 474, 'subsample': 0.5331246848014238, 'colsample_bytree': 0.930675978700571, 'reg_alpha': 5.9418636362326085, 'reg_lambda': 9.30182800683158, 'gamma': 3.1634799332403998}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:39,858] Trial 360 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.13930281564581504, 'n_estimators': 515, 'subsample': 0.5415170476930274, 'colsample_bytree': 0.9828819921356864, 'reg_alpha': 5.9657205318449025, 'reg_lambda': 9.69767562894285, 'gamma': 3.064326160584989}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:40,272] Trial 361 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.14992545044432387, 'n_estimators': 467, 'subsample': 0.549794843064324, 'colsample_bytree': 0.9372825640810479, 'reg_alpha': 4.20386297291673, 'reg_lambda': 6.354225017912038, 'gamma': 3.18858048525067}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:40,695] Trial 362 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.13451549168370255, 'n_estimators': 549, 'subsample': 0.5291682668111848, 'colsample_bytree': 0.9227448433169472, 'reg_alpha': 6.082878476532695, 'reg_lambda': 9.986239225322437, 'gamma': 3.032148691241073}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:41,151] Trial 363 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.14341822404966434, 'n_estimators': 486, 'subsample': 0.541803205095045, 'colsample_bytree': 0.9419404868245831, 'reg_alpha': 5.766551293657912, 'reg_lambda': 9.454149781949951, 'gamma': 2.98468134424414}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:41,546] Trial 364 finished with value: 0.7268 and parameters: {'max_depth': 6, 'learning_rate': 0.1555820169505525, 'n_estimators': 460, 'subsample': 0.5539501486327952, 'colsample_bytree': 0.9762456309004001, 'reg_alpha': 6.382386736666023, 'reg_lambda': 9.160392662642694, 'gamma': 3.1538964767529776}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:41,989] Trial 365 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.13659071121327235, 'n_estimators': 524, 'subsample': 0.5360396831589632, 'colsample_bytree': 0.9876849859996498, 'reg_alpha': 5.6906332631657035, 'reg_lambda': 9.801631682850893, 'gamma': 3.103605892895714}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:42,425] Trial 366 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.1347194807712544, 'n_estimators': 529, 'subsample': 0.5240438591957159, 'colsample_bytree': 0.9903631904893005, 'reg_alpha': 5.502214765136103, 'reg_lambda': 9.587731706149672, 'gamma': 2.7970801825710057}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:42,854] Trial 367 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.13564007219534263, 'n_estimators': 538, 'subsample': 0.5348430523001159, 'colsample_bytree': 0.9907510620950748, 'reg_alpha': 5.656671783383512, 'reg_lambda': 9.396542307179406, 'gamma': 2.9824889579385223}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:43,299] Trial 368 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.12572618982902273, 'n_estimators': 510, 'subsample': 0.5390952955405051, 'colsample_bytree': 0.9824320058310004, 'reg_alpha': 4.464150755384301, 'reg_lambda': 9.762433217654943, 'gamma': 3.220583641479316}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:43,789] Trial 369 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.13153111854622584, 'n_estimators': 581, 'subsample': 0.5261849703021358, 'colsample_bytree': 0.9708285783344901, 'reg_alpha': 6.108794992024387, 'reg_lambda': 9.22258232386444, 'gamma': 3.081358253711517}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:44,248] Trial 370 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.11957114409931184, 'n_estimators': 559, 'subsample': 0.5477029184647839, 'colsample_bytree': 0.9876608007038002, 'reg_alpha': 5.460628103988958, 'reg_lambda': 9.526381852125764, 'gamma': 2.851361750522082}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:44,663] Trial 371 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.12147097946890512, 'n_estimators': 559, 'subsample': 0.7843090053361825, 'colsample_bytree': 0.9893718604019612, 'reg_alpha': 5.4848783135952965, 'reg_lambda': 9.430443783614733, 'gamma': 3.495324069900806}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:45,234] Trial 372 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.11853413163598911, 'n_estimators': 714, 'subsample': 0.5451561474008229, 'colsample_bytree': 0.9831335193530782, 'reg_alpha': 5.386164874241249, 'reg_lambda': 9.204474832119287, 'gamma': 2.875028140248811}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:45,809] Trial 373 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.11955035328658224, 'n_estimators': 685, 'subsample': 0.5456911760791421, 'colsample_bytree': 0.9998702736817704, 'reg_alpha': 5.379379884318803, 'reg_lambda': 9.247199288710412, 'gamma': 2.871858505581722}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:46,387] Trial 374 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.11968547817818878, 'n_estimators': 716, 'subsample': 0.544407141031499, 'colsample_bytree': 0.9776170939774403, 'reg_alpha': 5.364711436819695, 'reg_lambda': 9.170287787376994, 'gamma': 2.816775456153744}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:46,970] Trial 375 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11656433785376867, 'n_estimators': 757, 'subsample': 0.5471594140302625, 'colsample_bytree': 0.9637702686760368, 'reg_alpha': 5.3643032362755, 'reg_lambda': 9.266895808403765, 'gamma': 2.697922249791595}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:47,512] Trial 376 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.1252890946632571, 'n_estimators': 700, 'subsample': 0.538119977491643, 'colsample_bytree': 0.9995360246569567, 'reg_alpha': 5.560462498520341, 'reg_lambda': 0.07454005091869398, 'gamma': 2.8524527565198396}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:47,971] Trial 377 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.12082797942940152, 'n_estimators': 527, 'subsample': 0.5224789746504249, 'colsample_bytree': 0.9785880512708227, 'reg_alpha': 5.276777607026348, 'reg_lambda': 9.057184453322547, 'gamma': 2.751545846352581}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:48,483] Trial 378 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.12909296723574612, 'n_estimators': 668, 'subsample': 0.5528570451552853, 'colsample_bytree': 0.9609773436830279, 'reg_alpha': 5.586553864445187, 'reg_lambda': 3.804863015360608, 'gamma': 2.8756289265773796}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:48,973] Trial 379 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.11469207956300567, 'n_estimators': 578, 'subsample': 0.5337025081673386, 'colsample_bytree': 0.9863626919256456, 'reg_alpha': 5.33920454379257, 'reg_lambda': 9.502728159609422, 'gamma': 2.7784451904905003}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:49,450] Trial 380 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.12472367888011127, 'n_estimators': 564, 'subsample': 0.5412552777202202, 'colsample_bytree': 0.96957368849959, 'reg_alpha': 5.67227296170449, 'reg_lambda': 9.313187937753973, 'gamma': 2.681128045185467}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:49,893] Trial 381 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.1195549548931425, 'n_estimators': 505, 'subsample': 0.5548012620630178, 'colsample_bytree': 0.978673672893844, 'reg_alpha': 6.834011555058723, 'reg_lambda': 9.130657085431938, 'gamma': 2.9396524400258293}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:50,422] Trial 382 finished with value: 0.718 and parameters: {'max_depth': 5, 'learning_rate': 0.1273956231015402, 'n_estimators': 686, 'subsample': 0.5304221789138704, 'colsample_bytree': 0.9879494214460534, 'reg_alpha': 5.778470491771192, 'reg_lambda': 9.566138592220241, 'gamma': 2.8543081239583943}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:50,934] Trial 383 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1304021649917673, 'n_estimators': 621, 'subsample': 0.5480544778937141, 'colsample_bytree': 0.9620804145508653, 'reg_alpha': 5.183618331880524, 'reg_lambda': 9.38298097642565, 'gamma': 2.646893780770388}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:51,401] Trial 384 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.13698714853954308, 'n_estimators': 603, 'subsample': 0.5183637659841601, 'colsample_bytree': 0.9719932653276071, 'reg_alpha': 6.626707664469402, 'reg_lambda': 9.031711781543699, 'gamma': 2.9466184463991674}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:51,948] Trial 385 finished with value: 0.718 and parameters: {'max_depth': 5, 'learning_rate': 0.11637047692313257, 'n_estimators': 744, 'subsample': 0.7680650082520818, 'colsample_bytree': 0.9543355530694597, 'reg_alpha': 5.416166177607056, 'reg_lambda': 5.222636912473387, 'gamma': 2.7684714006122793}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:52,353] Trial 386 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.1317524745414209, 'n_estimators': 490, 'subsample': 0.5429981552749348, 'colsample_bytree': 0.9928777610187006, 'reg_alpha': 6.0759008949887265, 'reg_lambda': 9.58498013420185, 'gamma': 2.8378900327917043}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:52,790] Trial 387 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.12218734599912537, 'n_estimators': 543, 'subsample': 0.5577024900429246, 'colsample_bytree': 0.9802215072777866, 'reg_alpha': 6.245707931357751, 'reg_lambda': 9.256987416760815, 'gamma': 2.9160122122945475}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:53,287] Trial 388 finished with value: 0.7248 and parameters: {'max_depth': 6, 'learning_rate': 0.14264975571221997, 'n_estimators': 637, 'subsample': 0.5286419509001506, 'colsample_bytree': 0.9708230927440576, 'reg_alpha': 5.732537629296241, 'reg_lambda': 4.290469840473213, 'gamma': 3.387273785550292}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:53,785] Trial 389 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11668230204968236, 'n_estimators': 516, 'subsample': 0.5654778448905777, 'colsample_bytree': 0.9447765729474615, 'reg_alpha': 7.378590550802565, 'reg_lambda': 8.844966992182858, 'gamma': 2.698327925363037}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:54,211] Trial 390 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1385275109434923, 'n_estimators': 518, 'subsample': 0.5366332094593154, 'colsample_bytree': 0.9998151865587045, 'reg_alpha': 6.5034130651265105, 'reg_lambda': 9.434739160383954, 'gamma': 2.9744962341635652}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:54,765] Trial 391 finished with value: 0.7284 and parameters: {'max_depth': 6, 'learning_rate': 0.12959188030267052, 'n_estimators': 502, 'subsample': 0.5496713613048803, 'colsample_bytree': 0.9311959090684777, 'reg_alpha': 5.925410354846847, 'reg_lambda': 9.670647750928929, 'gamma': 2.7982591617315644}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:55,191] Trial 392 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.12808267961456546, 'n_estimators': 491, 'subsample': 0.5537142239749556, 'colsample_bytree': 0.9298510901109726, 'reg_alpha': 5.830352190952537, 'reg_lambda': 9.172531243815262, 'gamma': 2.792751216942606}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:55,655] Trial 393 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.13208154928733168, 'n_estimators': 506, 'subsample': 0.5475360152930192, 'colsample_bytree': 0.9828670690605912, 'reg_alpha': 5.497254262241077, 'reg_lambda': 9.551896308946693, 'gamma': 2.6052530468444877}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:56,097] Trial 394 finished with value: 0.722 and parameters: {'max_depth': 6, 'learning_rate': 0.13654385897702936, 'n_estimators': 489, 'subsample': 0.5635518298310385, 'colsample_bytree': 0.924317767644817, 'reg_alpha': 5.961822199817853, 'reg_lambda': 8.987213490178661, 'gamma': 2.856821775245315}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:56,666] Trial 395 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12173846340146123, 'n_estimators': 557, 'subsample': 0.5557040613795653, 'colsample_bytree': 0.9376036448671512, 'reg_alpha': 5.658278953858975, 'reg_lambda': 3.3970305350144283, 'gamma': 2.7253827184738713}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:57,128] Trial 396 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.12691851612518648, 'n_estimators': 529, 'subsample': 0.572955119004222, 'colsample_bytree': 0.959887883821184, 'reg_alpha': 5.221692596318868, 'reg_lambda': 9.325626463011261, 'gamma': 2.9618078925284563}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:57,586] Trial 397 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.14148149990009556, 'n_estimators': 544, 'subsample': 0.5453016455808886, 'colsample_bytree': 0.9903107136746486, 'reg_alpha': 5.935011560530136, 'reg_lambda': 9.692587023291285, 'gamma': 2.8020383941078455}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:58,128] Trial 398 finished with value: 0.7204 and parameters: {'max_depth': 5, 'learning_rate': 0.11439221966517914, 'n_estimators': 477, 'subsample': 0.5596785171897086, 'colsample_bytree': 0.9175204970040525, 'reg_alpha': 5.523239849307586, 'reg_lambda': 9.116805284750772, 'gamma': 2.6629775135760236}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:58,611] Trial 399 finished with value: 0.716 and parameters: {'max_depth': 6, 'learning_rate': 0.12158499163024862, 'n_estimators': 498, 'subsample': 0.5378984927135027, 'colsample_bytree': 0.9726982875624721, 'reg_alpha': 2.211302859709585, 'reg_lambda': 8.818124408853112, 'gamma': 3.0702883407488786}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:59,158] Trial 400 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.13155478951925725, 'n_estimators': 683, 'subsample': 0.5488706496726621, 'colsample_bytree': 0.9827670906730904, 'reg_alpha': 6.253539273907665, 'reg_lambda': 9.437979041103558, 'gamma': 2.8895674234820565}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:50:59,615] Trial 401 finished with value: 0.7192 and parameters: {'max_depth': 5, 'learning_rate': 0.1360292699448442, 'n_estimators': 526, 'subsample': 0.5686133129592869, 'colsample_bytree': 0.999759288977657, 'reg_alpha': 5.078370058276771, 'reg_lambda': 9.664910460254452, 'gamma': 2.57234163329139}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:50:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:00,049] Trial 402 finished with value: 0.7164 and parameters: {'max_depth': 5, 'learning_rate': 0.14368599487329822, 'n_estimators': 444, 'subsample': 0.5876739024004277, 'colsample_bytree': 0.9625053681830873, 'reg_alpha': 5.772835347485528, 'reg_lambda': 9.301292535762748, 'gamma': 2.9603656064040345}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:00,470] Trial 403 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.11203591006006103, 'n_estimators': 510, 'subsample': 0.5550560815642815, 'colsample_bytree': 0.9350046840661513, 'reg_alpha': 6.116906260766288, 'reg_lambda': 9.630955139500099, 'gamma': 3.0314093771201684}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:00,883] Trial 404 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.12350148306721608, 'n_estimators': 482, 'subsample': 0.5357030760852897, 'colsample_bytree': 0.9897913388635986, 'reg_alpha': 5.425174450614808, 'reg_lambda': 4.64454360135366, 'gamma': 2.7895224261552607}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:01,508] Trial 405 finished with value: 0.7112 and parameters: {'max_depth': 5, 'learning_rate': 0.13179943241845654, 'n_estimators': 729, 'subsample': 0.7599507980405239, 'colsample_bytree': 0.951037376234642, 'reg_alpha': 5.929950170462368, 'reg_lambda': 6.0066862641930285, 'gamma': 1.0847621573923254}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:01,723] Trial 406 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.1468262625217732, 'n_estimators': 153, 'subsample': 0.5133559529200952, 'colsample_bytree': 0.973444898582706, 'reg_alpha': 5.567943794612885, 'reg_lambda': 8.974323271429178, 'gamma': 2.6872507056949995}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:02,153] Trial 407 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.1387454771563111, 'n_estimators': 544, 'subsample': 0.5429934911032657, 'colsample_bytree': 0.9182662834013029, 'reg_alpha': 5.6614610578591895, 'reg_lambda': 9.26294198474675, 'gamma': 3.1513792014877042}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:02,581] Trial 408 finished with value: 0.7236 and parameters: {'max_depth': 9, 'learning_rate': 0.11755406615102357, 'n_estimators': 498, 'subsample': 0.5234476123220602, 'colsample_bytree': 0.9814657968008551, 'reg_alpha': 6.045641390810942, 'reg_lambda': 9.7839471437418, 'gamma': 3.2711902923788134}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:02,775] Trial 409 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.12902364832756336, 'n_estimators': 138, 'subsample': 0.5653042448097402, 'colsample_bytree': 0.9686058882440266, 'reg_alpha': 5.761273967220693, 'reg_lambda': 9.510862391353927, 'gamma': 2.881636302183056}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:03,223] Trial 410 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.15510655154484404, 'n_estimators': 514, 'subsample': 0.5505681429445471, 'colsample_bytree': 0.9577070706541458, 'reg_alpha': 5.145497547641257, 'reg_lambda': 9.108523522297757, 'gamma': 2.5858687176674757}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:03,714] Trial 411 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.11171965680698327, 'n_estimators': 646, 'subsample': 0.5334521923121449, 'colsample_bytree': 0.9437468077160063, 'reg_alpha': 6.276851922616936, 'reg_lambda': 8.788198867066704, 'gamma': 3.0771040284510094}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:04,137] Trial 412 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.1480042524392298, 'n_estimators': 530, 'subsample': 0.5723704261034497, 'colsample_bytree': 0.9862183295763216, 'reg_alpha': 5.400952792871011, 'reg_lambda': 9.394886896624943, 'gamma': 4.730416068873011}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:04,525] Trial 413 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.16152790711631176, 'n_estimators': 481, 'subsample': 0.5447559552351555, 'colsample_bytree': 0.992652600717223, 'reg_alpha': 8.68172448429089, 'reg_lambda': 9.742624332164256, 'gamma': 2.7458022041458654}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:04,992] Trial 414 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.13573125803524416, 'n_estimators': 566, 'subsample': 0.5613136634322601, 'colsample_bytree': 0.9771877997509166, 'reg_alpha': 5.980511484270799, 'reg_lambda': 9.530838789868488, 'gamma': 2.967807532521985}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:05,365] Trial 415 finished with value: 0.722 and parameters: {'max_depth': 6, 'learning_rate': 0.12600648122177144, 'n_estimators': 448, 'subsample': 0.5266084483561148, 'colsample_bytree': 0.9662469901456845, 'reg_alpha': 5.812393262108116, 'reg_lambda': 9.178137574625039, 'gamma': 3.2061244997562106}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:05,569] Trial 416 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.15091637353775333, 'n_estimators': 156, 'subsample': 0.5533101728255121, 'colsample_bytree': 0.9338789842764667, 'reg_alpha': 2.7930187623975584, 'reg_lambda': 6.556909479270309, 'gamma': 2.8577408123883985}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:05,766] Trial 417 finished with value: 0.7204 and parameters: {'max_depth': 5, 'learning_rate': 0.14352893921001916, 'n_estimators': 138, 'subsample': 0.5404926840594747, 'colsample_bytree': 0.9525709891889929, 'reg_alpha': 6.170450064925518, 'reg_lambda': 9.789563665049952, 'gamma': 2.511895369279163}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:06,248] Trial 418 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.11948952046741634, 'n_estimators': 586, 'subsample': 0.5593216589179022, 'colsample_bytree': 0.9776611889700927, 'reg_alpha': 5.009788188647724, 'reg_lambda': 8.937649864003467, 'gamma': 3.059536165359106}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:06,668] Trial 419 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13846943114556923, 'n_estimators': 506, 'subsample': 0.5165212286165823, 'colsample_bytree': 0.9263736430676475, 'reg_alpha': 7.610126678785357, 'reg_lambda': 9.338324035089608, 'gamma': 2.6579555925849103}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:06,857] Trial 420 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.12560343076226815, 'n_estimators': 122, 'subsample': 0.5753515630376916, 'colsample_bytree': 0.9923425271180316, 'reg_alpha': 7.096480418181087, 'reg_lambda': 9.610287799927923, 'gamma': 2.795871232458101}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:07,345] Trial 421 finished with value: 0.7228 and parameters: {'max_depth': 4, 'learning_rate': 0.17421112665033234, 'n_estimators': 611, 'subsample': 0.5320593099173258, 'colsample_bytree': 0.9634109660469256, 'reg_alpha': 5.624198447241438, 'reg_lambda': 8.659125942760909, 'gamma': 3.2509585244794867}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:07,902] Trial 422 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.11591193026203397, 'n_estimators': 706, 'subsample': 0.5479452423828629, 'colsample_bytree': 0.9443999312800161, 'reg_alpha': 5.24766538882764, 'reg_lambda': 9.982781116842657, 'gamma': 2.9333962214299354}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:08,290] Trial 423 finished with value: 0.7256 and parameters: {'max_depth': 7, 'learning_rate': 0.10851289961310658, 'n_estimators': 461, 'subsample': 0.5378663963398949, 'colsample_bytree': 0.9994628532716314, 'reg_alpha': 6.4339175693827, 'reg_lambda': 9.124745820952024, 'gamma': 3.1248801959295345}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:08,702] Trial 424 finished with value: 0.7272 and parameters: {'max_depth': 4, 'learning_rate': 0.16470966768397005, 'n_estimators': 530, 'subsample': 0.587195778202998, 'colsample_bytree': 0.98231931003195, 'reg_alpha': 5.903638637530047, 'reg_lambda': 9.466134255515067, 'gamma': 3.016399100368287}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:09,124] Trial 425 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.13463339862404633, 'n_estimators': 481, 'subsample': 0.5638568904446181, 'colsample_bytree': 0.9704440641413112, 'reg_alpha': 5.392550785751099, 'reg_lambda': 9.813836953939623, 'gamma': 2.750363017144878}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:09,569] Trial 426 finished with value: 0.7252 and parameters: {'max_depth': 4, 'learning_rate': 0.15518030356175927, 'n_estimators': 548, 'subsample': 0.5224380138598169, 'colsample_bytree': 0.954382439263567, 'reg_alpha': 6.129569433328767, 'reg_lambda': 8.931940118231056, 'gamma': 2.8692391786744795}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:09,778] Trial 427 finished with value: 0.7288 and parameters: {'max_depth': 6, 'learning_rate': 0.14418868590486297, 'n_estimators': 167, 'subsample': 0.5528939252560824, 'colsample_bytree': 0.9879467632148521, 'reg_alpha': 5.654307313528469, 'reg_lambda': 9.286245069076374, 'gamma': 3.310125781717294}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:09,989] Trial 428 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.14393655084215426, 'n_estimators': 168, 'subsample': 0.5086772099066094, 'colsample_bytree': 0.9822034871326296, 'reg_alpha': 5.719840483571772, 'reg_lambda': 9.29620405899359, 'gamma': 3.3446629471413942}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:10,194] Trial 429 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.14861878363088055, 'n_estimators': 149, 'subsample': 0.5478095328522582, 'colsample_bytree': 0.9921624474323312, 'reg_alpha': 5.554196276391745, 'reg_lambda': 9.606332087621663, 'gamma': 2.6001708464145334}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:10,420] Trial 430 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.14047074708277113, 'n_estimators': 161, 'subsample': 0.5574730581240724, 'colsample_bytree': 0.9376312184427006, 'reg_alpha': 5.808139012239176, 'reg_lambda': 9.07642089104642, 'gamma': 2.7000410672415933}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:10,603] Trial 431 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.15962136076833222, 'n_estimators': 127, 'subsample': 0.573046767069062, 'colsample_bytree': 0.9077891158039694, 'reg_alpha': 5.922374807378103, 'reg_lambda': 9.815499177466691, 'gamma': 2.997564978596664}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:10,832] Trial 432 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.13078720130916502, 'n_estimators': 190, 'subsample': 0.5304270359404543, 'colsample_bytree': 0.9628096257204684, 'reg_alpha': 5.601263363500687, 'reg_lambda': 9.5166787902173, 'gamma': 3.300665847946242}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:11,031] Trial 433 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.14548428894612797, 'n_estimators': 141, 'subsample': 0.5403212601872955, 'colsample_bytree': 0.9728616961205104, 'reg_alpha': 8.395727574935819, 'reg_lambda': 8.748300517886895, 'gamma': 2.487849263744961}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:11,435] Trial 434 finished with value: 0.7264 and parameters: {'max_depth': 6, 'learning_rate': 0.15005199696352436, 'n_estimators': 502, 'subsample': 0.5533893000484152, 'colsample_bytree': 0.6447353474214512, 'reg_alpha': 6.124708285366981, 'reg_lambda': 9.32466121452576, 'gamma': 3.122335879383802}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:11,635] Trial 435 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.1398953822639434, 'n_estimators': 166, 'subsample': 0.7492240950807291, 'colsample_bytree': 0.9871218726318597, 'reg_alpha': 6.305367452342142, 'reg_lambda': 9.992230589698188, 'gamma': 2.875816571411549}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:12,060] Trial 436 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.13071000031353397, 'n_estimators': 522, 'subsample': 0.5657575509264888, 'colsample_bytree': 0.9179286475163742, 'reg_alpha': 5.4342974039800644, 'reg_lambda': 9.693635385721503, 'gamma': 2.7614767160754075}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:12,238] Trial 437 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.15448763360105164, 'n_estimators': 113, 'subsample': 0.5438532629837572, 'colsample_bytree': 0.9487238702056476, 'reg_alpha': 5.963004641219441, 'reg_lambda': 9.16320220444937, 'gamma': 2.615889189462261}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:12,611] Trial 438 finished with value: 0.7124 and parameters: {'max_depth': 4, 'learning_rate': 0.13514936224599977, 'n_estimators': 491, 'subsample': 0.9105933544768684, 'colsample_bytree': 0.9909439905050119, 'reg_alpha': 5.717284860878104, 'reg_lambda': 9.432233723237001, 'gamma': 3.499568228580152}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:12,851] Trial 439 finished with value: 0.722 and parameters: {'max_depth': 4, 'learning_rate': 0.1460573014187122, 'n_estimators': 220, 'subsample': 0.5283918864506771, 'colsample_bytree': 0.9268194704083034, 'reg_alpha': 6.692234652483766, 'reg_lambda': 8.898127772625202, 'gamma': 3.2238963438161536}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:13,067] Trial 440 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.1592972325128139, 'n_estimators': 179, 'subsample': 0.5012154966870925, 'colsample_bytree': 0.9710996437782844, 'reg_alpha': 5.459110906633259, 'reg_lambda': 9.681731328540296, 'gamma': 3.038694436222015}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:13,241] Trial 441 finished with value: 0.7192 and parameters: {'max_depth': 6, 'learning_rate': 0.12536529198031304, 'n_estimators': 101, 'subsample': 0.557918498494129, 'colsample_bytree': 0.9560092890653471, 'reg_alpha': 6.36422163702739, 'reg_lambda': 1.2958329553969632, 'gamma': 2.9305772224003603}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:13,424] Trial 442 finished with value: 0.7232 and parameters: {'max_depth': 4, 'learning_rate': 0.13848292972474777, 'n_estimators': 130, 'subsample': 0.5184539644854405, 'colsample_bytree': 0.94505358138598, 'reg_alpha': 5.865058612991352, 'reg_lambda': 9.084369627002717, 'gamma': 2.7757991353002947}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:13,939] Trial 443 finished with value: 0.7084 and parameters: {'max_depth': 6, 'learning_rate': 0.16571224963795833, 'n_estimators': 432, 'subsample': 0.5374024632101627, 'colsample_bytree': 0.8954620752324215, 'reg_alpha': 6.108164520715643, 'reg_lambda': 9.79394073784134, 'gamma': 0.9033969983962609}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:14,324] Trial 444 finished with value: 0.7172 and parameters: {'max_depth': 8, 'learning_rate': 0.15271374592105807, 'n_estimators': 474, 'subsample': 0.57688744863887, 'colsample_bytree': 0.9779748612304481, 'reg_alpha': 5.37392162335241, 'reg_lambda': 9.520839760270698, 'gamma': 3.3503891105245245}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:14,740] Trial 445 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.13337456183820293, 'n_estimators': 514, 'subsample': 0.5475331634553073, 'colsample_bytree': 0.9635073813773553, 'reg_alpha': 5.676704078332269, 'reg_lambda': 8.654687156297623, 'gamma': 3.1186219406024005}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:15,155] Trial 446 finished with value: 0.7152 and parameters: {'max_depth': 5, 'learning_rate': 0.12426760045910666, 'n_estimators': 514, 'subsample': 0.5960399342799845, 'colsample_bytree': 0.9591166849311403, 'reg_alpha': 9.97509414790058, 'reg_lambda': 8.572915792920577, 'gamma': 3.1519609396209907}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:15,606] Trial 447 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.14184618826456213, 'n_estimators': 548, 'subsample': 0.5679337861044889, 'colsample_bytree': 0.937444788037029, 'reg_alpha': 5.624951410739077, 'reg_lambda': 8.740379939187463, 'gamma': 3.111495542743625}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:16,080] Trial 448 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.12879000892861964, 'n_estimators': 574, 'subsample': 0.5474908871593481, 'colsample_bytree': 0.963314845282682, 'reg_alpha': 5.136078827573838, 'reg_lambda': 8.873056908691847, 'gamma': 2.9916880725557937}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:16,574] Trial 449 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.13280030922333827, 'n_estimators': 527, 'subsample': 0.5573239837942897, 'colsample_bytree': 0.9509007372291522, 'reg_alpha': 0.37883664830379526, 'reg_lambda': 9.304223499119164, 'gamma': 3.234074647912707}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:17,028] Trial 450 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.12137786659719746, 'n_estimators': 501, 'subsample': 0.5830574440736822, 'colsample_bytree': 0.9689112036866971, 'reg_alpha': 5.680686528075485, 'reg_lambda': 8.667191928927057, 'gamma': 3.4211474808351965}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:17,665] Trial 451 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.14978248006868794, 'n_estimators': 665, 'subsample': 0.5448130202634265, 'colsample_bytree': 0.9431658036769593, 'reg_alpha': 5.37415828570948, 'reg_lambda': 9.834836898890773, 'gamma': 3.082196523957338}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:18,114] Trial 452 finished with value: 0.7268 and parameters: {'max_depth': 7, 'learning_rate': 0.17297080177056184, 'n_estimators': 520, 'subsample': 0.5540199514245379, 'colsample_bytree': 0.9317166917064673, 'reg_alpha': 6.543234057562258, 'reg_lambda': 9.994036856259015, 'gamma': 3.2265568285127557}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:18,541] Trial 453 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.13679460978833985, 'n_estimators': 540, 'subsample': 0.5690589887201202, 'colsample_bytree': 0.9578406471490309, 'reg_alpha': 6.9152572119615625, 'reg_lambda': 9.06841605393988, 'gamma': 2.93615839706599}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:18,932] Trial 454 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.157142758727355, 'n_estimators': 459, 'subsample': 0.5314622052819342, 'colsample_bytree': 0.9751943488946235, 'reg_alpha': 6.001685105911028, 'reg_lambda': 8.496838817590753, 'gamma': 2.8527495513086922}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:19,362] Trial 455 finished with value: 0.718 and parameters: {'max_depth': 4, 'learning_rate': 0.14520472355819378, 'n_estimators': 486, 'subsample': 0.5610906070957834, 'colsample_bytree': 0.5013895885248073, 'reg_alpha': 5.58872462566062, 'reg_lambda': 9.612367252213195, 'gamma': 1.5162393976419524}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:20,011] Trial 456 finished with value: 0.7172 and parameters: {'max_depth': 5, 'learning_rate': 0.18148816813630012, 'n_estimators': 784, 'subsample': 0.5383212314180961, 'colsample_bytree': 0.965776128948047, 'reg_alpha': 5.205027262026136, 'reg_lambda': 4.0472894426529455, 'gamma': 3.041455876297288}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:20,471] Trial 457 finished with value: 0.7216 and parameters: {'max_depth': 4, 'learning_rate': 0.13300596882661894, 'n_estimators': 492, 'subsample': 0.5489232571450986, 'colsample_bytree': 0.809658633242892, 'reg_alpha': 5.779503874580368, 'reg_lambda': 9.399832450690134, 'gamma': 3.314432619816159}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:20,958] Trial 458 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.11763754625197301, 'n_estimators': 561, 'subsample': 0.5212330831100193, 'colsample_bytree': 0.9529310359364132, 'reg_alpha': 3.4165511294035995, 'reg_lambda': 8.9320132106488, 'gamma': 3.1389281882451767}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:21,404] Trial 459 finished with value: 0.7224 and parameters: {'max_depth': 10, 'learning_rate': 0.16311182264134275, 'n_estimators': 511, 'subsample': 0.5661776622847158, 'colsample_bytree': 0.9808049257579519, 'reg_alpha': 6.30301182698538, 'reg_lambda': 5.495965089942382, 'gamma': 2.9552855474588204}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:21,884] Trial 460 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.12664474136705126, 'n_estimators': 531, 'subsample': 0.5345590655359624, 'colsample_bytree': 0.9188901387968572, 'reg_alpha': 6.077701692361955, 'reg_lambda': 9.22386254768294, 'gamma': 3.5673636843417134}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:22,322] Trial 461 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.1412776137979765, 'n_estimators': 506, 'subsample': 0.5487132250525463, 'colsample_bytree': 0.9419581226403568, 'reg_alpha': 5.488581504424937, 'reg_lambda': 9.702031123029753, 'gamma': 2.841995006964063}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:22,716] Trial 462 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.15200158579609147, 'n_estimators': 472, 'subsample': 0.5755969533699135, 'colsample_bytree': 0.9670417675062339, 'reg_alpha': 5.846514300310972, 'reg_lambda': 9.434691858844593, 'gamma': 3.19198370845212}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:23,139] Trial 463 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.15857513381070473, 'n_estimators': 468, 'subsample': 0.5834375356385412, 'colsample_bytree': 0.9649477085801895, 'reg_alpha': 5.882636104913988, 'reg_lambda': 9.499113162682075, 'gamma': 3.2216449507268985}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:23,580] Trial 464 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.1685697751125124, 'n_estimators': 467, 'subsample': 0.5779437467757638, 'colsample_bytree': 0.9298663144393302, 'reg_alpha': 6.217965702790504, 'reg_lambda': 9.99909179090395, 'gamma': 3.1136215395654205}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:23,946] Trial 465 finished with value: 0.716 and parameters: {'max_depth': 5, 'learning_rate': 0.14879764056921135, 'n_estimators': 422, 'subsample': 0.5905843259048212, 'colsample_bytree': 0.9857671924619502, 'reg_alpha': 5.803929078282944, 'reg_lambda': 9.654109085212495, 'gamma': 4.963231681469168}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:24,303] Trial 466 finished with value: 0.7156 and parameters: {'max_depth': 5, 'learning_rate': 0.15176464909782145, 'n_estimators': 449, 'subsample': 0.776179165227403, 'colsample_bytree': 0.9546594510854347, 'reg_alpha': 6.36479546815556, 'reg_lambda': 9.435790983251817, 'gamma': 3.4045448983591546}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:24,695] Trial 467 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.12156383439897661, 'n_estimators': 474, 'subsample': 0.5718382010422676, 'colsample_bytree': 0.9745608531508273, 'reg_alpha': 6.016038805561514, 'reg_lambda': 9.805645371714409, 'gamma': 3.3053948200140395}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:25,168] Trial 468 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.11085826531656336, 'n_estimators': 493, 'subsample': 0.558867669589615, 'colsample_bytree': 0.9991441684583591, 'reg_alpha': 6.6451666131011295, 'reg_lambda': 9.238914892161098, 'gamma': 3.1939806203839685}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:25,585] Trial 469 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.1555220084815055, 'n_estimators': 480, 'subsample': 0.566072398670855, 'colsample_bytree': 0.9452437516704847, 'reg_alpha': 5.672365941790496, 'reg_lambda': 9.56676813754618, 'gamma': 3.0287617963919726}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:25,972] Trial 470 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.11616155899101786, 'n_estimators': 451, 'subsample': 0.5723450043772451, 'colsample_bytree': 0.937207243466864, 'reg_alpha': 5.600165826758452, 'reg_lambda': 9.607337322632137, 'gamma': 3.0824601749540697}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:26,375] Trial 471 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.16512660310203464, 'n_estimators': 485, 'subsample': 0.5830435371996948, 'colsample_bytree': 0.9430105994640349, 'reg_alpha': 6.151955206865006, 'reg_lambda': 9.833588919106258, 'gamma': 3.0251269820116797}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:26,776] Trial 472 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.1579195211268119, 'n_estimators': 502, 'subsample': 0.5986164468211902, 'colsample_bytree': 0.9299892762725254, 'reg_alpha': 5.287066594191138, 'reg_lambda': 9.49840124661618, 'gamma': 3.167474061468212}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:27,200] Trial 473 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.15344772403911272, 'n_estimators': 476, 'subsample': 0.5656939477357208, 'colsample_bytree': 0.9111158907873543, 'reg_alpha': 5.824254944419551, 'reg_lambda': 9.704797120211273, 'gamma': 2.998391953611515}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:27,610] Trial 474 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.1620158887558607, 'n_estimators': 509, 'subsample': 0.5723426515817208, 'colsample_bytree': 0.9477450001382225, 'reg_alpha': 6.417090888811316, 'reg_lambda': 9.399441057383422, 'gamma': 3.2953002985843707}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:28,027] Trial 475 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.12908251430414927, 'n_estimators': 463, 'subsample': 0.5569519732658617, 'colsample_bytree': 0.9581081750756274, 'reg_alpha': 5.501429365927343, 'reg_lambda': 9.827690351689228, 'gamma': 3.103788911307323}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:28,402] Trial 476 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.13535075084769843, 'n_estimators': 431, 'subsample': 0.5612944419378466, 'colsample_bytree': 0.9244106809914561, 'reg_alpha': 5.040873609387232, 'reg_lambda': 9.996153378633617, 'gamma': 2.942196248949678}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:28,827] Trial 477 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.1044883463106861, 'n_estimators': 490, 'subsample': 0.578844572039726, 'colsample_bytree': 0.9454052596350785, 'reg_alpha': 5.936854610514854, 'reg_lambda': 9.583645889467615, 'gamma': 3.17102380191188}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:29,354] Trial 478 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.12229696465135785, 'n_estimators': 522, 'subsample': 0.5652029819997608, 'colsample_bytree': 0.9348653353650133, 'reg_alpha': 5.670501115454569, 'reg_lambda': 9.325580168947235, 'gamma': 3.353114291917909}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:29,775] Trial 479 finished with value: 0.718 and parameters: {'max_depth': 5, 'learning_rate': 0.12022704712854042, 'n_estimators': 520, 'subsample': 0.5892733046394246, 'colsample_bytree': 0.9373710880704417, 'reg_alpha': 5.20920808284158, 'reg_lambda': 9.389922813484176, 'gamma': 3.476435841225508}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:30,198] Trial 480 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.19328192401860617, 'n_estimators': 539, 'subsample': 0.5690290515052076, 'colsample_bytree': 0.8469124775286427, 'reg_alpha': 5.6705655061771765, 'reg_lambda': 9.242166936837558, 'gamma': 3.615143714804938}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:30,625] Trial 481 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.12311242598714157, 'n_estimators': 519, 'subsample': 0.5552334014131862, 'colsample_bytree': 0.9118764721554992, 'reg_alpha': 5.342531161270884, 'reg_lambda': 9.611723655611504, 'gamma': 3.3194027704358096}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:31,060] Trial 482 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.11541120297801383, 'n_estimators': 556, 'subsample': 0.5757553665174738, 'colsample_bytree': 0.9244014529362572, 'reg_alpha': 5.57634344837278, 'reg_lambda': 9.297234648291026, 'gamma': 3.1961738648348983}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:31,667] Trial 483 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.130054388830661, 'n_estimators': 722, 'subsample': 0.5631554345780901, 'colsample_bytree': 0.9379567465472004, 'reg_alpha': 0.724140517602673, 'reg_lambda': 9.067490549099112, 'gamma': 3.4538945252463713}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:32,211] Trial 484 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.1293427647739483, 'n_estimators': 754, 'subsample': 0.5528886623527011, 'colsample_bytree': 0.9543380561044701, 'reg_alpha': 7.173848337750432, 'reg_lambda': 9.462124408135223, 'gamma': 3.3765985723414804}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:32,632] Trial 485 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.12419602245211636, 'n_estimators': 536, 'subsample': 0.5826740113915648, 'colsample_bytree': 0.9455987943668187, 'reg_alpha': 6.7945546503889185, 'reg_lambda': 9.797832871439688, 'gamma': 3.3135971945963387}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:33,059] Trial 486 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.13459826730081745, 'n_estimators': 500, 'subsample': 0.5624075345963091, 'colsample_bytree': 0.9199865334890946, 'reg_alpha': 5.734322781126123, 'reg_lambda': 9.660439305348632, 'gamma': 3.2319730785960363}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:33,439] Trial 487 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.16799472903396986, 'n_estimators': 479, 'subsample': 0.5487020571280965, 'colsample_bytree': 0.9326758303768277, 'reg_alpha': 8.963445406462542, 'reg_lambda': 9.171010812488825, 'gamma': 3.023464565150242}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:33,901] Trial 488 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.14037592862847764, 'n_estimators': 590, 'subsample': 0.5707170750387147, 'colsample_bytree': 0.9624576850810349, 'reg_alpha': 6.013667612156633, 'reg_lambda': 9.424492793081221, 'gamma': 3.0765491040444375}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:34,402] Trial 489 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11329245076108624, 'n_estimators': 642, 'subsample': 0.6038512891118373, 'colsample_bytree': 0.9528712541777747, 'reg_alpha': 6.261849313279947, 'reg_lambda': 9.99780514137526, 'gamma': 2.910608457893017}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:34,786] Trial 490 finished with value: 0.7192 and parameters: {'max_depth': 6, 'learning_rate': 0.15625248378641246, 'n_estimators': 450, 'subsample': 0.5568935272357315, 'colsample_bytree': 0.9657699426245897, 'reg_alpha': 5.410659626678254, 'reg_lambda': 9.029738491408239, 'gamma': 3.360475212273702}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:35,223] Trial 491 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.11934390182546052, 'n_estimators': 520, 'subsample': 0.5443459677965059, 'colsample_bytree': 0.9887705089109843, 'reg_alpha': 4.903223709042436, 'reg_lambda': 9.577315657816394, 'gamma': 3.1369873835965465}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:35,512] Trial 492 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.1447181192501283, 'n_estimators': 294, 'subsample': 0.5657911050638372, 'colsample_bytree': 0.9292891390517067, 'reg_alpha': 5.7919378028657045, 'reg_lambda': 9.800391523821142, 'gamma': 3.2504385372592943}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:35,968] Trial 493 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.1263018328428109, 'n_estimators': 569, 'subsample': 0.5469285477525847, 'colsample_bytree': 0.9742327880913814, 'reg_alpha': 6.513883918921562, 'reg_lambda': 9.275955649252035, 'gamma': 3.0004595200857382}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:36,400] Trial 494 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.17561673306974812, 'n_estimators': 558, 'subsample': 0.5785458457915087, 'colsample_bytree': 0.972182501802129, 'reg_alpha': 6.571848539474968, 'reg_lambda': 9.349143101656106, 'gamma': 3.07601478041237}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:36,859] Trial 495 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.12676608131343078, 'n_estimators': 577, 'subsample': 0.5548505275320302, 'colsample_bytree': 0.959614744087523, 'reg_alpha': 6.842721510341015, 'reg_lambda': 9.692242945446633, 'gamma': 3.4191331179588027}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:37,390] Trial 496 finished with value: 0.7264 and parameters: {'max_depth': 6, 'learning_rate': 0.14161152812955982, 'n_estimators': 551, 'subsample': 0.5655176842122583, 'colsample_bytree': 0.9513384303933451, 'reg_alpha': 7.038112877224496, 'reg_lambda': 9.515012025377963, 'gamma': 2.996681092167137}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:37,840] Trial 497 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.1335887089546146, 'n_estimators': 568, 'subsample': 0.5427857694057533, 'colsample_bytree': 0.9668574048726917, 'reg_alpha': 6.44996192806239, 'reg_lambda': 9.81976227472852, 'gamma': 3.28113020509222}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:38,279] Trial 498 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.1519928423467985, 'n_estimators': 532, 'subsample': 0.5933301447466368, 'colsample_bytree': 0.9466030322988415, 'reg_alpha': 6.584590879299595, 'reg_lambda': 9.01736996578963, 'gamma': 3.178069142573973}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:38,544] Trial 499 finished with value: 0.7172 and parameters: {'max_depth': 5, 'learning_rate': 0.16174198378690618, 'n_estimators': 265, 'subsample': 0.5537449565742252, 'colsample_bytree': 0.9769054078466849, 'reg_alpha': 6.214283726488331, 'reg_lambda': 9.248787686653909, 'gamma': 3.5508667240049974}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:39,015] Trial 500 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.13552943598344394, 'n_estimators': 605, 'subsample': 0.5735698441930933, 'colsample_bytree': 0.9379482110887756, 'reg_alpha': 6.7329266818136, 'reg_lambda': 9.508206862088889, 'gamma': 3.0275410761029855}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:39,434] Trial 501 finished with value: 0.722 and parameters: {'max_depth': 6, 'learning_rate': 0.12625103557807735, 'n_estimators': 500, 'subsample': 0.539532658563463, 'colsample_bytree': 0.9034127748662865, 'reg_alpha': 6.422206064067537, 'reg_lambda': 8.896908149452834, 'gamma': 3.7580418704054415}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:39,887] Trial 502 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.14028573855111068, 'n_estimators': 542, 'subsample': 0.5614043391836148, 'colsample_bytree': 0.9598125080130432, 'reg_alpha': 6.2158123614666305, 'reg_lambda': 9.816933459176248, 'gamma': 3.1304572726842794}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:40,361] Trial 503 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.14760738732537748, 'n_estimators': 555, 'subsample': 0.5504145127208241, 'colsample_bytree': 0.9662786509790443, 'reg_alpha': 6.051726914670231, 'reg_lambda': 9.844517519479616, 'gamma': 2.9344842121171553}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:40,869] Trial 504 finished with value: 0.722 and parameters: {'max_depth': 7, 'learning_rate': 0.14133629140577783, 'n_estimators': 572, 'subsample': 0.5597755706401673, 'colsample_bytree': 0.9590293873146783, 'reg_alpha': 6.142687094265066, 'reg_lambda': 9.830047604051607, 'gamma': 3.075449187937089}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:41,336] Trial 505 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.15571054404082904, 'n_estimators': 536, 'subsample': 0.5324289958661569, 'colsample_bytree': 0.9772573971526161, 'reg_alpha': 5.896550359182705, 'reg_lambda': 9.988707459171488, 'gamma': 3.2574641104325104}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:41,824] Trial 506 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.14486815902419506, 'n_estimators': 542, 'subsample': 0.5445477693328667, 'colsample_bytree': 0.9682333742083813, 'reg_alpha': 6.434741308269708, 'reg_lambda': 9.35705182455688, 'gamma': 2.8462379755242684}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:42,353] Trial 507 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.1526239840016042, 'n_estimators': 514, 'subsample': 0.5278115691861336, 'colsample_bytree': 0.9560587630764471, 'reg_alpha': 6.016042640338615, 'reg_lambda': 9.153301513590321, 'gamma': 2.9972551210157126}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:42,849] Trial 508 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.13925872388821497, 'n_estimators': 586, 'subsample': 0.5608236782120681, 'colsample_bytree': 0.9817520767969838, 'reg_alpha': 5.716197367394083, 'reg_lambda': 9.536787291273289, 'gamma': 3.148381080054329}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:43,311] Trial 509 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.162304298414132, 'n_estimators': 539, 'subsample': 0.5476218689608064, 'colsample_bytree': 0.9504004627260447, 'reg_alpha': 6.617687796208245, 'reg_lambda': 9.690458789312201, 'gamma': 2.9277519037877546}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:43,782] Trial 510 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.16940705050945162, 'n_estimators': 550, 'subsample': 0.5143270783124656, 'colsample_bytree': 0.9688114545944845, 'reg_alpha': 6.211285493959298, 'reg_lambda': 8.69720889717631, 'gamma': 3.409142216614247}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:44,246] Trial 511 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.15118548765291878, 'n_estimators': 523, 'subsample': 0.5369546692550315, 'colsample_bytree': 0.9814614584479658, 'reg_alpha': 5.86023627781398, 'reg_lambda': 9.381857303821572, 'gamma': 3.246793028686561}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:44,684] Trial 512 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.13633653331342793, 'n_estimators': 480, 'subsample': 0.5555740254557248, 'colsample_bytree': 0.9613198312179841, 'reg_alpha': 4.700990948408571, 'reg_lambda': 9.054068667729066, 'gamma': 3.0516565068879364}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:44,887] Trial 513 finished with value: 0.7228 and parameters: {'max_depth': 8, 'learning_rate': 0.14751195930701036, 'n_estimators': 100, 'subsample': 0.5636499838649782, 'colsample_bytree': 0.9742982102456662, 'reg_alpha': 5.608707819557898, 'reg_lambda': 9.643688396887999, 'gamma': 2.860573583210476}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:45,338] Trial 514 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.10912916254122065, 'n_estimators': 517, 'subsample': 0.5245040308045017, 'colsample_bytree': 0.9441581867239119, 'reg_alpha': 6.051907613592119, 'reg_lambda': 9.999934808629426, 'gamma': 3.1294275101669586}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:45,811] Trial 515 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.15748023683808463, 'n_estimators': 575, 'subsample': 0.5814663072016288, 'colsample_bytree': 0.9582008084967322, 'reg_alpha': 6.966452843268604, 'reg_lambda': 8.829799428468169, 'gamma': 2.9585596310006643}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:46,015] Trial 516 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.12984012546275547, 'n_estimators': 119, 'subsample': 0.5398470547672647, 'colsample_bytree': 0.9857558218631244, 'reg_alpha': 5.928234531447607, 'reg_lambda': 9.233022200711623, 'gamma': 2.767492838443909}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:46,502] Trial 517 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.13940163279259885, 'n_estimators': 462, 'subsample': 0.5506517227242497, 'colsample_bytree': 0.972598132044705, 'reg_alpha': 6.356485732124519, 'reg_lambda': 9.822706351182573, 'gamma': 3.318546065937298}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:46,956] Trial 518 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.12519725782194838, 'n_estimators': 531, 'subsample': 0.56250779267558, 'colsample_bytree': 0.7017480781316834, 'reg_alpha': 5.487868987879507, 'reg_lambda': 9.462423959307351, 'gamma': 3.103079817065641}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:47,429] Trial 519 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.14742393232533743, 'n_estimators': 560, 'subsample': 0.5492938982147114, 'colsample_bytree': 0.7655675800077476, 'reg_alpha': 5.668415800968562, 'reg_lambda': 9.706763730721661, 'gamma': 3.5207787594426163}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:47,862] Trial 520 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13269398597777443, 'n_estimators': 496, 'subsample': 0.5720608082819899, 'colsample_bytree': 0.9484054933030469, 'reg_alpha': 4.259267027288174, 'reg_lambda': 9.12131333312522, 'gamma': 3.2109054926829654}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:48,280] Trial 521 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.15885423030083903, 'n_estimators': 505, 'subsample': 0.5335366760069008, 'colsample_bytree': 0.9628012568559171, 'reg_alpha': 6.195603169790158, 'reg_lambda': 9.339143568162706, 'gamma': 2.9801027794329853}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:48,670] Trial 522 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.12026372631830434, 'n_estimators': 438, 'subsample': 0.5095920063716195, 'colsample_bytree': 0.9887079892777666, 'reg_alpha': 5.927606670178473, 'reg_lambda': 9.5436366845789, 'gamma': 2.845350182671492}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:49,034] Trial 523 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.144452223686231, 'n_estimators': 414, 'subsample': 0.543597556377571, 'colsample_bytree': 0.9399249714402144, 'reg_alpha': 5.238797459899199, 'reg_lambda': 8.939508508879836, 'gamma': 3.392377875107926}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:49,409] Trial 524 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.1437018040961788, 'n_estimators': 414, 'subsample': 0.5284362309367173, 'colsample_bytree': 0.9358039127686807, 'reg_alpha': 5.146155938757345, 'reg_lambda': 8.531756634056258, 'gamma': 3.369656861526228}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:49,761] Trial 525 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.13923550833659104, 'n_estimators': 409, 'subsample': 0.5417763660043287, 'colsample_bytree': 0.9429163125707941, 'reg_alpha': 5.007942018773997, 'reg_lambda': 8.824071387238803, 'gamma': 3.444925611824463}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:50,132] Trial 526 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.15021341010442243, 'n_estimators': 430, 'subsample': 0.5184668015468318, 'colsample_bytree': 0.9403286367766044, 'reg_alpha': 5.441732862886902, 'reg_lambda': 8.36819020664683, 'gamma': 3.667347148997662}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:50,532] Trial 527 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.14427616006549215, 'n_estimators': 464, 'subsample': 0.8281293453238943, 'colsample_bytree': 0.9324686991137555, 'reg_alpha': 5.184233876451124, 'reg_lambda': 8.692137382222457, 'gamma': 3.5525736238937773}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:50,922] Trial 528 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.15227917240117356, 'n_estimators': 456, 'subsample': 0.5414395799812329, 'colsample_bytree': 0.9167755460929972, 'reg_alpha': 4.87038590989321, 'reg_lambda': 8.957847171759774, 'gamma': 3.3784046608345673}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:51,339] Trial 529 finished with value: 0.7232 and parameters: {'max_depth': 7, 'learning_rate': 0.13562775644834243, 'n_estimators': 487, 'subsample': 0.5275249455629505, 'colsample_bytree': 0.9494312084644947, 'reg_alpha': 5.519975387051852, 'reg_lambda': 8.99580104580502, 'gamma': 3.258614943918249}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:51,702] Trial 530 finished with value: 0.7204 and parameters: {'max_depth': 5, 'learning_rate': 0.16377280144875211, 'n_estimators': 447, 'subsample': 0.5533050245849491, 'colsample_bytree': 0.7968049296005084, 'reg_alpha': 7.751526456343455, 'reg_lambda': 9.182224022163103, 'gamma': 3.2680859538594156}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:52,105] Trial 531 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.12937168732680462, 'n_estimators': 475, 'subsample': 0.5397856640868468, 'colsample_bytree': 0.9270676209722067, 'reg_alpha': 5.217160833667402, 'reg_lambda': 8.796583356793127, 'gamma': 3.4443259641220716}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:52,536] Trial 532 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.1553154326665113, 'n_estimators': 514, 'subsample': 0.5619907607667135, 'colsample_bytree': 0.8566974835194449, 'reg_alpha': 5.32484883421432, 'reg_lambda': 9.812815007255207, 'gamma': 3.157629452841084}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:52,840] Trial 533 finished with value: 0.7224 and parameters: {'max_depth': 6, 'learning_rate': 0.14209992144818578, 'n_estimators': 326, 'subsample': 0.5731024807730726, 'colsample_bytree': 0.9539890735315224, 'reg_alpha': 5.753947578582931, 'reg_lambda': 8.99625625518944, 'gamma': 3.3442722548089425}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:53,237] Trial 534 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.1717173782019576, 'n_estimators': 441, 'subsample': 0.5481482011542786, 'colsample_bytree': 0.9794177940301416, 'reg_alpha': 4.620258977829368, 'reg_lambda': 9.669424004127546, 'gamma': 2.703095813378}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:53,430] Trial 535 finished with value: 0.7144 and parameters: {'max_depth': 5, 'learning_rate': 0.13598299315511653, 'n_estimators': 128, 'subsample': 0.5847783316118668, 'colsample_bytree': 0.9378666378266777, 'reg_alpha': 7.331283262761923, 'reg_lambda': 9.833740957856866, 'gamma': 3.4776545858598498}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:53,727] Trial 536 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.12318350889428678, 'n_estimators': 240, 'subsample': 0.532014375180481, 'colsample_bytree': 0.9566971552935905, 'reg_alpha': 5.6651931240680895, 'reg_lambda': 9.983847810008221, 'gamma': 3.193612485812156}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:54,175] Trial 537 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.14780626480525497, 'n_estimators': 545, 'subsample': 0.5561757192574954, 'colsample_bytree': 0.988015983676767, 'reg_alpha': 5.546889131831894, 'reg_lambda': 9.242634846417701, 'gamma': 3.047134892178207}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:54,592] Trial 538 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11336651687419876, 'n_estimators': 486, 'subsample': 0.6225986718866038, 'colsample_bytree': 0.9464153873909599, 'reg_alpha': 5.274158959330229, 'reg_lambda': 9.535625526702658, 'gamma': 3.300958585097402}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:55,032] Trial 539 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.1312446842253848, 'n_estimators': 528, 'subsample': 0.5204607671511341, 'colsample_bytree': 0.8242575679486795, 'reg_alpha': 5.013957294740125, 'reg_lambda': 8.595847727718661, 'gamma': 3.119380423840213}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:55,420] Trial 540 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.15716688733676012, 'n_estimators': 467, 'subsample': 0.567898453606557, 'colsample_bytree': 0.9669614955247517, 'reg_alpha': 4.033848051647757, 'reg_lambda': 9.116453325442052, 'gamma': 3.6009450281050492}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:55,622] Trial 541 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.13841949474879028, 'n_estimators': 143, 'subsample': 0.5441293045713931, 'colsample_bytree': 0.960171587617792, 'reg_alpha': 5.815235198029265, 'reg_lambda': 9.432526744859207, 'gamma': 2.7937767989552618}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:56,100] Trial 542 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.14406668000276002, 'n_estimators': 595, 'subsample': 0.5345200353514713, 'colsample_bytree': 0.9178924724582889, 'reg_alpha': 5.972927403458871, 'reg_lambda': 8.847897147906933, 'gamma': 2.8877571065832943}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:56,452] Trial 543 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.16419186577543304, 'n_estimators': 398, 'subsample': 0.5524751181753775, 'colsample_bytree': 0.9788872052846281, 'reg_alpha': 5.5015976409344605, 'reg_lambda': 9.691767603419892, 'gamma': 4.501606200539301}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:56,894] Trial 544 finished with value: 0.726 and parameters: {'max_depth': 6, 'learning_rate': 0.12549262519847068, 'n_estimators': 499, 'subsample': 0.5017737965127297, 'colsample_bytree': 0.8836392592052412, 'reg_alpha': 4.724174838489441, 'reg_lambda': 9.433497540939278, 'gamma': 3.1982881635857323}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:57,222] Trial 545 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.1505149251886643, 'n_estimators': 277, 'subsample': 0.564115061788399, 'colsample_bytree': 0.992283660941487, 'reg_alpha': 5.771927271467053, 'reg_lambda': 9.995794861449836, 'gamma': 3.0697122871051303}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:57,663] Trial 546 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.11843423235077738, 'n_estimators': 519, 'subsample': 0.5444414709169947, 'colsample_bytree': 0.9265777121607003, 'reg_alpha': 6.105699298305357, 'reg_lambda': 7.206152235198832, 'gamma': 3.3946094633030115}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:58,112] Trial 547 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.11690089376305011, 'n_estimators': 519, 'subsample': 0.525272951230545, 'colsample_bytree': 0.9345632777961878, 'reg_alpha': 6.202579360699068, 'reg_lambda': 8.543675903074003, 'gamma': 3.3933702186132044}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:58,565] Trial 548 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.11307766285861767, 'n_estimators': 539, 'subsample': 0.5368069432875449, 'colsample_bytree': 0.9496577339073664, 'reg_alpha': 6.0937729434786085, 'reg_lambda': 7.183185737195286, 'gamma': 3.5100575437487596}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:59,015] Trial 549 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.1077464042685865, 'n_estimators': 505, 'subsample': 0.5451940384059399, 'colsample_bytree': 0.7528324356979478, 'reg_alpha': 4.428073611659757, 'reg_lambda': 9.764748720499737, 'gamma': 3.3902397644026667}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:59,523] Trial 550 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.12048340992986896, 'n_estimators': 567, 'subsample': 0.5099559205200477, 'colsample_bytree': 0.9696161912615445, 'reg_alpha': 6.292722487059345, 'reg_lambda': 8.241496913409781, 'gamma': 3.6226646802265003}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:51:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:51:59,913] Trial 551 finished with value: 0.7124 and parameters: {'max_depth': 5, 'learning_rate': 0.12547904500648352, 'n_estimators': 484, 'subsample': 0.9452040605755779, 'colsample_bytree': 0.9244968118612368, 'reg_alpha': 6.042426820620885, 'reg_lambda': 6.7937977684343895, 'gamma': 3.4724635608555015}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:00,402] Trial 552 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.13098397854389693, 'n_estimators': 551, 'subsample': 0.53417316023423, 'colsample_bytree': 0.7804781448582027, 'reg_alpha': 5.910895948189728, 'reg_lambda': 7.063353002297035, 'gamma': 3.2976354777891372}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:00,842] Trial 553 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.12289342673305026, 'n_estimators': 525, 'subsample': 0.5440201134388937, 'colsample_bytree': 0.9758732889085479, 'reg_alpha': 6.400805801628125, 'reg_lambda': 7.834213605355323, 'gamma': 3.3408748300800966}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:01,297] Trial 554 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.11731824704819654, 'n_estimators': 507, 'subsample': 0.5220544026192709, 'colsample_bytree': 0.9551250481813957, 'reg_alpha': 4.8964214522643585, 'reg_lambda': 7.358819648862372, 'gamma': 3.2251175362196682}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:01,684] Trial 555 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13366598907056967, 'n_estimators': 425, 'subsample': 0.5527114770147435, 'colsample_bytree': 0.9429693460110267, 'reg_alpha': 5.364429469592908, 'reg_lambda': 8.05778843657205, 'gamma': 3.455406341858098}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:02,165] Trial 556 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.11246424136373818, 'n_estimators': 471, 'subsample': 0.538031810415978, 'colsample_bytree': 0.9900554358375754, 'reg_alpha': 6.162882522913994, 'reg_lambda': 8.708592437516698, 'gamma': 3.2983922996304726}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:02,630] Trial 557 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.10618951277634034, 'n_estimators': 532, 'subsample': 0.5518901159172063, 'colsample_bytree': 0.9638192489462548, 'reg_alpha': 5.860120218872148, 'reg_lambda': 8.432785480798234, 'gamma': 3.192638310526907}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:03,048] Trial 558 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.12827602517520595, 'n_estimators': 488, 'subsample': 0.5278093743167017, 'colsample_bytree': 0.9814935841421174, 'reg_alpha': 5.635437106955374, 'reg_lambda': 9.835140930423373, 'gamma': 3.1066978512979695}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:03,511] Trial 559 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.13970593733861406, 'n_estimators': 509, 'subsample': 0.5582342697868093, 'colsample_bytree': 0.9998347913240295, 'reg_alpha': 5.114733740678462, 'reg_lambda': 9.642218853681362, 'gamma': 3.2804286214784444}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:03,941] Trial 560 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.2668617705324348, 'n_estimators': 552, 'subsample': 0.5453603651593424, 'colsample_bytree': 0.9369463067749082, 'reg_alpha': 6.043175869222894, 'reg_lambda': 9.148857819787981, 'gamma': 3.1786409431382294}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:04,307] Trial 561 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.1177463984183987, 'n_estimators': 451, 'subsample': 0.535501937241674, 'colsample_bytree': 0.9688692870325071, 'reg_alpha': 6.369604231255871, 'reg_lambda': 7.688487591385522, 'gamma': 3.5291741305574273}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:04,744] Trial 562 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.1345024493547471, 'n_estimators': 518, 'subsample': 0.5178257423878955, 'colsample_bytree': 0.9517430594700138, 'reg_alpha': 5.583475852419858, 'reg_lambda': 7.505358412201553, 'gamma': 3.404687073621737}. Best is trial 232 with value: 0.73.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:05,154] Trial 563 finished with value: 0.7312 and parameters: {'max_depth': 5, 'learning_rate': 0.1357494228418595, 'n_estimators': 523, 'subsample': 0.5113919768026095, 'colsample_bytree': 0.9490066382621876, 'reg_alpha': 5.296781481718319, 'reg_lambda': 7.906003422711987, 'gamma': 3.729600106104718}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:05,553] Trial 564 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12432841895918288, 'n_estimators': 520, 'subsample': 0.5076781093037405, 'colsample_bytree': 0.9282733291874188, 'reg_alpha': 5.254419912105469, 'reg_lambda': 8.187927834299142, 'gamma': 4.035592639188531}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:05,980] Trial 565 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.13252918914854844, 'n_estimators': 510, 'subsample': 0.507214284408029, 'colsample_bytree': 0.9443503490684301, 'reg_alpha': 5.313590703134621, 'reg_lambda': 7.505018272408274, 'gamma': 3.4912049784159125}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:06,379] Trial 566 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.12918532647959924, 'n_estimators': 491, 'subsample': 0.5143113983112279, 'colsample_bytree': 0.949253699860505, 'reg_alpha': 1.8799701283831673, 'reg_lambda': 7.597868432502881, 'gamma': 4.245777484645672}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:06,829] Trial 567 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.11978677790088721, 'n_estimators': 525, 'subsample': 0.5015416179623452, 'colsample_bytree': 0.9333951961062164, 'reg_alpha': 5.004578044082594, 'reg_lambda': 7.288708628725584, 'gamma': 3.6225098570921723}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:07,219] Trial 568 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.11068071969805768, 'n_estimators': 475, 'subsample': 0.5177700906193992, 'colsample_bytree': 0.942057140303835, 'reg_alpha': 4.806828494918009, 'reg_lambda': 7.7291942936158975, 'gamma': 3.7237952974713915}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:07,614] Trial 569 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.13612410877929043, 'n_estimators': 498, 'subsample': 0.518967702837583, 'colsample_bytree': 0.9529648960594452, 'reg_alpha': 5.4781974239211, 'reg_lambda': 7.520621340338372, 'gamma': 3.5783322352994253}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:08,044] Trial 570 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.14451000284308121, 'n_estimators': 533, 'subsample': 0.5126225271560461, 'colsample_bytree': 0.911758564463134, 'reg_alpha': 5.224960343632494, 'reg_lambda': 7.747002950085365, 'gamma': 3.6738597601311787}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:08,446] Trial 571 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.12380454574807373, 'n_estimators': 498, 'subsample': 0.5201568408993603, 'colsample_bytree': 0.9261020087450479, 'reg_alpha': 5.506129097406114, 'reg_lambda': 7.987289629158955, 'gamma': 3.3559259096039025}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:08,845] Trial 572 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11483408206082649, 'n_estimators': 462, 'subsample': 0.5243665349969409, 'colsample_bytree': 0.9408162788140204, 'reg_alpha': 4.580288493111206, 'reg_lambda': 7.854437654242906, 'gamma': 3.7694787229598945}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:09,251] Trial 573 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13621546482423252, 'n_estimators': 517, 'subsample': 0.5001728265361837, 'colsample_bytree': 0.950936305388503, 'reg_alpha': 5.126037094862645, 'reg_lambda': 8.116162031262974, 'gamma': 3.8413086274827126}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:09,651] Trial 574 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.12783956209899563, 'n_estimators': 480, 'subsample': 0.5170804106015909, 'colsample_bytree': 0.9583387135687562, 'reg_alpha': 5.382625755238251, 'reg_lambda': 7.99374352803613, 'gamma': 4.077701373000549}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:10,062] Trial 575 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.14645503078699834, 'n_estimators': 508, 'subsample': 0.5294280851849678, 'colsample_bytree': 0.9344087469108153, 'reg_alpha': 5.620509399599535, 'reg_lambda': 7.17848211239784, 'gamma': 3.435232195635851}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:10,487] Trial 576 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10560416185398706, 'n_estimators': 528, 'subsample': 0.5100423992594812, 'colsample_bytree': 0.9231413692647981, 'reg_alpha': 4.822505010347013, 'reg_lambda': 7.3560963095509, 'gamma': 3.3864039758933924}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:10,931] Trial 577 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.13234751374089615, 'n_estimators': 548, 'subsample': 0.5270555802459586, 'colsample_bytree': 0.9488334920341693, 'reg_alpha': 5.1063957862946605, 'reg_lambda': 9.363745405391125, 'gamma': 3.785805938216679}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:11,318] Trial 578 finished with value: 0.7148 and parameters: {'max_depth': 5, 'learning_rate': 0.1404727706645543, 'n_estimators': 489, 'subsample': 0.8894551656193612, 'colsample_bytree': 0.9594126331428133, 'reg_alpha': 5.456882855436105, 'reg_lambda': 7.497142758689472, 'gamma': 3.597312813632913}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:11,777] Trial 579 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.12337465668854383, 'n_estimators': 572, 'subsample': 0.5302198497869265, 'colsample_bytree': 0.9681454971195369, 'reg_alpha': 5.688726103424668, 'reg_lambda': 7.839974390538588, 'gamma': 3.3750376045144224}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:12,194] Trial 580 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.15161139425238604, 'n_estimators': 437, 'subsample': 0.5174142131418739, 'colsample_bytree': 0.8956175872125662, 'reg_alpha': 4.987134987233952, 'reg_lambda': 6.97871951894302, 'gamma': 3.2740696540412597}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:12,580] Trial 581 finished with value: 0.7264 and parameters: {'max_depth': 6, 'learning_rate': 0.11744922115073625, 'n_estimators': 470, 'subsample': 0.5390282268907306, 'colsample_bytree': 0.9415338547631011, 'reg_alpha': 5.2808654198151785, 'reg_lambda': 7.984529204439664, 'gamma': 3.8680169741422628}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:12,926] Trial 582 finished with value: 0.7152 and parameters: {'max_depth': 7, 'learning_rate': 0.1364183779350973, 'n_estimators': 370, 'subsample': 0.9756709354782991, 'colsample_bytree': 0.9535008811026449, 'reg_alpha': 7.981029512599732, 'reg_lambda': 7.588104114560955, 'gamma': 3.5129380447329672}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:13,349] Trial 583 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.12732405511331335, 'n_estimators': 514, 'subsample': 0.5463735048877992, 'colsample_bytree': 0.9693227897171283, 'reg_alpha': 5.674787895507897, 'reg_lambda': 8.337349462583237, 'gamma': 2.9973708621244453}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:13,768] Trial 584 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.1446772127190433, 'n_estimators': 518, 'subsample': 0.513505729457025, 'colsample_bytree': 0.928838794293133, 'reg_alpha': 5.575243077607013, 'reg_lambda': 8.542350518258553, 'gamma': 2.952940979212576}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:14,189] Trial 585 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13169903593308402, 'n_estimators': 502, 'subsample': 0.5304290085213313, 'colsample_bytree': 0.959895252280865, 'reg_alpha': 5.4112249185531365, 'reg_lambda': 8.261256881518223, 'gamma': 3.239906213706596}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:14,506] Trial 586 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.11012114326540881, 'n_estimators': 301, 'subsample': 0.5404189609876772, 'colsample_bytree': 0.9423552520243059, 'reg_alpha': 5.705517737062292, 'reg_lambda': 8.374966880068673, 'gamma': 3.042132223860278}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:14,916] Trial 587 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.15370137826534572, 'n_estimators': 483, 'subsample': 0.5512385763234736, 'colsample_bytree': 0.9660825557970923, 'reg_alpha': 5.573852393581261, 'reg_lambda': 8.15112518971544, 'gamma': 3.406807836860816}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:15,346] Trial 588 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.14116227270450116, 'n_estimators': 502, 'subsample': 0.5240052496523423, 'colsample_bytree': 0.9495329599863469, 'reg_alpha': 5.315517802255989, 'reg_lambda': 8.327675805334088, 'gamma': 3.122410600047385}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:15,731] Trial 589 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.12085844236843488, 'n_estimators': 456, 'subsample': 0.5003744742522329, 'colsample_bytree': 0.910458671665274, 'reg_alpha': 5.685072253180678, 'reg_lambda': 8.050463841094576, 'gamma': 3.6839831917296046}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:16,188] Trial 590 finished with value: 0.7264 and parameters: {'max_depth': 6, 'learning_rate': 0.14698557500487475, 'n_estimators': 519, 'subsample': 0.5355055379305088, 'colsample_bytree': 0.9344120059613833, 'reg_alpha': 5.858107770729994, 'reg_lambda': 7.9036434844875405, 'gamma': 2.7751526963757476}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:16,597] Trial 591 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.12983302492853535, 'n_estimators': 489, 'subsample': 0.5574113711555334, 'colsample_bytree': 0.97474655355306, 'reg_alpha': 5.1271377938614275, 'reg_lambda': 7.784653071084122, 'gamma': 3.3088767854606185}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:17,068] Trial 592 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.17823656814726122, 'n_estimators': 541, 'subsample': 0.5434079941874496, 'colsample_bytree': 0.9561602248738919, 'reg_alpha': 5.5073139849821064, 'reg_lambda': 8.26814636218096, 'gamma': 2.907507761169243}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:17,474] Trial 593 finished with value: 0.72 and parameters: {'max_depth': 6, 'learning_rate': 0.10329765273767669, 'n_estimators': 471, 'subsample': 0.5742300390020334, 'colsample_bytree': 0.7173668470716568, 'reg_alpha': 5.800317976959573, 'reg_lambda': 8.471220903400166, 'gamma': 3.2279662001894516}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:17,932] Trial 594 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.1598189614441652, 'n_estimators': 510, 'subsample': 0.5622404982310731, 'colsample_bytree': 0.9665231143649432, 'reg_alpha': 5.346005451127375, 'reg_lambda': 7.6519410830582615, 'gamma': 3.021101250743736}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:18,460] Trial 595 finished with value: 0.7156 and parameters: {'max_depth': 5, 'learning_rate': 0.13640632646931986, 'n_estimators': 495, 'subsample': 0.5501213975712288, 'colsample_bytree': 0.9219544434370849, 'reg_alpha': 0.042343744899805635, 'reg_lambda': 8.640145986490136, 'gamma': 2.691132898149894}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:18,914] Trial 596 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11566145829749266, 'n_estimators': 525, 'subsample': 0.5247609862975436, 'colsample_bytree': 0.9438429000899771, 'reg_alpha': 4.383009343628872, 'reg_lambda': 8.389170874159182, 'gamma': 4.01265259743375}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:19,343] Trial 597 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.16820377431693492, 'n_estimators': 443, 'subsample': 0.5103550819171211, 'colsample_bytree': 0.9819145677504062, 'reg_alpha': 5.760261641766965, 'reg_lambda': 8.122604669134546, 'gamma': 3.5084313014867865}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:19,725] Trial 598 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.12687690019135045, 'n_estimators': 413, 'subsample': 0.5348106548617064, 'colsample_bytree': 0.9334144977554429, 'reg_alpha': 4.700896739133426, 'reg_lambda': 8.762758406985418, 'gamma': 3.9673395201034305}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:20,185] Trial 599 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.14976216512880494, 'n_estimators': 483, 'subsample': 0.5476983352230004, 'colsample_bytree': 0.6778239215219883, 'reg_alpha': 5.537817941730146, 'reg_lambda': 8.936359989384465, 'gamma': 3.176817454121394}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:20,684] Trial 600 finished with value: 0.7104 and parameters: {'max_depth': 5, 'learning_rate': 0.13943611350986845, 'n_estimators': 345, 'subsample': 0.5648295321032492, 'colsample_bytree': 0.9594931221073586, 'reg_alpha': 4.968130103537113, 'reg_lambda': 7.4843951398053825, 'gamma': 0.3597222874812438}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:21,192] Trial 601 finished with value: 0.7252 and parameters: {'max_depth': 4, 'learning_rate': 0.12207324199874921, 'n_estimators': 532, 'subsample': 0.5790794021470328, 'colsample_bytree': 0.9728176393880648, 'reg_alpha': 5.91749642311724, 'reg_lambda': 9.566797216609483, 'gamma': 3.068844195362126}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:21,668] Trial 602 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.13287190760763898, 'n_estimators': 509, 'subsample': 0.5572400698467519, 'colsample_bytree': 0.9489809235227195, 'reg_alpha': 5.23283178416031, 'reg_lambda': 9.987811936884505, 'gamma': 2.9154556469625947}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:22,059] Trial 603 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.1549259927144888, 'n_estimators': 473, 'subsample': 0.5427730806960425, 'colsample_bytree': 0.9828816762945214, 'reg_alpha': 5.666078843371464, 'reg_lambda': 9.582574621187266, 'gamma': 3.3534536745511336}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:22,432] Trial 604 finished with value: 0.7144 and parameters: {'max_depth': 7, 'learning_rate': 0.1875993465982047, 'n_estimators': 459, 'subsample': 0.5300439946028968, 'colsample_bytree': 0.9632740314755209, 'reg_alpha': 7.550233479129044, 'reg_lambda': 6.146941570761443, 'gamma': 4.368923327841616}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:22,859] Trial 605 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.21753799889971598, 'n_estimators': 511, 'subsample': 0.5204200603756468, 'colsample_bytree': 0.9027190962007307, 'reg_alpha': 5.372969066612648, 'reg_lambda': 8.72011124755156, 'gamma': 3.241690816915982}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:23,311] Trial 606 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.1440232824551525, 'n_estimators': 538, 'subsample': 0.5536701661486808, 'colsample_bytree': 0.9428701187057521, 'reg_alpha': 5.868208172740151, 'reg_lambda': 9.822874026905787, 'gamma': 3.119078240211871}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:23,817] Trial 607 finished with value: 0.7284 and parameters: {'max_depth': 6, 'learning_rate': 0.11132318903748833, 'n_estimators': 505, 'subsample': 0.5380447485956441, 'colsample_bytree': 0.9535536513877797, 'reg_alpha': 5.507242439087951, 'reg_lambda': 7.2860039980256595, 'gamma': 2.7929877188503287}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:24,529] Trial 608 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.10746902876755487, 'n_estimators': 960, 'subsample': 0.5320303672064591, 'colsample_bytree': 0.9354231741109544, 'reg_alpha': 5.068954570553688, 'reg_lambda': 7.161920578588742, 'gamma': 2.7878621192362507}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:25,025] Trial 609 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.11204274910826834, 'n_estimators': 526, 'subsample': 0.511736504403858, 'colsample_bytree': 0.9504702056818318, 'reg_alpha': 5.441020194318303, 'reg_lambda': 6.866780292158049, 'gamma': 2.663117742019539}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:25,535] Trial 610 finished with value: 0.7216 and parameters: {'max_depth': 6, 'learning_rate': 0.11493729186500302, 'n_estimators': 555, 'subsample': 0.5389369060886549, 'colsample_bytree': 0.9196765183883688, 'reg_alpha': 4.187845002451631, 'reg_lambda': 7.482364654009219, 'gamma': 2.808040721205879}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:25,986] Trial 611 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.10545636947969121, 'n_estimators': 501, 'subsample': 0.5242268016050373, 'colsample_bytree': 0.9303148633812749, 'reg_alpha': 5.227001734974703, 'reg_lambda': 7.360788860874439, 'gamma': 2.739086455553621}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:26,284] Trial 612 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.10033285232307773, 'n_estimators': 257, 'subsample': 0.5417944110465782, 'colsample_bytree': 0.9479839214830118, 'reg_alpha': 4.761978063881244, 'reg_lambda': 6.911673814301675, 'gamma': 2.8682694904380446}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:26,743] Trial 613 finished with value: 0.7296 and parameters: {'max_depth': 6, 'learning_rate': 0.11958734027372143, 'n_estimators': 539, 'subsample': 0.5349232588192318, 'colsample_bytree': 0.9561600943669665, 'reg_alpha': 5.546608740935383, 'reg_lambda': 7.264007125951255, 'gamma': 2.8402290735996476}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:27,222] Trial 614 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.1110887766570981, 'n_estimators': 542, 'subsample': 0.5206295197357483, 'colsample_bytree': 0.9390246884704528, 'reg_alpha': 5.590963800464674, 'reg_lambda': 6.659740515029768, 'gamma': 2.6927153360112626}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:27,692] Trial 615 finished with value: 0.7248 and parameters: {'max_depth': 6, 'learning_rate': 0.11849922131155863, 'n_estimators': 526, 'subsample': 0.5084134735916154, 'colsample_bytree': 0.9592913601493483, 'reg_alpha': 5.596812857974905, 'reg_lambda': 6.9309026720684805, 'gamma': 2.9458378509252716}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:28,182] Trial 616 finished with value: 0.7208 and parameters: {'max_depth': 6, 'learning_rate': 0.09915846258247944, 'n_estimators': 548, 'subsample': 0.5283181755904321, 'colsample_bytree': 0.952618271002527, 'reg_alpha': 4.551764543280617, 'reg_lambda': 6.993357563163398, 'gamma': 2.640304592591811}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:28,651] Trial 617 finished with value: 0.7276 and parameters: {'max_depth': 6, 'learning_rate': 0.12627322910618782, 'n_estimators': 515, 'subsample': 0.5311824817771655, 'colsample_bytree': 0.9403627725655217, 'reg_alpha': 5.036141085280541, 'reg_lambda': 7.226373548607356, 'gamma': 2.8166842790555857}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:29,090] Trial 618 finished with value: 0.718 and parameters: {'max_depth': 6, 'learning_rate': 0.10916103801819348, 'n_estimators': 535, 'subsample': 0.5147704766966967, 'colsample_bytree': 0.7355521859740473, 'reg_alpha': 8.373486654671364, 'reg_lambda': 7.668055691007665, 'gamma': 2.925863425931879}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:29,660] Trial 619 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.019748047467993246, 'n_estimators': 506, 'subsample': 0.5355994020058423, 'colsample_bytree': 0.9558038994199977, 'reg_alpha': 5.293908745169004, 'reg_lambda': 7.3677011565906625, 'gamma': 2.7702361456492492}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:30,085] Trial 620 finished with value: 0.726 and parameters: {'max_depth': 6, 'learning_rate': 0.12179933028726074, 'n_estimators': 497, 'subsample': 0.5406751391948876, 'colsample_bytree': 0.9272522615325695, 'reg_alpha': 5.717060882594977, 'reg_lambda': 7.502160124394746, 'gamma': 3.0011423973672815}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:30,530] Trial 621 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.13038153032204972, 'n_estimators': 525, 'subsample': 0.521114734960591, 'colsample_bytree': 0.9444373481987964, 'reg_alpha': 5.458655087620225, 'reg_lambda': 7.142914530507708, 'gamma': 3.477144936366613}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:30,974] Trial 622 finished with value: 0.7248 and parameters: {'max_depth': 6, 'learning_rate': 0.11707255914363969, 'n_estimators': 547, 'subsample': 0.5477425438198515, 'colsample_bytree': 0.9517564027878572, 'reg_alpha': 5.995712067867504, 'reg_lambda': 7.382049381772402, 'gamma': 4.175150647548926}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:31,487] Trial 623 finished with value: 0.7248 and parameters: {'max_depth': 6, 'learning_rate': 0.1261111301393236, 'n_estimators': 491, 'subsample': 0.5344331649106878, 'colsample_bytree': 0.9354293476954135, 'reg_alpha': 4.874472511649879, 'reg_lambda': 7.239313621169173, 'gamma': 2.611163751761569}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:31,946] Trial 624 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.134271602440058, 'n_estimators': 519, 'subsample': 0.5229647261029038, 'colsample_bytree': 0.9622572210670438, 'reg_alpha': 5.7729344816477255, 'reg_lambda': 7.120429278775235, 'gamma': 3.0234341035404615}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:32,450] Trial 625 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.11509470857972731, 'n_estimators': 560, 'subsample': 0.8715922597231345, 'colsample_bytree': 0.9154749112016655, 'reg_alpha': 5.133772829357324, 'reg_lambda': 7.863474743970456, 'gamma': 2.8890293266718032}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:32,915] Trial 626 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.1040363372723401, 'n_estimators': 535, 'subsample': 0.5503855168636154, 'colsample_bytree': 0.9542362237865917, 'reg_alpha': 5.571313531070025, 'reg_lambda': 7.684961406601077, 'gamma': 3.5613883494631473}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:33,372] Trial 627 finished with value: 0.7236 and parameters: {'max_depth': 6, 'learning_rate': 0.13803006377665655, 'n_estimators': 498, 'subsample': 0.5063600524165661, 'colsample_bytree': 0.9422418996924418, 'reg_alpha': 5.372423488585354, 'reg_lambda': 7.6040455016035535, 'gamma': 2.708430363403379}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:33,792] Trial 628 finished with value: 0.7244 and parameters: {'max_depth': 6, 'learning_rate': 0.12813529518258884, 'n_estimators': 516, 'subsample': 0.5394866398258648, 'colsample_bytree': 0.6310639417056634, 'reg_alpha': 5.998289985677343, 'reg_lambda': 6.67626271935481, 'gamma': 3.3641266952713305}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:34,240] Trial 629 finished with value: 0.7204 and parameters: {'max_depth': 6, 'learning_rate': 0.12114040422628239, 'n_estimators': 491, 'subsample': 0.5552883992100406, 'colsample_bytree': 0.9265576634840735, 'reg_alpha': 5.707204921937938, 'reg_lambda': 7.305132936909121, 'gamma': 2.8263366200320275}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:34,740] Trial 630 finished with value: 0.7196 and parameters: {'max_depth': 9, 'learning_rate': 0.11214824983246695, 'n_estimators': 514, 'subsample': 0.5290627523133782, 'colsample_bytree': 0.969889259620245, 'reg_alpha': 3.041249835379854, 'reg_lambda': 7.909951455203425, 'gamma': 2.9905074078360907}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:35,233] Trial 631 finished with value: 0.7268 and parameters: {'max_depth': 7, 'learning_rate': 0.13411582081041923, 'n_estimators': 551, 'subsample': 0.5451929029039709, 'colsample_bytree': 0.9600493242865161, 'reg_alpha': 3.8907281299172363, 'reg_lambda': 8.091620591021831, 'gamma': 3.0909452026777426}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:35,707] Trial 632 finished with value: 0.726 and parameters: {'max_depth': 4, 'learning_rate': 0.12331774343072899, 'n_estimators': 533, 'subsample': 0.5626391944852207, 'colsample_bytree': 0.9448718636868352, 'reg_alpha': 5.321293718130023, 'reg_lambda': 7.682722582037793, 'gamma': 3.4445103286575565}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:36,191] Trial 633 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.1404962661548932, 'n_estimators': 485, 'subsample': 0.533955588649168, 'colsample_bytree': 0.9719119692539712, 'reg_alpha': 5.867556570322688, 'reg_lambda': 7.085645654003989, 'gamma': 3.261557612192092}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:36,663] Trial 634 finished with value: 0.7264 and parameters: {'max_depth': 4, 'learning_rate': 0.10812394473123219, 'n_estimators': 508, 'subsample': 0.7019758045864654, 'colsample_bytree': 0.9358692153382488, 'reg_alpha': 5.590167871471717, 'reg_lambda': 8.509178723800325, 'gamma': 2.909377482076136}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:37,120] Trial 635 finished with value: 0.7248 and parameters: {'max_depth': 7, 'learning_rate': 0.12916830922399541, 'n_estimators': 528, 'subsample': 0.5003209234882303, 'colsample_bytree': 0.8661431631456284, 'reg_alpha': 4.311360943099617, 'reg_lambda': 7.9100158512059755, 'gamma': 3.6860987871295485}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:37,551] Trial 636 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.13566808062224703, 'n_estimators': 482, 'subsample': 0.5166351144503806, 'colsample_bytree': 0.9569905392916161, 'reg_alpha': 6.066627244697777, 'reg_lambda': 7.4531296215510165, 'gamma': 2.732464582794856}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:38,033] Trial 637 finished with value: 0.726 and parameters: {'max_depth': 4, 'learning_rate': 0.14373381624183307, 'n_estimators': 564, 'subsample': 0.5519011105099559, 'colsample_bytree': 0.9489573816495582, 'reg_alpha': 5.1232251823492465, 'reg_lambda': 8.80326845761737, 'gamma': 3.086691977651799}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:38,547] Trial 638 finished with value: 0.7248 and parameters: {'max_depth': 4, 'learning_rate': 0.1159705355353987, 'n_estimators': 503, 'subsample': 0.5418802064936996, 'colsample_bytree': 0.9226354167137467, 'reg_alpha': 5.48924367339675, 'reg_lambda': 8.303185823205347, 'gamma': 2.5715181911922125}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:39,054] Trial 639 finished with value: 0.7276 and parameters: {'max_depth': 6, 'learning_rate': 0.12498693555909708, 'n_estimators': 540, 'subsample': 0.5669484463926967, 'colsample_bytree': 0.9629544428179839, 'reg_alpha': 5.747364944850866, 'reg_lambda': 7.204018240038929, 'gamma': 3.3208973713067564}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:39,512] Trial 640 finished with value: 0.7284 and parameters: {'max_depth': 4, 'learning_rate': 0.1632686491637107, 'n_estimators': 516, 'subsample': 0.5273822913859842, 'colsample_bytree': 0.9727295943040489, 'reg_alpha': 5.94754489653218, 'reg_lambda': 8.611187574940146, 'gamma': 2.9780037168930877}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:39,957] Trial 641 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.1722338904064404, 'n_estimators': 462, 'subsample': 0.5108587470981716, 'colsample_bytree': 0.966365355172556, 'reg_alpha': 6.124098952320339, 'reg_lambda': 8.504565749319568, 'gamma': 2.842731957196441}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:40,381] Trial 642 finished with value: 0.7184 and parameters: {'max_depth': 4, 'learning_rate': 0.16317357533083662, 'n_estimators': 494, 'subsample': 0.6380416269646344, 'colsample_bytree': 0.9510664463486771, 'reg_alpha': 5.93928741260551, 'reg_lambda': 8.568544027770582, 'gamma': 3.90690825630995}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:40,553] Trial 643 finished with value: 0.7188 and parameters: {'max_depth': 4, 'learning_rate': 0.29900890464739305, 'n_estimators': 100, 'subsample': 0.5223458703526571, 'colsample_bytree': 0.9336914647960729, 'reg_alpha': 4.553799979204411, 'reg_lambda': 8.251256851274634, 'gamma': 2.938705617664614}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:40,987] Trial 644 finished with value: 0.7168 and parameters: {'max_depth': 4, 'learning_rate': 0.1700794269949058, 'n_estimators': 513, 'subsample': 0.8056926301537793, 'colsample_bytree': 0.9726844628689477, 'reg_alpha': 6.134854935392937, 'reg_lambda': 6.456266267756415, 'gamma': 2.7996061883682835}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:41,435] Trial 645 finished with value: 0.7204 and parameters: {'max_depth': 4, 'learning_rate': 0.20255548462568043, 'n_estimators': 387, 'subsample': 0.528591676356613, 'colsample_bytree': 0.955901449748071, 'reg_alpha': 5.9784132003192605, 'reg_lambda': 8.601392595800748, 'gamma': 2.9767534161239775}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:41,863] Trial 646 finished with value: 0.72 and parameters: {'max_depth': 4, 'learning_rate': 0.17905850378918475, 'n_estimators': 481, 'subsample': 0.5190824222182517, 'colsample_bytree': 0.9400934447939784, 'reg_alpha': 5.769996027526653, 'reg_lambda': 8.975481987328287, 'gamma': 2.749999120633781}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:42,222] Trial 647 finished with value: 0.7244 and parameters: {'max_depth': 4, 'learning_rate': 0.16510306269175007, 'n_estimators': 319, 'subsample': 0.5597595971098017, 'colsample_bytree': 0.9642573364847647, 'reg_alpha': 5.005509589776041, 'reg_lambda': 8.398639685047202, 'gamma': 2.8861487031518815}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:42,681] Trial 648 finished with value: 0.7252 and parameters: {'max_depth': 4, 'learning_rate': 0.15709702203333, 'n_estimators': 504, 'subsample': 0.5472335068819332, 'colsample_bytree': 0.946101129519583, 'reg_alpha': 4.790439768092967, 'reg_lambda': 8.850296302433811, 'gamma': 3.036886186028685}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:42,862] Trial 649 finished with value: 0.7172 and parameters: {'max_depth': 4, 'learning_rate': 0.1617532496866971, 'n_estimators': 116, 'subsample': 0.5312856818177968, 'colsample_bytree': 0.9289446445160715, 'reg_alpha': 5.248979044835724, 'reg_lambda': 8.70699123168465, 'gamma': 3.1686976893914216}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:43,327] Trial 650 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.1678348142021505, 'n_estimators': 525, 'subsample': 0.5131104673036233, 'colsample_bytree': 0.9102420157632878, 'reg_alpha': 6.177710624980726, 'reg_lambda': 8.147599073752797, 'gamma': 2.6640308981614167}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:44,044] Trial 651 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.1593176445016629, 'n_estimators': 1000, 'subsample': 0.5576195378123687, 'colsample_bytree': 0.9739118998322933, 'reg_alpha': 5.460076277533631, 'reg_lambda': 8.984985015338745, 'gamma': 3.4931339015761647}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:44,454] Trial 652 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.10411836208516423, 'n_estimators': 455, 'subsample': 0.5424672211154973, 'colsample_bytree': 0.9571972263555608, 'reg_alpha': 5.877063977329417, 'reg_lambda': 8.67116128372363, 'gamma': 2.9819955608074897}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:44,872] Trial 653 finished with value: 0.7248 and parameters: {'max_depth': 6, 'learning_rate': 0.09767687215514816, 'n_estimators': 472, 'subsample': 0.5683224597080663, 'colsample_bytree': 0.6631375132932823, 'reg_alpha': 5.692785183627592, 'reg_lambda': 8.36196461764719, 'gamma': 2.8179243801023044}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:45,310] Trial 654 finished with value: 0.724 and parameters: {'max_depth': 4, 'learning_rate': 0.17391891989932326, 'n_estimators': 544, 'subsample': 0.5252074970708747, 'colsample_bytree': 0.9479873264262993, 'reg_alpha': 6.2968383828387875, 'reg_lambda': 7.716832890803222, 'gamma': 3.3977396488685674}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:45,718] Trial 655 finished with value: 0.7296 and parameters: {'max_depth': 6, 'learning_rate': 0.15453287236616625, 'n_estimators': 500, 'subsample': 0.5379924604746513, 'colsample_bytree': 0.9778305526618986, 'reg_alpha': 5.99165391373971, 'reg_lambda': 8.867807238430583, 'gamma': 3.2174491782342303}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:46,154] Trial 656 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.1489542466443139, 'n_estimators': 521, 'subsample': 0.5360206542943019, 'colsample_bytree': 0.9774657308859664, 'reg_alpha': 5.487227168802141, 'reg_lambda': 8.797937065213977, 'gamma': 3.2903078490724327}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:46,550] Trial 657 finished with value: 0.7256 and parameters: {'max_depth': 4, 'learning_rate': 0.16136492770672695, 'n_estimators': 504, 'subsample': 0.5119770443523178, 'colsample_bytree': 0.978207700837509, 'reg_alpha': 5.88059121478823, 'reg_lambda': 8.93434084655868, 'gamma': 3.5751063918508015}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:47,023] Trial 658 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.15460683346575485, 'n_estimators': 561, 'subsample': 0.5518726270566232, 'colsample_bytree': 0.9690754999755897, 'reg_alpha': 5.208530474481329, 'reg_lambda': 8.628253743389406, 'gamma': 2.5990695648867335}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:47,500] Trial 659 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.15542357555123565, 'n_estimators': 585, 'subsample': 0.5250911066892879, 'colsample_bytree': 0.9797451239545997, 'reg_alpha': 5.59743306055291, 'reg_lambda': 8.99224220374149, 'gamma': 2.889959692715045}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:47,756] Trial 660 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.16618932245993195, 'n_estimators': 232, 'subsample': 0.540434966620806, 'colsample_bytree': 0.9659184248727433, 'reg_alpha': 5.390541523129122, 'reg_lambda': 8.768955472798893, 'gamma': 3.068421627131631}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:48,218] Trial 661 finished with value: 0.7236 and parameters: {'max_depth': 4, 'learning_rate': 0.1627694342860634, 'n_estimators': 538, 'subsample': 0.5556417901286629, 'colsample_bytree': 0.9809657758712351, 'reg_alpha': 4.915335655948875, 'reg_lambda': 8.451998265492747, 'gamma': 3.3997443740576125}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:48,681] Trial 662 finished with value: 0.718 and parameters: {'max_depth': 10, 'learning_rate': 0.15520466066608277, 'n_estimators': 519, 'subsample': 0.5305454697028871, 'colsample_bytree': 0.9640064951436937, 'reg_alpha': 5.996448164718846, 'reg_lambda': 9.075233374552937, 'gamma': 2.734554691611269}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:49,168] Trial 663 finished with value: 0.7232 and parameters: {'max_depth': 7, 'learning_rate': 0.14986888753047733, 'n_estimators': 505, 'subsample': 0.5709601405108589, 'colsample_bytree': 0.974940648994419, 'reg_alpha': 4.640620523185595, 'reg_lambda': 8.016685797810206, 'gamma': 3.1530204561110184}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:49,567] Trial 664 finished with value: 0.7184 and parameters: {'max_depth': 6, 'learning_rate': 0.15722626131733922, 'n_estimators': 492, 'subsample': 0.8547973748618394, 'colsample_bytree': 0.9877736147254987, 'reg_alpha': 5.737731142549471, 'reg_lambda': 7.327272550594343, 'gamma': 2.97414910626529}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:50,178] Trial 665 finished with value: 0.7216 and parameters: {'max_depth': 4, 'learning_rate': 0.17172718940702347, 'n_estimators': 772, 'subsample': 0.5179943208243053, 'colsample_bytree': 0.9567097593951127, 'reg_alpha': 4.444403461120929, 'reg_lambda': 8.820924853508965, 'gamma': 3.276068459562744}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:50,612] Trial 666 finished with value: 0.722 and parameters: {'max_depth': 6, 'learning_rate': 0.16117897458062322, 'n_estimators': 535, 'subsample': 0.5476444678830708, 'colsample_bytree': 0.9701030828289608, 'reg_alpha': 5.5650442079534175, 'reg_lambda': 9.124850728292959, 'gamma': 3.1636858505918743}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:50,826] Trial 667 finished with value: 0.722 and parameters: {'max_depth': 6, 'learning_rate': 0.11023700341258458, 'n_estimators': 129, 'subsample': 0.535814813239764, 'colsample_bytree': 0.9660039564225421, 'reg_alpha': 5.254987643934504, 'reg_lambda': 8.479557530219452, 'gamma': 2.8454702768981077}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:51,300] Trial 668 finished with value: 0.728 and parameters: {'max_depth': 4, 'learning_rate': 0.14688788527303415, 'n_estimators': 552, 'subsample': 0.5859149319084543, 'colsample_bytree': 0.9571021621700693, 'reg_alpha': 5.9443644557963715, 'reg_lambda': 6.868737289563192, 'gamma': 3.0288854767477753}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:51,744] Trial 669 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.16673518209860774, 'n_estimators': 521, 'subsample': 0.5065591268170463, 'colsample_bytree': 0.9847988394887813, 'reg_alpha': 5.819409176746702, 'reg_lambda': 8.937991200910592, 'gamma': 3.6148440519319442}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:52,140] Trial 670 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10185707292087243, 'n_estimators': 492, 'subsample': 0.5607400004550841, 'colsample_bytree': 0.6932648900940755, 'reg_alpha': 6.1260362002794375, 'reg_lambda': 8.651450100747143, 'gamma': 3.4549183480298336}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:52,601] Trial 671 finished with value: 0.7208 and parameters: {'max_depth': 6, 'learning_rate': 0.1515632244869061, 'n_estimators': 511, 'subsample': 0.5491611259273251, 'colsample_bytree': 0.9757645573422081, 'reg_alpha': 5.414232723887596, 'reg_lambda': 9.11992560867573, 'gamma': 3.3378108677555676}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:52,815] Trial 672 finished with value: 0.7224 and parameters: {'max_depth': 4, 'learning_rate': 0.11765470314645728, 'n_estimators': 148, 'subsample': 0.5278671917013805, 'colsample_bytree': 0.9491432149973942, 'reg_alpha': 5.6363064830397285, 'reg_lambda': 5.714859450614796, 'gamma': 3.787246641427144}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:53,270] Trial 673 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11068369955772508, 'n_estimators': 477, 'subsample': 0.5399194345004725, 'colsample_bytree': 0.9623086714039129, 'reg_alpha': 4.974609171377911, 'reg_lambda': 7.606785103561227, 'gamma': 2.720171159472836}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:53,684] Trial 674 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.15319548269368094, 'n_estimators': 429, 'subsample': 0.5680117194035155, 'colsample_bytree': 0.9919648874135732, 'reg_alpha': 6.33794741414976, 'reg_lambda': 8.228019406871242, 'gamma': 2.9164152856866545}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:53,934] Trial 675 finished with value: 0.7212 and parameters: {'max_depth': 4, 'learning_rate': 0.1590479607564792, 'n_estimators': 209, 'subsample': 0.5547476120571243, 'colsample_bytree': 0.9744920213436253, 'reg_alpha': 5.7822234969374895, 'reg_lambda': 7.893623426902031, 'gamma': 3.250852615728892}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:54,245] Trial 676 finished with value: 0.7256 and parameters: {'max_depth': 6, 'learning_rate': 0.11804925134725958, 'n_estimators': 282, 'subsample': 0.5250919565354312, 'colsample_bytree': 0.9541966973886835, 'reg_alpha': 5.177695761951177, 'reg_lambda': 9.200171764091783, 'gamma': 3.08495697354455}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:54,718] Trial 677 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.14697760824838255, 'n_estimators': 533, 'subsample': 0.546129583638828, 'colsample_bytree': 0.9393383880263566, 'reg_alpha': 6.047181256023307, 'reg_lambda': 8.832710103988978, 'gamma': 2.573455499794838}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:55,193] Trial 678 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.1067407534412509, 'n_estimators': 565, 'subsample': 0.5144581469014924, 'colsample_bytree': 0.9617322006049583, 'reg_alpha': 7.819659937837749, 'reg_lambda': 8.62238060713687, 'gamma': 2.8517590728920017}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:55,650] Trial 679 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.12235989670851574, 'n_estimators': 491, 'subsample': 0.576600184732428, 'colsample_bytree': 0.9809393639384736, 'reg_alpha': 5.572005344525392, 'reg_lambda': 9.009544737778992, 'gamma': 3.207285684343778}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:56,086] Trial 680 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.1660056599339271, 'n_estimators': 514, 'subsample': 0.5624454540184776, 'colsample_bytree': 0.9483307891325263, 'reg_alpha': 5.368972463762879, 'reg_lambda': 8.385741368589455, 'gamma': 2.9743525550805394}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:56,570] Trial 681 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.1770633856742997, 'n_estimators': 545, 'subsample': 0.534202735414411, 'colsample_bytree': 0.9223851426781614, 'reg_alpha': 4.814349128879257, 'reg_lambda': 5.016449628652035, 'gamma': 3.3978073118438985}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:57,075] Trial 682 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.1477150161529849, 'n_estimators': 465, 'subsample': 0.5518003356870053, 'colsample_bytree': 0.9693840480307806, 'reg_alpha': 4.095877390654011, 'reg_lambda': 7.420966065772043, 'gamma': 2.6979737542238422}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:57,549] Trial 683 finished with value: 0.728 and parameters: {'max_depth': 7, 'learning_rate': 0.11280087958084789, 'n_estimators': 506, 'subsample': 0.5380364504223156, 'colsample_bytree': 0.9354561014202684, 'reg_alpha': 5.873247142453712, 'reg_lambda': 7.098343741772942, 'gamma': 3.5308863733539786}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:58,029] Trial 684 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.14227995466203222, 'n_estimators': 521, 'subsample': 0.520157703336215, 'colsample_bytree': 0.9910611002792269, 'reg_alpha': 5.648109228985887, 'reg_lambda': 9.22083899834338, 'gamma': 3.098526077442915}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:58,224] Trial 685 finished with value: 0.7208 and parameters: {'max_depth': 4, 'learning_rate': 0.158632000097108, 'n_estimators': 118, 'subsample': 0.5032505314066051, 'colsample_bytree': 0.8425669747152427, 'reg_alpha': 6.212934392097739, 'reg_lambda': 8.778177195960021, 'gamma': 2.793989380724943}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:58,673] Trial 686 finished with value: 0.72 and parameters: {'max_depth': 6, 'learning_rate': 0.12061646828993076, 'n_estimators': 493, 'subsample': 0.5946961488534476, 'colsample_bytree': 0.9547468200984305, 'reg_alpha': 5.101993260936034, 'reg_lambda': 9.0392392452221, 'gamma': 2.9414022959486514}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:59,089] Trial 687 finished with value: 0.7268 and parameters: {'max_depth': 4, 'learning_rate': 0.1277677427592955, 'n_estimators': 442, 'subsample': 0.5588629367127413, 'colsample_bytree': 0.9454140471730083, 'reg_alpha': 6.009243807890978, 'reg_lambda': 9.282269811887625, 'gamma': 3.3421174946478254}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:52:59,546] Trial 688 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.10010188449333049, 'n_estimators': 530, 'subsample': 0.5462013545155353, 'colsample_bytree': 0.9683041197947361, 'reg_alpha': 5.467919819502954, 'reg_lambda': 8.101905621821585, 'gamma': 3.2013433591797034}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:00,130] Trial 689 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.030854868126671417, 'n_estimators': 550, 'subsample': 0.5335624174522968, 'colsample_bytree': 0.9618575637270822, 'reg_alpha': 5.442138410814266, 'reg_lambda': 7.986051183486836, 'gamma': 3.2822439993194594}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:00,627] Trial 690 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.15219148268907162, 'n_estimators': 585, 'subsample': 0.543028183027434, 'colsample_bytree': 0.9533564982100089, 'reg_alpha': 5.508310603369394, 'reg_lambda': 7.989479402070302, 'gamma': 3.202607880085956}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:01,163] Trial 691 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09976377085900322, 'n_estimators': 536, 'subsample': 0.5263918277192248, 'colsample_bytree': 0.9302470098260663, 'reg_alpha': 5.29024371701793, 'reg_lambda': 8.29241845089707, 'gamma': 3.317623973354275}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:01,627] Trial 692 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.09575030430304418, 'n_estimators': 560, 'subsample': 0.5445324132492388, 'colsample_bytree': 0.9672204527056184, 'reg_alpha': 5.67921520450493, 'reg_lambda': 7.556066437661823, 'gamma': 3.4288514734430424}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:02,071] Trial 693 finished with value: 0.724 and parameters: {'max_depth': 6, 'learning_rate': 0.14467391072137398, 'n_estimators': 528, 'subsample': 0.5178517918550402, 'colsample_bytree': 0.9431748427694603, 'reg_alpha': 5.798784189405331, 'reg_lambda': 8.138289233422835, 'gamma': 3.2174314239891926}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:02,686] Trial 694 finished with value: 0.7108 and parameters: {'max_depth': 8, 'learning_rate': 0.16414924926560634, 'n_estimators': 507, 'subsample': 0.5002205756854415, 'colsample_bytree': 0.9607068309112705, 'reg_alpha': 5.3541062257787475, 'reg_lambda': 8.170146924052519, 'gamma': 1.3621447686171337}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:03,241] Trial 695 finished with value: 0.7252 and parameters: {'max_depth': 6, 'learning_rate': 0.11449067014662334, 'n_estimators': 539, 'subsample': 0.5344799694682981, 'colsample_bytree': 0.9183680634098513, 'reg_alpha': 5.57417406785695, 'reg_lambda': 7.727742274489304, 'gamma': 3.1364830052914017}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:03,687] Trial 696 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.1561915882643866, 'n_estimators': 481, 'subsample': 0.5459219637158312, 'colsample_bytree': 0.9512009233074493, 'reg_alpha': 5.859108975366714, 'reg_lambda': 8.076855634814672, 'gamma': 3.4457731382124592}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:04,275] Trial 697 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.055221959105595034, 'n_estimators': 573, 'subsample': 0.5262015008778876, 'colsample_bytree': 0.9037197127704901, 'reg_alpha': 5.232497445503242, 'reg_lambda': 7.833008526530646, 'gamma': 3.6779079872203813}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:04,761] Trial 698 finished with value: 0.7308 and parameters: {'max_depth': 5, 'learning_rate': 0.12309023836014442, 'n_estimators': 505, 'subsample': 0.5493213980702376, 'colsample_bytree': 0.9713053316243548, 'reg_alpha': 5.6634963641355975, 'reg_lambda': 8.405786826379295, 'gamma': 3.272751768767239}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:05,273] Trial 699 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.1201073946809001, 'n_estimators': 518, 'subsample': 0.5539850659913612, 'colsample_bytree': 0.9741136160385417, 'reg_alpha': 5.68670630403289, 'reg_lambda': 8.324156249334067, 'gamma': 3.326621680590884}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:05,713] Trial 700 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.12467129956310596, 'n_estimators': 498, 'subsample': 0.5525142218100185, 'colsample_bytree': 0.9713617566037444, 'reg_alpha': 5.434219333497406, 'reg_lambda': 8.40538758744817, 'gamma': 3.267898131970061}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:06,252] Trial 701 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.12919409434774906, 'n_estimators': 608, 'subsample': 0.5595459134444319, 'colsample_bytree': 0.967282146233805, 'reg_alpha': 5.871597781588927, 'reg_lambda': 8.511762312910694, 'gamma': 3.1678323257590764}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:06,689] Trial 702 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.11564129113795713, 'n_estimators': 478, 'subsample': 0.544755927534562, 'colsample_bytree': 0.9796925953858435, 'reg_alpha': 5.584141212291502, 'reg_lambda': 8.418253005348289, 'gamma': 3.393175268522073}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:07,114] Trial 703 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.1090353874585911, 'n_estimators': 469, 'subsample': 0.548248577732062, 'colsample_bytree': 0.97840702375705, 'reg_alpha': 5.549408334829691, 'reg_lambda': 8.373698415864533, 'gamma': 3.5177321347265655}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:07,515] Trial 704 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.11488185612578361, 'n_estimators': 463, 'subsample': 0.5681773044799895, 'colsample_bytree': 0.9835187244800561, 'reg_alpha': 5.352050517217899, 'reg_lambda': 8.2549941427025, 'gamma': 3.4343224893877626}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:07,963] Trial 705 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.12063840006870089, 'n_estimators': 456, 'subsample': 0.5595836679330826, 'colsample_bytree': 0.9544238475963716, 'reg_alpha': 5.578511530286512, 'reg_lambda': 8.086721087396452, 'gamma': 3.5293594396460684}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:08,384] Trial 706 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.22937922956457957, 'n_estimators': 482, 'subsample': 0.5449899073822341, 'colsample_bytree': 0.960297309338846, 'reg_alpha': 5.232576449096673, 'reg_lambda': 8.506922480029807, 'gamma': 3.355623305805899}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:08,833] Trial 707 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11535500639287034, 'n_estimators': 485, 'subsample': 0.5547405931552885, 'colsample_bytree': 0.9818901471293309, 'reg_alpha': 5.705395780562572, 'reg_lambda': 8.206948932980424, 'gamma': 3.4009941520884066}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:09,244] Trial 708 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.10683381792925518, 'n_estimators': 495, 'subsample': 0.5452653610327398, 'colsample_bytree': 0.9391276832909714, 'reg_alpha': 5.457224080955728, 'reg_lambda': 8.540400494395355, 'gamma': 3.564660784023568}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:09,641] Trial 709 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.11901491063382444, 'n_estimators': 446, 'subsample': 0.5683407867123292, 'colsample_bytree': 0.9933298520544692, 'reg_alpha': 5.671093923116142, 'reg_lambda': 8.336801228193295, 'gamma': 3.3097431360084144}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:10,067] Trial 710 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.12358655625220966, 'n_estimators': 501, 'subsample': 0.5394357003299166, 'colsample_bytree': 0.9642886624761333, 'reg_alpha': 5.161636975385039, 'reg_lambda': 8.674276136159094, 'gamma': 3.2465960494422426}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:10,485] Trial 711 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11264536566289256, 'n_estimators': 475, 'subsample': 0.5521781232689056, 'colsample_bytree': 0.9482713985575871, 'reg_alpha': 5.34387079129192, 'reg_lambda': 7.986417333509492, 'gamma': 3.445244484643262}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:10,939] Trial 712 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.12888385313990727, 'n_estimators': 529, 'subsample': 0.5592624577436, 'colsample_bytree': 0.9745280965363183, 'reg_alpha': 5.737345694109304, 'reg_lambda': 3.5709810567720437, 'gamma': 3.6318695201833835}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:11,390] Trial 713 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10322057992253383, 'n_estimators': 505, 'subsample': 0.574354142299954, 'colsample_bytree': 0.9329349243830316, 'reg_alpha': 5.460068017382718, 'reg_lambda': 7.023458046133346, 'gamma': 3.3619380427848164}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:11,815] Trial 714 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.12436805558899687, 'n_estimators': 476, 'subsample': 0.5394018659719585, 'colsample_bytree': 0.9626296176377211, 'reg_alpha': 5.541872069903049, 'reg_lambda': 9.328119015142455, 'gamma': 3.2663949578082265}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:12,263] Trial 715 finished with value: 0.718 and parameters: {'max_depth': 5, 'learning_rate': 0.28565206453531117, 'n_estimators': 551, 'subsample': 0.5499056084185238, 'colsample_bytree': 0.9446722455515013, 'reg_alpha': 5.808012949424688, 'reg_lambda': 7.3141091833897915, 'gamma': 3.180527915014452}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:12,689] Trial 716 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.1309712430007559, 'n_estimators': 525, 'subsample': 0.5634239364303768, 'colsample_bytree': 0.9837503239993228, 'reg_alpha': 6.102133072074239, 'reg_lambda': 8.210609077570496, 'gamma': 3.425506311952614}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:13,113] Trial 717 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.11682893698678712, 'n_estimators': 456, 'subsample': 0.5379302595953411, 'colsample_bytree': 0.9585867676116252, 'reg_alpha': 5.143991985604579, 'reg_lambda': 8.820893827268087, 'gamma': 3.3443462968854516}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:13,548] Trial 718 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.11226403776681422, 'n_estimators': 497, 'subsample': 0.5519396835627841, 'colsample_bytree': 0.9714632290025269, 'reg_alpha': 5.990209189169584, 'reg_lambda': 8.513114438898027, 'gamma': 3.230252094646085}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:14,192] Trial 719 finished with value: 0.7112 and parameters: {'max_depth': 5, 'learning_rate': 0.13303602148898006, 'n_estimators': 514, 'subsample': 0.675728191442672, 'colsample_bytree': 0.9271661074939865, 'reg_alpha': 5.348408058685924, 'reg_lambda': 9.595691193552913, 'gamma': 0.585943507515424}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:14,700] Trial 720 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.12229993523163639, 'n_estimators': 630, 'subsample': 0.5426398966998364, 'colsample_bytree': 0.9514377136116401, 'reg_alpha': 5.7126074872629085, 'reg_lambda': 9.382474457022138, 'gamma': 3.533906828756081}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:15,227] Trial 721 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.12199536072593849, 'n_estimators': 701, 'subsample': 0.5658719710048297, 'colsample_bytree': 0.93886856473164, 'reg_alpha': 6.240128998247895, 'reg_lambda': 9.41792402570055, 'gamma': 3.7666034972028344}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:15,719] Trial 722 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.1273314163569445, 'n_estimators': 662, 'subsample': 0.5560732105168744, 'colsample_bytree': 0.9918110191972533, 'reg_alpha': 5.838046917415616, 'reg_lambda': 9.295200674799133, 'gamma': 3.6540817756101496}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:16,329] Trial 723 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.13268532641159972, 'n_estimators': 793, 'subsample': 0.575759345977752, 'colsample_bytree': 0.9482436061357521, 'reg_alpha': 1.4014941889161694, 'reg_lambda': 9.126281960682546, 'gamma': 3.605117129639066}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:16,808] Trial 724 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.12691918112773287, 'n_estimators': 619, 'subsample': 0.5397242262989809, 'colsample_bytree': 0.9778170019949781, 'reg_alpha': 7.250516207544122, 'reg_lambda': 9.55055840845816, 'gamma': 3.517677736586853}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:17,300] Trial 725 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.13694246044883943, 'n_estimators': 625, 'subsample': 0.551589835227379, 'colsample_bytree': 0.9160310621211265, 'reg_alpha': 6.02033141146981, 'reg_lambda': 9.364822728286567, 'gamma': 3.514477697713543}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:17,831] Trial 726 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.1227744375231771, 'n_estimators': 735, 'subsample': 0.5629444262424156, 'colsample_bytree': 0.9641054232228679, 'reg_alpha': 5.694427289596454, 'reg_lambda': 9.699193354200647, 'gamma': 3.6236891495080323}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:18,362] Trial 727 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11869157989848256, 'n_estimators': 694, 'subsample': 0.5459824859499274, 'colsample_bytree': 0.9374041160113377, 'reg_alpha': 6.472712418039736, 'reg_lambda': 8.885814413524079, 'gamma': 3.7361573259550545}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:18,805] Trial 728 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.13041612282250356, 'n_estimators': 577, 'subsample': 0.5819990146319094, 'colsample_bytree': 0.9559726955930854, 'reg_alpha': 6.260339032351645, 'reg_lambda': 9.127953385120128, 'gamma': 3.864909337095253}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:19,333] Trial 729 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.12585292980120433, 'n_estimators': 634, 'subsample': 0.5441614706055137, 'colsample_bytree': 0.96753364855641, 'reg_alpha': 5.795903560230627, 'reg_lambda': 9.473915644485642, 'gamma': 3.466454158141794}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:19,890] Trial 730 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.13927077508993527, 'n_estimators': 716, 'subsample': 0.5334552239577832, 'colsample_bytree': 0.9825158199279426, 'reg_alpha': 5.629312215161391, 'reg_lambda': 9.238763310325403, 'gamma': 3.4866399418374376}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:20,287] Trial 731 finished with value: 0.7172 and parameters: {'max_depth': 5, 'learning_rate': 0.13177222917108222, 'n_estimators': 428, 'subsample': 0.9055124961927428, 'colsample_bytree': 0.9287031357678852, 'reg_alpha': 6.03094514839615, 'reg_lambda': 9.732450949773968, 'gamma': 3.395704082680628}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:20,727] Trial 732 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.1380627877421943, 'n_estimators': 554, 'subsample': 0.5585819634155484, 'colsample_bytree': 0.9481760440531845, 'reg_alpha': 5.8654565767951485, 'reg_lambda': 8.703833920641605, 'gamma': 3.5705948060746393}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:21,192] Trial 733 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.12029629249779905, 'n_estimators': 589, 'subsample': 0.5728077917518519, 'colsample_bytree': 0.9560358225080957, 'reg_alpha': 6.174276196351578, 'reg_lambda': 8.643461534233403, 'gamma': 3.7104486319898062}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:21,693] Trial 734 finished with value: 0.7308 and parameters: {'max_depth': 5, 'learning_rate': 0.1371650386760933, 'n_estimators': 657, 'subsample': 0.5616321462255703, 'colsample_bytree': 0.998785948206082, 'reg_alpha': 5.8782030478045035, 'reg_lambda': 4.518430061002668, 'gamma': 3.6138074863513414}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:22,243] Trial 735 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1389280761313081, 'n_estimators': 663, 'subsample': 0.5855432457832547, 'colsample_bytree': 0.9943481728070928, 'reg_alpha': 6.018497635343112, 'reg_lambda': 4.25816307989673, 'gamma': 3.817308713772833}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:22,723] Trial 736 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13787559807110356, 'n_estimators': 637, 'subsample': 0.5726448129998328, 'colsample_bytree': 0.9909405172386787, 'reg_alpha': 6.543964627520491, 'reg_lambda': 4.961045650545895, 'gamma': 3.639104518298377}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:23,237] Trial 737 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.12518546647614479, 'n_estimators': 679, 'subsample': 0.566805791920408, 'colsample_bytree': 0.9955102208702079, 'reg_alpha': 6.2905198900447346, 'reg_lambda': 4.626298506724656, 'gamma': 3.7237421706485163}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:23,700] Trial 738 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.11691024225483068, 'n_estimators': 611, 'subsample': 0.6073847119012176, 'colsample_bytree': 0.9996771003685314, 'reg_alpha': 5.895445214423052, 'reg_lambda': 4.887030468735661, 'gamma': 3.62421612526008}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:24,246] Trial 739 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.132843635062323, 'n_estimators': 679, 'subsample': 0.5808878956160948, 'colsample_bytree': 0.9868226164041319, 'reg_alpha': 6.087518834269079, 'reg_lambda': 4.141204552804182, 'gamma': 3.5652093153958004}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:24,797] Trial 740 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.1278844612132575, 'n_estimators': 730, 'subsample': 0.5612753945445457, 'colsample_bytree': 0.9971253954448414, 'reg_alpha': 5.8945338101052505, 'reg_lambda': 9.821318218699378, 'gamma': 3.693471264499829}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:25,355] Trial 741 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.13876396727116358, 'n_estimators': 703, 'subsample': 0.5665847339617471, 'colsample_bytree': 0.9834615645868932, 'reg_alpha': 6.375491028748126, 'reg_lambda': 9.59877080729918, 'gamma': 3.881587147877093}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:25,856] Trial 742 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.04761587221885223, 'n_estimators': 603, 'subsample': 0.59108637735369, 'colsample_bytree': 0.9863956984648198, 'reg_alpha': 6.12410544743511, 'reg_lambda': 9.427061316290393, 'gamma': 3.5874329166760552}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:26,359] Trial 743 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.12123516695017142, 'n_estimators': 648, 'subsample': 0.5583265779553709, 'colsample_bytree': 0.9755446342412873, 'reg_alpha': 5.823185675149592, 'reg_lambda': 4.67832050160256, 'gamma': 3.5625805946237783}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:26,812] Trial 744 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11579948239550253, 'n_estimators': 562, 'subsample': 0.5714863655056658, 'colsample_bytree': 0.9743631760408916, 'reg_alpha': 6.656474535686708, 'reg_lambda': 3.080815342119588, 'gamma': 3.748487205807906}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:27,342] Trial 745 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.10645856135364619, 'n_estimators': 678, 'subsample': 0.5586649122559144, 'colsample_bytree': 0.997046462552981, 'reg_alpha': 5.920789053778585, 'reg_lambda': 3.867779606227038, 'gamma': 3.4959677400685796}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:27,837] Trial 746 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.13338975282342716, 'n_estimators': 655, 'subsample': 0.5785741662173511, 'colsample_bytree': 0.9864650808921361, 'reg_alpha': 5.76931721239141, 'reg_lambda': 3.929117172552454, 'gamma': 3.6579905449425127}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:28,336] Trial 747 finished with value: 0.722 and parameters: {'max_depth': 9, 'learning_rate': 0.1279693674302166, 'n_estimators': 620, 'subsample': 0.5577216366913148, 'colsample_bytree': 0.9999234258586439, 'reg_alpha': 6.190910147114581, 'reg_lambda': 5.135434651738446, 'gamma': 3.51346045683339}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:28,812] Trial 748 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.14195470458759904, 'n_estimators': 596, 'subsample': 0.5519460823695139, 'colsample_bytree': 0.9472288527866506, 'reg_alpha': 5.55547723067289, 'reg_lambda': 4.239419387017491, 'gamma': 3.8145296502813055}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:29,359] Trial 749 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12297959380785448, 'n_estimators': 667, 'subsample': 0.5692340077354232, 'colsample_bytree': 0.9744796077001703, 'reg_alpha': 6.035554270311654, 'reg_lambda': 5.4325491757084565, 'gamma': 3.4811380912507057}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:29,923] Trial 750 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.1120122163967481, 'n_estimators': 754, 'subsample': 0.5556519904277607, 'colsample_bytree': 0.9664311120907146, 'reg_alpha': 5.655217415813509, 'reg_lambda': 9.666235208211955, 'gamma': 3.7180111921748575}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:30,428] Trial 751 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.13571384245158474, 'n_estimators': 639, 'subsample': 0.8182450378382458, 'colsample_bytree': 0.9835098918142069, 'reg_alpha': 5.894898221388733, 'reg_lambda': 9.843793096315615, 'gamma': 3.596795617800834}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:30,965] Trial 752 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09724931615631026, 'n_estimators': 714, 'subsample': 0.5630564023767686, 'colsample_bytree': 0.9527018498871405, 'reg_alpha': 6.391269276090056, 'reg_lambda': 4.803562305029521, 'gamma': 3.386953649353209}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:31,458] Trial 753 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11846722508731382, 'n_estimators': 581, 'subsample': 0.64991996371497, 'colsample_bytree': 0.9446934947078932, 'reg_alpha': 5.74406321979942, 'reg_lambda': 9.381516759698544, 'gamma': 3.5790178366199212}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:31,940] Trial 754 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.12902368093180913, 'n_estimators': 573, 'subsample': 0.5487302039820433, 'colsample_bytree': 0.9692486875589993, 'reg_alpha': 2.496033788792389, 'reg_lambda': 9.491633203539708, 'gamma': 3.4485704699992357}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:32,522] Trial 755 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.14180803991512167, 'n_estimators': 773, 'subsample': 0.5357930826367525, 'colsample_bytree': 0.8757661424242055, 'reg_alpha': 6.80922269999888, 'reg_lambda': 8.14137419188406, 'gamma': 3.330523322185469}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:32,990] Trial 756 finished with value: 0.7244 and parameters: {'max_depth': 7, 'learning_rate': 0.12409008562695212, 'n_estimators': 551, 'subsample': 0.5766065011595836, 'colsample_bytree': 0.980993781440424, 'reg_alpha': 5.543123291567744, 'reg_lambda': 4.521960307827973, 'gamma': 3.5461658497250426}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:33,655] Trial 757 finished with value: 0.7144 and parameters: {'max_depth': 5, 'learning_rate': 0.13228091853534607, 'n_estimators': 547, 'subsample': 0.5465070170534623, 'colsample_bytree': 0.9593723374812342, 'reg_alpha': 6.220843844936534, 'reg_lambda': 9.957481045839563, 'gamma': 0.7948142582759454}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:34,219] Trial 758 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.10954872693497825, 'n_estimators': 742, 'subsample': 0.6626271349843557, 'colsample_bytree': 0.9359371670931911, 'reg_alpha': 5.955943623105281, 'reg_lambda': 9.985470693617232, 'gamma': 3.352336064246754}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:34,720] Trial 759 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.116388224415752, 'n_estimators': 598, 'subsample': 0.5642037941008774, 'colsample_bytree': 0.9910229032716056, 'reg_alpha': 5.727361164753627, 'reg_lambda': 9.239865916006917, 'gamma': 3.4188037453987703}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:35,249] Trial 760 finished with value: 0.7192 and parameters: {'max_depth': 5, 'learning_rate': 0.14500115359107152, 'n_estimators': 654, 'subsample': 0.5555580767107926, 'colsample_bytree': 0.9997958366827963, 'reg_alpha': 5.530200461831951, 'reg_lambda': 4.734698534728459, 'gamma': 3.280992415236295}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:35,702] Trial 761 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.1372897355600541, 'n_estimators': 530, 'subsample': 0.5341525721676993, 'colsample_bytree': 0.97423054663829, 'reg_alpha': 6.0090426289860845, 'reg_lambda': 4.396673603350328, 'gamma': 3.7018544465476313}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:36,162] Trial 762 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.10085002488240485, 'n_estimators': 540, 'subsample': 0.5895808110478001, 'colsample_bytree': 0.9273343819142367, 'reg_alpha': 6.401325701810122, 'reg_lambda': 9.589139644618166, 'gamma': 3.4770242846266206}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:36,632] Trial 763 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12541653189633106, 'n_estimators': 540, 'subsample': 0.5451146144646725, 'colsample_bytree': 0.9468272999714332, 'reg_alpha': 5.764613440056341, 'reg_lambda': 8.391352977087195, 'gamma': 3.266841946138973}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:37,158] Trial 764 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.1298813004635456, 'n_estimators': 692, 'subsample': 0.5675463054782955, 'colsample_bytree': 0.9598879517681594, 'reg_alpha': 8.187543244665617, 'reg_lambda': 9.682101080038684, 'gamma': 3.6470968028019555}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:37,657] Trial 765 finished with value: 0.7252 and parameters: {'max_depth': 7, 'learning_rate': 0.12011555686421148, 'n_estimators': 628, 'subsample': 0.5536468023846709, 'colsample_bytree': 0.9680563907541645, 'reg_alpha': 6.128767566079967, 'reg_lambda': 9.114995045578862, 'gamma': 3.3626356836253377}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:38,107] Trial 766 finished with value: 0.7228 and parameters: {'max_depth': 6, 'learning_rate': 0.14126006892176193, 'n_estimators': 573, 'subsample': 0.5377194993625449, 'colsample_bytree': 0.9807599677609146, 'reg_alpha': 5.441551656863593, 'reg_lambda': 9.326711414500782, 'gamma': 3.8238157225925566}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:38,578] Trial 767 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.10725372181401346, 'n_estimators': 563, 'subsample': 0.5287172462232654, 'colsample_bytree': 0.9521080738936826, 'reg_alpha': 5.888581222406207, 'reg_lambda': 9.50150930062553, 'gamma': 3.2058878758164355}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:38,997] Trial 768 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13605221551522148, 'n_estimators': 527, 'subsample': 0.6259557921403431, 'colsample_bytree': 0.9200986165582614, 'reg_alpha': 5.667632350140106, 'reg_lambda': 0.344829843666286, 'gamma': 3.5110744321865797}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:39,419] Trial 769 finished with value: 0.7264 and parameters: {'max_depth': 6, 'learning_rate': 0.14935360982976295, 'n_estimators': 491, 'subsample': 0.5785994052537216, 'colsample_bytree': 0.9387243633467819, 'reg_alpha': 5.399438165577632, 'reg_lambda': 7.86580661700936, 'gamma': 3.3221793858390947}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:39,845] Trial 770 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.1147076518939098, 'n_estimators': 519, 'subsample': 0.5445526067165931, 'colsample_bytree': 0.9596089503774506, 'reg_alpha': 6.268026625658636, 'reg_lambda': 9.075287176856015, 'gamma': 3.1997698667185714}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:40,302] Trial 771 finished with value: 0.7148 and parameters: {'max_depth': 5, 'learning_rate': 0.11280196805937426, 'n_estimators': 557, 'subsample': 0.9205379054990218, 'colsample_bytree': 0.9669796749392999, 'reg_alpha': 6.645413876753354, 'reg_lambda': 8.942664998781725, 'gamma': 3.1781332434205183}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:40,713] Trial 772 finished with value: 0.7172 and parameters: {'max_depth': 5, 'learning_rate': 0.10414178569670636, 'n_estimators': 541, 'subsample': 0.9994900996401619, 'colsample_bytree': 0.9594777480556049, 'reg_alpha': 6.475828466694639, 'reg_lambda': 8.779419555512165, 'gamma': 3.268855348197191}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:41,167] Trial 773 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10897325558004772, 'n_estimators': 521, 'subsample': 0.5422453107735041, 'colsample_bytree': 0.9783581443430883, 'reg_alpha': 6.344596858746715, 'reg_lambda': 4.3658668491109935, 'gamma': 3.1291142890525507}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:41,598] Trial 774 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.1112835329743845, 'n_estimators': 531, 'subsample': 0.5330080880202372, 'colsample_bytree': 0.9680963337728704, 'reg_alpha': 6.892233475963987, 'reg_lambda': 9.012626374267997, 'gamma': 3.413801171945823}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:42,084] Trial 775 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.1141058849710279, 'n_estimators': 600, 'subsample': 0.7194037399936644, 'colsample_bytree': 0.9877593659023152, 'reg_alpha': 6.227652896479382, 'reg_lambda': 9.164034431873356, 'gamma': 3.220845284168694}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:42,550] Trial 776 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10094056079986807, 'n_estimators': 557, 'subsample': 0.5587498784258224, 'colsample_bytree': 0.9577265211781295, 'reg_alpha': 9.491624289547856, 'reg_lambda': 4.539867062692566, 'gamma': 3.9352564984749288}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:42,989] Trial 777 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.11733203625357701, 'n_estimators': 514, 'subsample': 0.5465990600664743, 'colsample_bytree': 0.9699377703846077, 'reg_alpha': 6.5788216075043415, 'reg_lambda': 8.773614482967638, 'gamma': 3.307474715741114}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:43,450] Trial 778 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.09337454359121132, 'n_estimators': 583, 'subsample': 0.5326115828976865, 'colsample_bytree': 0.9515386333347642, 'reg_alpha': 6.271092682555539, 'reg_lambda': 8.97763977874271, 'gamma': 3.4138937433681806}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:43,961] Trial 779 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.10574453056877785, 'n_estimators': 651, 'subsample': 0.5220807106288421, 'colsample_bytree': 0.9771791122562312, 'reg_alpha': 7.1223032572411995, 'reg_lambda': 8.468243398065987, 'gamma': 3.5449114264666512}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:44,395] Trial 780 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.11939602117979566, 'n_estimators': 526, 'subsample': 0.5648310937714082, 'colsample_bytree': 0.9602474163586925, 'reg_alpha': 6.133448096056728, 'reg_lambda': 8.234916038864151, 'gamma': 3.1755574292714837}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:44,867] Trial 781 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.11555436872545598, 'n_estimators': 548, 'subsample': 0.5513839528780209, 'colsample_bytree': 0.9885052992979584, 'reg_alpha': 6.711350895553972, 'reg_lambda': 9.184618767895138, 'gamma': 3.2737704100032303}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:45,332] Trial 782 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.1060242482041242, 'n_estimators': 576, 'subsample': 0.5455652575005406, 'colsample_bytree': 0.9898400301688934, 'reg_alpha': 6.606044381977063, 'reg_lambda': 9.097914432709773, 'gamma': 3.1092024516663535}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:45,832] Trial 783 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11255083663887568, 'n_estimators': 612, 'subsample': 0.538784357834655, 'colsample_bytree': 0.9999440494606168, 'reg_alpha': 6.493770457053479, 'reg_lambda': 8.932180505516762, 'gamma': 3.095265445182361}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:46,284] Trial 784 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11574532310494332, 'n_estimators': 558, 'subsample': 0.5276571724385049, 'colsample_bytree': 0.9875859607819771, 'reg_alpha': 6.375943179268408, 'reg_lambda': 8.751176653469376, 'gamma': 3.223333876672047}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:46,736] Trial 785 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.11026621601172691, 'n_estimators': 547, 'subsample': 0.5552676142581722, 'colsample_bytree': 0.9915578912009768, 'reg_alpha': 6.810899447565174, 'reg_lambda': 5.24084504908242, 'gamma': 3.256400386599472}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:47,186] Trial 786 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11906062791290384, 'n_estimators': 573, 'subsample': 0.5421597085498303, 'colsample_bytree': 0.9822196742369134, 'reg_alpha': 6.698444255862712, 'reg_lambda': 9.186597785000917, 'gamma': 3.425322525743593}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:47,676] Trial 787 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.10133295610183692, 'n_estimators': 547, 'subsample': 0.5512358504899956, 'colsample_bytree': 0.9798257866867479, 'reg_alpha': 6.121854322371109, 'reg_lambda': 3.326040638702326, 'gamma': 3.0846635863176237}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:48,131] Trial 788 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10409975976042223, 'n_estimators': 557, 'subsample': 0.5285962305536396, 'colsample_bytree': 0.9876673179112967, 'reg_alpha': 6.507471825340025, 'reg_lambda': 3.3207601660678487, 'gamma': 3.3546768359869104}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:48,606] Trial 789 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.09797540829393248, 'n_estimators': 563, 'subsample': 0.5370766132227988, 'colsample_bytree': 0.9796502548039425, 'reg_alpha': 6.208502731245727, 'reg_lambda': 2.7955677018064193, 'gamma': 3.1463500162159446}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:49,062] Trial 790 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09409779575032068, 'n_estimators': 575, 'subsample': 0.5497193794603646, 'colsample_bytree': 0.9920608625702272, 'reg_alpha': 6.36003039408228, 'reg_lambda': 2.586357827583945, 'gamma': 3.6316918080171945}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:49,559] Trial 791 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.09837923813492244, 'n_estimators': 589, 'subsample': 0.5213836147600317, 'colsample_bytree': 0.9998625646612948, 'reg_alpha': 6.10304988848643, 'reg_lambda': 0.9105143267174456, 'gamma': 3.070832200874716}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:50,199] Trial 792 finished with value: 0.7148 and parameters: {'max_depth': 5, 'learning_rate': 0.09036540667618495, 'n_estimators': 547, 'subsample': 0.5377238291372558, 'colsample_bytree': 0.9795640088212954, 'reg_alpha': 6.425598332212571, 'reg_lambda': 9.043081175304824, 'gamma': 0.1921027793311758}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:50,833] Trial 793 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.1001172717463108, 'n_estimators': 810, 'subsample': 0.5500125372803392, 'colsample_bytree': 0.9873034405843789, 'reg_alpha': 6.253121455675084, 'reg_lambda': 2.4109118512668157, 'gamma': 3.5290313688005055}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:51,263] Trial 794 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.10700990933858606, 'n_estimators': 537, 'subsample': 0.526268590116166, 'colsample_bytree': 0.9749588404084862, 'reg_alpha': 6.044476788941065, 'reg_lambda': 3.0111578419940686, 'gamma': 3.7377315519528764}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:51,752] Trial 795 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.11088885447123695, 'n_estimators': 599, 'subsample': 0.5441329527315021, 'colsample_bytree': 0.9817395065422369, 'reg_alpha': 6.065872233711951, 'reg_lambda': 4.010304918165669, 'gamma': 3.2935072304152344}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:52,205] Trial 796 finished with value: 0.7308 and parameters: {'max_depth': 5, 'learning_rate': 0.10026077152952742, 'n_estimators': 548, 'subsample': 0.5533232756098374, 'colsample_bytree': 0.9710233019978016, 'reg_alpha': 6.713387783279067, 'reg_lambda': 3.6186675625484317, 'gamma': 3.206739866673011}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:52,732] Trial 797 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.08590037955434116, 'n_estimators': 568, 'subsample': 0.5580268516334198, 'colsample_bytree': 0.9914591422785407, 'reg_alpha': 6.784744523134975, 'reg_lambda': 3.4879969401856705, 'gamma': 3.4297974561768787}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:53,181] Trial 798 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.09278559738626732, 'n_estimators': 553, 'subsample': 0.5556753537632106, 'colsample_bytree': 0.9992067743348222, 'reg_alpha': 6.830366601580734, 'reg_lambda': 3.3314308481901307, 'gamma': 3.2344432911323877}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:53,674] Trial 799 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.08868137338750462, 'n_estimators': 594, 'subsample': 0.5652961632629201, 'colsample_bytree': 0.9988481012793154, 'reg_alpha': 6.55264476267905, 'reg_lambda': 3.314944038516048, 'gamma': 3.1948714325321204}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:54,127] Trial 800 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.09376461269401544, 'n_estimators': 571, 'subsample': 0.5718801670403427, 'colsample_bytree': 0.9995334381130876, 'reg_alpha': 6.990215691363368, 'reg_lambda': 3.593257197192825, 'gamma': 3.3647939798089275}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:54,634] Trial 801 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.0784395839154372, 'n_estimators': 586, 'subsample': 0.5551703508401961, 'colsample_bytree': 0.9778135746746998, 'reg_alpha': 5.604654519775053, 'reg_lambda': 3.2012754679812527, 'gamma': 3.214191735349745}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:55,079] Trial 802 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.08187418390064002, 'n_estimators': 544, 'subsample': 0.5401608893782444, 'colsample_bytree': 0.9889633246464858, 'reg_alpha': 7.0079462772531995, 'reg_lambda': 3.2501571940364546, 'gamma': 3.5646036149639198}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:55,547] Trial 803 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.09613934703113954, 'n_estimators': 551, 'subsample': 0.5562592293720448, 'colsample_bytree': 0.9997442298695334, 'reg_alpha': 6.948793922107644, 'reg_lambda': 3.7170103938032306, 'gamma': 3.3292255173317566}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:56,036] Trial 804 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.08921238291706424, 'n_estimators': 619, 'subsample': 0.531419243408875, 'colsample_bytree': 0.9718341169318552, 'reg_alpha': 5.89184421101163, 'reg_lambda': 2.9998487900273525, 'gamma': 3.457872802898058}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:56,525] Trial 805 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.0990393893275824, 'n_estimators': 571, 'subsample': 0.5510074555786955, 'colsample_bytree': 0.9770158318891674, 'reg_alpha': 5.328821341126579, 'reg_lambda': 3.4526511099163604, 'gamma': 3.1449632234544933}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:57,229] Trial 806 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.09353145406369447, 'n_estimators': 978, 'subsample': 0.5407705554761886, 'colsample_bytree': 0.9866731369226606, 'reg_alpha': 6.6808846528579835, 'reg_lambda': 3.564873698591886, 'gamma': 3.042102920336882}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:57,952] Trial 807 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.08486284116759135, 'n_estimators': 976, 'subsample': 0.5119888810383145, 'colsample_bytree': 0.9916805056763391, 'reg_alpha': 6.5784388721122005, 'reg_lambda': 3.193327449232579, 'gamma': 3.047123301208576}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:58,528] Trial 808 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.09218216436491256, 'n_estimators': 764, 'subsample': 0.521219120843893, 'colsample_bytree': 0.9867753443920192, 'reg_alpha': 6.9573142880071925, 'reg_lambda': 3.5107970329736866, 'gamma': 3.0313638145946378}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:59,231] Trial 809 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.0913228884283047, 'n_estimators': 969, 'subsample': 0.5686972892746824, 'colsample_bytree': 0.9993777879853669, 'reg_alpha': 6.707157452032001, 'reg_lambda': 2.863422889138316, 'gamma': 3.1329562108476696}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:53:59,836] Trial 810 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.09569729136534112, 'n_estimators': 809, 'subsample': 0.5311026121716251, 'colsample_bytree': 0.986074911198015, 'reg_alpha': 7.070400267143255, 'reg_lambda': 3.554950702859856, 'gamma': 3.0453593669398358}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:53:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:00,496] Trial 811 finished with value: 0.7172 and parameters: {'max_depth': 5, 'learning_rate': 0.09550273608298102, 'n_estimators': 904, 'subsample': 0.9466269772231547, 'colsample_bytree': 0.9824694724755619, 'reg_alpha': 7.213286113668006, 'reg_lambda': 3.7303609491192566, 'gamma': 3.2083196913307144}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:01,150] Trial 812 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.0987717558409606, 'n_estimators': 951, 'subsample': 0.688922381331087, 'colsample_bytree': 0.9895295676012301, 'reg_alpha': 6.78551709538937, 'reg_lambda': 3.2882022842541705, 'gamma': 4.6363851508771905}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:01,888] Trial 813 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.07519792268148043, 'n_estimators': 937, 'subsample': 0.5600105754316419, 'colsample_bytree': 0.9752553876209039, 'reg_alpha': 6.735335951244827, 'reg_lambda': 3.7662441828695297, 'gamma': 3.0449169730649657}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:02,593] Trial 814 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.08442616650719789, 'n_estimators': 944, 'subsample': 0.5383605632999532, 'colsample_bytree': 0.9800376706909297, 'reg_alpha': 7.382541039870856, 'reg_lambda': 3.097831897796875, 'gamma': 3.127629559983707}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:03,298] Trial 815 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.08968867066438395, 'n_estimators': 933, 'subsample': 0.5490945647950357, 'colsample_bytree': 0.9918547662956584, 'reg_alpha': 6.735575764989645, 'reg_lambda': 3.4745528175495832, 'gamma': 3.226441188565404}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:03,756] Trial 816 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.08673209997909054, 'n_estimators': 536, 'subsample': 0.5770495207736284, 'colsample_bytree': 0.9705663159649318, 'reg_alpha': 6.8571827617429015, 'reg_lambda': 3.7724917536620945, 'gamma': 3.0428110581001255}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:04,227] Trial 817 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10358112778779074, 'n_estimators': 555, 'subsample': 0.5182329710627958, 'colsample_bytree': 0.9702766355050798, 'reg_alpha': 6.560574777331467, 'reg_lambda': 3.446285331803459, 'gamma': 3.270041781965692}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:04,670] Trial 818 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.10051884894285171, 'n_estimators': 529, 'subsample': 0.5604063531122401, 'colsample_bytree': 0.9824108256388152, 'reg_alpha': 7.132583669325316, 'reg_lambda': 3.3229901849184134, 'gamma': 3.109311622101167}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:05,139] Trial 819 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.09272971570640408, 'n_estimators': 540, 'subsample': 0.5338217050004181, 'colsample_bytree': 0.9996635943348381, 'reg_alpha': 6.458372276498746, 'reg_lambda': 3.6586992970709984, 'gamma': 3.1469890277643184}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:05,917] Trial 820 finished with value: 0.7168 and parameters: {'max_depth': 5, 'learning_rate': 0.09910690186932566, 'n_estimators': 990, 'subsample': 0.5494244142776153, 'colsample_bytree': 0.9706813025926223, 'reg_alpha': 0.9683047555718849, 'reg_lambda': 3.3229138019916142, 'gamma': 3.2960199599266704}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:06,609] Trial 821 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.08263640651047906, 'n_estimators': 826, 'subsample': 0.5423322653396949, 'colsample_bytree': 0.9892078874412252, 'reg_alpha': 6.343655674521002, 'reg_lambda': 3.5963941855490367, 'gamma': 3.1926285745564753}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:07,246] Trial 822 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10183984698263812, 'n_estimators': 778, 'subsample': 0.5715160957074402, 'colsample_bytree': 0.9793988695111318, 'reg_alpha': 6.896296364002162, 'reg_lambda': 2.7523358856584847, 'gamma': 3.0055148580674427}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:07,939] Trial 823 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09251991609336625, 'n_estimators': 901, 'subsample': 0.5576706554419645, 'colsample_bytree': 0.8334136781952508, 'reg_alpha': 6.537826132162975, 'reg_lambda': 3.9667053911115495, 'gamma': 3.3517958356999893}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:08,380] Trial 824 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.1043943437087171, 'n_estimators': 526, 'subsample': 0.5298231319110035, 'colsample_bytree': 0.9650035430167251, 'reg_alpha': 6.271309115779923, 'reg_lambda': 2.8682479418390505, 'gamma': 3.0463038607914052}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:08,864] Trial 825 finished with value: 0.7196 and parameters: {'max_depth': 8, 'learning_rate': 0.09474354827606336, 'n_estimators': 553, 'subsample': 0.5129258618601226, 'colsample_bytree': 0.9906730667479139, 'reg_alpha': 6.717007813492201, 'reg_lambda': 4.007029532689165, 'gamma': 3.238661940558449}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:09,352] Trial 826 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.06560415481295012, 'n_estimators': 568, 'subsample': 0.5487658230580413, 'colsample_bytree': 0.9762305535197934, 'reg_alpha': 5.142547266485668, 'reg_lambda': 3.647345234074303, 'gamma': 2.9724579345344018}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:10,016] Trial 827 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10478781885308447, 'n_estimators': 926, 'subsample': 0.5654879315816963, 'colsample_bytree': 0.9653340696464235, 'reg_alpha': 6.118201867035442, 'reg_lambda': 3.3363547359652457, 'gamma': 3.362704169163385}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:10,570] Trial 828 finished with value: 0.7136 and parameters: {'max_depth': 5, 'learning_rate': 0.10125324322079828, 'n_estimators': 750, 'subsample': 0.8445980820569354, 'colsample_bytree': 0.9992338232006993, 'reg_alpha': 1.7991153332717955, 'reg_lambda': 3.152455180211947, 'gamma': 3.151723493604737}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:11,030] Trial 829 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.1058490791008289, 'n_estimators': 531, 'subsample': 0.5390469632690232, 'colsample_bytree': 0.9813512494414979, 'reg_alpha': 6.36007245804462, 'reg_lambda': 3.077460826515673, 'gamma': 3.2524134210575397}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:11,691] Trial 830 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.08946369152167816, 'n_estimators': 911, 'subsample': 0.5267351983044686, 'colsample_bytree': 0.9633050995080589, 'reg_alpha': 5.886278262615196, 'reg_lambda': 3.8924237789670864, 'gamma': 3.0556480688682464}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:12,333] Trial 831 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.08080476060478184, 'n_estimators': 800, 'subsample': 0.5528589503209236, 'colsample_bytree': 0.973760222144015, 'reg_alpha': 5.431231835144385, 'reg_lambda': 5.98801453681952, 'gamma': 3.328347153809921}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:12,767] Trial 832 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.09769554323865538, 'n_estimators': 541, 'subsample': 0.5824970414266225, 'colsample_bytree': 0.9914047424689458, 'reg_alpha': 5.995461032902749, 'reg_lambda': 3.681847954716138, 'gamma': 3.4468253925286163}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:13,211] Trial 833 finished with value: 0.7292 and parameters: {'max_depth': 5, 'learning_rate': 0.1018192021933254, 'n_estimators': 516, 'subsample': 0.5420192365291295, 'colsample_bytree': 0.984208839063179, 'reg_alpha': 6.442806679636576, 'reg_lambda': 3.3425867497514576, 'gamma': 3.1151771597301723}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:13,678] Trial 834 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.09599977880811893, 'n_estimators': 559, 'subsample': 0.5224544619455522, 'colsample_bytree': 0.9840899803278358, 'reg_alpha': 6.600775008801716, 'reg_lambda': 3.1498278732933933, 'gamma': 2.9621951292314748}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:14,132] Trial 835 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.08993743959191616, 'n_estimators': 517, 'subsample': 0.5360463139429813, 'colsample_bytree': 0.999638313199548, 'reg_alpha': 6.913986812054439, 'reg_lambda': 2.9211277783202814, 'gamma': 3.1207074426179386}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:14,823] Trial 836 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.09837881807374219, 'n_estimators': 979, 'subsample': 0.5605281824814942, 'colsample_bytree': 0.9834527131613535, 'reg_alpha': 6.612594661987288, 'reg_lambda': 3.501260766138372, 'gamma': 3.0320152016989574}. Best is trial 563 with value: 0.7312.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:15,295] Trial 837 finished with value: 0.7324 and parameters: {'max_depth': 5, 'learning_rate': 0.09976068728329174, 'n_estimators': 535, 'subsample': 0.5457055989159076, 'colsample_bytree': 0.9727094003502108, 'reg_alpha': 6.45550321235626, 'reg_lambda': 3.457148566236242, 'gamma': 2.9296956909032517}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:15,760] Trial 838 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09253552434173529, 'n_estimators': 555, 'subsample': 0.5321927473974254, 'colsample_bytree': 0.981851596206218, 'reg_alpha': 6.70154125235278, 'reg_lambda': 3.42111324492836, 'gamma': 2.922194809923614}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:16,241] Trial 839 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10129175333854765, 'n_estimators': 540, 'subsample': 0.5425209214534423, 'colsample_bytree': 0.9737005153918251, 'reg_alpha': 6.464358723570224, 'reg_lambda': 3.2603700829570035, 'gamma': 2.9512130984239735}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:16,724] Trial 840 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.09469625704137696, 'n_estimators': 572, 'subsample': 0.5226421830629693, 'colsample_bytree': 0.9865643869538173, 'reg_alpha': 6.497968003606314, 'reg_lambda': 3.6532536578895716, 'gamma': 3.1633718345210426}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:17,199] Trial 841 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.09892084598372758, 'n_estimators': 540, 'subsample': 0.5152755989495471, 'colsample_bytree': 0.990886056600548, 'reg_alpha': 6.927967462733947, 'reg_lambda': 3.7985123278793202, 'gamma': 2.896466072522108}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:17,660] Trial 842 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.10531514275678251, 'n_estimators': 560, 'subsample': 0.5354603575802243, 'colsample_bytree': 0.9739320924530557, 'reg_alpha': 6.727477987870511, 'reg_lambda': 3.404210752861953, 'gamma': 3.0817553110820737}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:18,116] Trial 843 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.10351539121853544, 'n_estimators': 528, 'subsample': 0.5458860521303052, 'colsample_bytree': 0.9750846523849942, 'reg_alpha': 6.442494356548266, 'reg_lambda': 3.058346936819576, 'gamma': 3.1784736480292977}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:18,604] Trial 844 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.07168687132393119, 'n_estimators': 582, 'subsample': 0.5298696128860877, 'colsample_bytree': 0.9908987166997821, 'reg_alpha': 6.302452736110659, 'reg_lambda': 3.1805558948153894, 'gamma': 2.9986241490008467}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:19,055] Trial 845 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.08487596603250444, 'n_estimators': 516, 'subsample': 0.5499835234352216, 'colsample_bytree': 0.9676656936388897, 'reg_alpha': 6.828301616385567, 'reg_lambda': 2.669690568557586, 'gamma': 3.1085516124716217}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:19,511] Trial 846 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10711727467381676, 'n_estimators': 543, 'subsample': 0.5431718904339888, 'colsample_bytree': 0.9822649529805034, 'reg_alpha': 6.613890821431147, 'reg_lambda': 3.3873252928779656, 'gamma': 2.894676195699266}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:19,998] Trial 847 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.08662753138525081, 'n_estimators': 526, 'subsample': 0.5081726126489959, 'colsample_bytree': 0.9995411068999407, 'reg_alpha': 6.402268428034253, 'reg_lambda': 2.9437613631119492, 'gamma': 3.2655253455790647}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:20,448] Trial 848 finished with value: 0.7248 and parameters: {'max_depth': 7, 'learning_rate': 0.09564054604459671, 'n_estimators': 545, 'subsample': 0.5351245007041718, 'colsample_bytree': 0.9655125537207971, 'reg_alpha': 7.241840205085899, 'reg_lambda': 3.6425933721472794, 'gamma': 3.199750966770716}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:20,942] Trial 849 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.10109949753655839, 'n_estimators': 556, 'subsample': 0.5209937210460153, 'colsample_bytree': 0.9751811452042375, 'reg_alpha': 6.606559644120545, 'reg_lambda': 3.8518226068489074, 'gamma': 3.0080175300655703}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:21,404] Trial 850 finished with value: 0.7296 and parameters: {'max_depth': 5, 'learning_rate': 0.10915839379287418, 'n_estimators': 523, 'subsample': 0.5554974767755207, 'colsample_bytree': 0.9842561582225945, 'reg_alpha': 6.313130788000496, 'reg_lambda': 3.2549858926295716, 'gamma': 3.0828292255049687}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:21,903] Trial 851 finished with value: 0.7292 and parameters: {'max_depth': 5, 'learning_rate': 0.10707021452629084, 'n_estimators': 516, 'subsample': 0.554409179356569, 'colsample_bytree': 0.9646110456397082, 'reg_alpha': 6.289118212865301, 'reg_lambda': 3.182770529099462, 'gamma': 2.9369164445144667}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:22,343] Trial 852 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.10877879142044054, 'n_estimators': 524, 'subsample': 0.5406971617761211, 'colsample_bytree': 0.9732165129269428, 'reg_alpha': 6.538130831137427, 'reg_lambda': 3.045832179508609, 'gamma': 2.8810605542313477}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:22,824] Trial 853 finished with value: 0.7304 and parameters: {'max_depth': 5, 'learning_rate': 0.10789073212210504, 'n_estimators': 533, 'subsample': 0.5494918664467614, 'colsample_bytree': 0.964631182248661, 'reg_alpha': 6.404245671070886, 'reg_lambda': 3.333136912126734, 'gamma': 3.0281748100583408}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:23,282] Trial 854 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10540183820020006, 'n_estimators': 536, 'subsample': 0.528852950293629, 'colsample_bytree': 0.9665125341962648, 'reg_alpha': 6.766981646212853, 'reg_lambda': 3.2297654810802445, 'gamma': 3.0551620909302}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:23,729] Trial 855 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.10806948478268338, 'n_estimators': 515, 'subsample': 0.552944078656113, 'colsample_bytree': 0.97852176899273, 'reg_alpha': 6.3943822105523545, 'reg_lambda': 2.7871463192590475, 'gamma': 3.0120897682139125}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:24,184] Trial 856 finished with value: 0.7132 and parameters: {'max_depth': 5, 'learning_rate': 0.10172598029063273, 'n_estimators': 563, 'subsample': 0.986124076344764, 'colsample_bytree': 0.966524100927344, 'reg_alpha': 6.511627259720904, 'reg_lambda': 3.5074030031987755, 'gamma': 3.0951596799631527}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:24,657] Trial 857 finished with value: 0.7264 and parameters: {'max_depth': 8, 'learning_rate': 0.10740262023528939, 'n_estimators': 541, 'subsample': 0.5392364060368574, 'colsample_bytree': 0.978845968807855, 'reg_alpha': 6.323766082126828, 'reg_lambda': 3.124465934337469, 'gamma': 2.958223829695997}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:25,093] Trial 858 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.11012572579375793, 'n_estimators': 526, 'subsample': 0.5524149877962512, 'colsample_bytree': 0.96385056204136, 'reg_alpha': 6.7306583739432835, 'reg_lambda': 3.316390730036598, 'gamma': 3.1074026813624003}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:25,551] Trial 859 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.1011238382640418, 'n_estimators': 513, 'subsample': 0.5163543364339505, 'colsample_bytree': 0.9858799797501524, 'reg_alpha': 6.457394191252729, 'reg_lambda': 3.4131984539961713, 'gamma': 2.9547968691503996}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:26,022] Trial 860 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.09605772536252102, 'n_estimators': 580, 'subsample': 0.5281345587209436, 'colsample_bytree': 0.9719304105036294, 'reg_alpha': 6.884108491552627, 'reg_lambda': 3.066842514112987, 'gamma': 3.0781736317296744}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:26,489] Trial 861 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10945112752742114, 'n_estimators': 556, 'subsample': 0.5423672393373924, 'colsample_bytree': 0.961238517437114, 'reg_alpha': 6.303607236297053, 'reg_lambda': 3.3263965259135735, 'gamma': 3.158053736514107}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:26,934] Trial 862 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.10204102750697111, 'n_estimators': 531, 'subsample': 0.5598129868703307, 'colsample_bytree': 0.9907217115909377, 'reg_alpha': 6.589160073051804, 'reg_lambda': 2.925858205016667, 'gamma': 3.003108439553015}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:27,413] Trial 863 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.11029621898294686, 'n_estimators': 510, 'subsample': 0.5486043240127763, 'colsample_bytree': 0.9803387920690182, 'reg_alpha': 6.263017601813212, 'reg_lambda': 3.548424685399305, 'gamma': 2.942304731770088}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:27,878] Trial 864 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.09152062856029786, 'n_estimators': 547, 'subsample': 0.5359592912150201, 'colsample_bytree': 0.9707881654988777, 'reg_alpha': 6.706301927460988, 'reg_lambda': 3.1579908430146513, 'gamma': 3.153017851059166}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:28,329] Trial 865 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.10218974126686457, 'n_estimators': 529, 'subsample': 0.5587880616947838, 'colsample_bytree': 0.9607269304667682, 'reg_alpha': 6.994851381205596, 'reg_lambda': 3.5418446988631294, 'gamma': 3.047282305103106}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:28,768] Trial 866 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.11054872780589324, 'n_estimators': 509, 'subsample': 0.5089069088956958, 'colsample_bytree': 0.9814518529125248, 'reg_alpha': 6.474735725793734, 'reg_lambda': 2.633109288004921, 'gamma': 2.8775811172329697}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:29,254] Trial 867 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.09679946068833113, 'n_estimators': 561, 'subsample': 0.5241744215223412, 'colsample_bytree': 0.9920544420102815, 'reg_alpha': 6.2292392782659265, 'reg_lambda': 3.2222293306057983, 'gamma': 3.1954997377999383}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:29,729] Trial 868 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.10454949696266885, 'n_estimators': 590, 'subsample': 0.549660610888304, 'colsample_bytree': 0.9711255971855376, 'reg_alpha': 6.331760204796634, 'reg_lambda': 3.37402603485446, 'gamma': 3.0877134968460727}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:30,188] Trial 869 finished with value: 0.7212 and parameters: {'max_depth': 5, 'learning_rate': 0.11234655261113695, 'n_estimators': 536, 'subsample': 0.537660978482362, 'colsample_bytree': 0.9622314777556977, 'reg_alpha': 6.567038036619149, 'reg_lambda': 2.9252694843137688, 'gamma': 3.235689328096988}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:30,623] Trial 870 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.09269138949914046, 'n_estimators': 513, 'subsample': 0.5454731712866329, 'colsample_bytree': 0.9852631488086193, 'reg_alpha': 7.052170263755553, 'reg_lambda': 3.825282128217571, 'gamma': 3.0006277110368504}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:31,109] Trial 871 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.10615828795321683, 'n_estimators': 565, 'subsample': 0.570158439763057, 'colsample_bytree': 0.8074729945712599, 'reg_alpha': 6.247792088668115, 'reg_lambda': 2.9814615819646164, 'gamma': 2.853123674436646}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:31,558] Trial 872 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.09898855161903619, 'n_estimators': 546, 'subsample': 0.5317007235159983, 'colsample_bytree': 0.9745764045698133, 'reg_alpha': 6.774462307499724, 'reg_lambda': 3.6663398156815203, 'gamma': 3.1273914576830584}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:31,990] Trial 873 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.11177519136534873, 'n_estimators': 502, 'subsample': 0.557525479972749, 'colsample_bytree': 0.9605199978326471, 'reg_alpha': 6.406560743995571, 'reg_lambda': 4.089225257505396, 'gamma': 3.2421401608965237}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:32,652] Trial 874 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.08748538850080104, 'n_estimators': 885, 'subsample': 0.5174430639109538, 'colsample_bytree': 0.9913366101897503, 'reg_alpha': 6.649411747242584, 'reg_lambda': 3.449033327754944, 'gamma': 2.9238531516743813}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:33,110] Trial 875 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10253420511233204, 'n_estimators': 534, 'subsample': 0.5451247147746399, 'colsample_bytree': 0.9785078982852262, 'reg_alpha': 6.268588864460447, 'reg_lambda': 3.1356264155092375, 'gamma': 3.067691398438199}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:33,578] Trial 876 finished with value: 0.7216 and parameters: {'max_depth': 5, 'learning_rate': 0.0969009424770101, 'n_estimators': 576, 'subsample': 0.5639977789859408, 'colsample_bytree': 0.9706158226605024, 'reg_alpha': 6.459982244044672, 'reg_lambda': 3.22299524774676, 'gamma': 3.1845755178416044}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:34,018] Trial 877 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11333586280568045, 'n_estimators': 513, 'subsample': 0.5000981334908556, 'colsample_bytree': 0.9607301531822934, 'reg_alpha': 6.171399776600773, 'reg_lambda': 3.6283743223931206, 'gamma': 3.8577791224214666}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:34,460] Trial 878 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.10680616159141156, 'n_estimators': 526, 'subsample': 0.5314588363453338, 'colsample_bytree': 0.9827173260123044, 'reg_alpha': 6.584848440318435, 'reg_lambda': 2.863118006052818, 'gamma': 2.9934501631277977}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:34,972] Trial 879 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.07819396241349078, 'n_estimators': 550, 'subsample': 0.5524404166154403, 'colsample_bytree': 0.9693928756723964, 'reg_alpha': 6.154243480407638, 'reg_lambda': 3.8312928259756736, 'gamma': 3.279183831811445}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:35,414] Trial 880 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.09283035242042546, 'n_estimators': 522, 'subsample': 0.543347628415762, 'colsample_bytree': 0.9923213860452356, 'reg_alpha': 6.849843471656175, 'reg_lambda': 3.3780059822129176, 'gamma': 3.1129274080531455}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:35,871] Trial 881 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10116652131932327, 'n_estimators': 499, 'subsample': 0.525318918535534, 'colsample_bytree': 0.9581947398817152, 'reg_alpha': 6.4111587549997955, 'reg_lambda': 3.4925421243734136, 'gamma': 2.8568916751770845}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:36,325] Trial 882 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.11298677959977246, 'n_estimators': 543, 'subsample': 0.5561846127573866, 'colsample_bytree': 0.9997062734091955, 'reg_alpha': 6.142510594380221, 'reg_lambda': 3.244346734848209, 'gamma': 3.1906432750744447}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:36,819] Trial 883 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.10539038901689023, 'n_estimators': 559, 'subsample': 0.5391199761041419, 'colsample_bytree': 0.9815188986090846, 'reg_alpha': 6.579833910516518, 'reg_lambda': 4.057821965877668, 'gamma': 2.9511030519508865}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:37,515] Trial 884 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.11425688149197562, 'n_estimators': 997, 'subsample': 0.5663523465461037, 'colsample_bytree': 0.9706681534829101, 'reg_alpha': 7.093633841074963, 'reg_lambda': 3.547579394660589, 'gamma': 3.0490475609692202}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:37,952] Trial 885 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.09531039312747233, 'n_estimators': 503, 'subsample': 0.5517505633213189, 'colsample_bytree': 0.979008928074985, 'reg_alpha': 6.836712399141597, 'reg_lambda': 2.382781651794208, 'gamma': 3.7869545060782976}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:38,636] Trial 886 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10843841195787174, 'n_estimators': 959, 'subsample': 0.5210062730725931, 'colsample_bytree': 0.9588142154681155, 'reg_alpha': 6.340297089631293, 'reg_lambda': 3.201724761330348, 'gamma': 3.2944579551665503}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:39,101] Trial 887 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.08808027966546556, 'n_estimators': 528, 'subsample': 0.5339033210048689, 'colsample_bytree': 0.9894783384382853, 'reg_alpha': 6.18975123661369, 'reg_lambda': 3.642814670903714, 'gamma': 3.1646537776488604}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:39,657] Trial 888 finished with value: 0.7188 and parameters: {'max_depth': 5, 'learning_rate': 0.10179645810239864, 'n_estimators': 727, 'subsample': 0.8782974843315443, 'colsample_bytree': 0.9994418143515992, 'reg_alpha': 6.674419699908514, 'reg_lambda': 2.769459875701068, 'gamma': 2.911226172360732}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:40,160] Trial 889 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.11436550992818771, 'n_estimators': 586, 'subsample': 0.5736197903891835, 'colsample_bytree': 0.9678183304713407, 'reg_alpha': 6.431901566968824, 'reg_lambda': 5.7422965593060065, 'gamma': 3.315576628438369}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:40,616] Trial 890 finished with value: 0.7284 and parameters: {'max_depth': 5, 'learning_rate': 0.10833093369003277, 'n_estimators': 541, 'subsample': 0.5422908297894568, 'colsample_bytree': 0.9846580735547229, 'reg_alpha': 6.143917153647272, 'reg_lambda': 3.0181414015454298, 'gamma': 3.0575763498080084}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:41,086] Trial 891 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.09659182602853804, 'n_estimators': 518, 'subsample': 0.5610009430577859, 'colsample_bytree': 0.9562112026617507, 'reg_alpha': 6.33817377107729, 'reg_lambda': 3.332408566135064, 'gamma': 3.1888056441912824}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:41,700] Trial 892 finished with value: 0.726 and parameters: {'max_depth': 7, 'learning_rate': 0.11606769219907775, 'n_estimators': 794, 'subsample': 0.5115923943423215, 'colsample_bytree': 0.974411950109582, 'reg_alpha': 6.104016804849513, 'reg_lambda': 3.8173407348781394, 'gamma': 2.838495079233582}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:42,173] Trial 893 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10539793559228278, 'n_estimators': 572, 'subsample': 0.5491530171880605, 'colsample_bytree': 0.9650407504163314, 'reg_alpha': 6.787118075830753, 'reg_lambda': 2.9952121466555477, 'gamma': 3.3801194676071398}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:42,604] Trial 894 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.0981397351651016, 'n_estimators': 496, 'subsample': 0.5297863745656419, 'colsample_bytree': 0.9902681850735614, 'reg_alpha': 6.605145358185544, 'reg_lambda': 3.5075956108807635, 'gamma': 2.992228136250914}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:43,082] Trial 895 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.0891241281870263, 'n_estimators': 553, 'subsample': 0.7283269538142929, 'colsample_bytree': 0.9761358682595085, 'reg_alpha': 7.152976120432876, 'reg_lambda': 3.371019835188049, 'gamma': 3.085999682894863}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:43,710] Trial 896 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.10982006186020239, 'n_estimators': 836, 'subsample': 0.5572234804072808, 'colsample_bytree': 0.9559247980028044, 'reg_alpha': 6.458057982000677, 'reg_lambda': 3.2082100172672066, 'gamma': 3.2160115803517666}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:44,198] Trial 897 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.11798695820458621, 'n_estimators': 520, 'subsample': 0.5393109851690474, 'colsample_bytree': 0.9820199947105975, 'reg_alpha': 6.097257028749286, 'reg_lambda': 3.6219550941294254, 'gamma': 3.687386567826904}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:44,706] Trial 898 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.10139159002287446, 'n_estimators': 531, 'subsample': 0.5681375868537135, 'colsample_bytree': 0.968309038621589, 'reg_alpha': 6.362078996010321, 'reg_lambda': 2.6353658034872396, 'gamma': 3.3310050299311413}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:45,222] Trial 899 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.08081440048612959, 'n_estimators': 501, 'subsample': 0.5233686299927891, 'colsample_bytree': 0.9904261766650221, 'reg_alpha': 6.022969705521464, 'reg_lambda': 2.9199048990035408, 'gamma': 2.9374727858565604}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:45,696] Trial 900 finished with value: 0.724 and parameters: {'max_depth': 10, 'learning_rate': 0.11522274646148396, 'n_estimators': 548, 'subsample': 0.547987467270221, 'colsample_bytree': 0.9562166192103603, 'reg_alpha': 6.242912064026245, 'reg_lambda': 3.948673202769913, 'gamma': 3.108876203650073}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:46,216] Trial 901 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10642073094877173, 'n_estimators': 603, 'subsample': 0.5333963844191941, 'colsample_bytree': 0.9782293883777735, 'reg_alpha': 6.873730307828782, 'reg_lambda': 3.3515550254406703, 'gamma': 3.4496089917907495}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:46,717] Trial 902 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.09316896833338845, 'n_estimators': 565, 'subsample': 0.5562099592193295, 'colsample_bytree': 0.9676635633770588, 'reg_alpha': 6.606229669410152, 'reg_lambda': 3.131267525613353, 'gamma': 3.2313715983522906}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:47,190] Trial 903 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.11250575310857149, 'n_estimators': 517, 'subsample': 0.54233487364638, 'colsample_bytree': 0.9912849101528843, 'reg_alpha': 6.03796214330883, 'reg_lambda': 4.191679489932127, 'gamma': 3.0101105539217863}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:47,623] Trial 904 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.10162673265710187, 'n_estimators': 535, 'subsample': 0.5743815972098786, 'colsample_bytree': 0.7880554000314314, 'reg_alpha': 6.227438241394324, 'reg_lambda': 3.7517092814281923, 'gamma': 3.985391427006977}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:48,064] Trial 905 finished with value: 0.722 and parameters: {'max_depth': 5, 'learning_rate': 0.11909686762335359, 'n_estimators': 493, 'subsample': 0.5112053893107229, 'colsample_bytree': 0.9642324566944124, 'reg_alpha': 6.469671853918671, 'reg_lambda': 3.3015405873850288, 'gamma': 2.8245513991123152}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:48,528] Trial 906 finished with value: 0.73 and parameters: {'max_depth': 5, 'learning_rate': 0.10628100091305942, 'n_estimators': 505, 'subsample': 0.5617379687877595, 'colsample_bytree': 0.97800336897851, 'reg_alpha': 5.996706650470481, 'reg_lambda': 3.5186851835263524, 'gamma': 3.2607255013034186}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:48,972] Trial 907 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.08632896313866417, 'n_estimators': 489, 'subsample': 0.5788217633925842, 'colsample_bytree': 0.9818975672074268, 'reg_alpha': 5.937602515796298, 'reg_lambda': 3.88226878822539, 'gamma': 3.3314614200546537}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:49,406] Trial 908 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.09911197733357627, 'n_estimators': 510, 'subsample': 0.5931911472465251, 'colsample_bytree': 0.9923148026467279, 'reg_alpha': 5.94172264705961, 'reg_lambda': 3.639772394196023, 'gamma': 3.40920112699252}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:49,861] Trial 909 finished with value: 0.7168 and parameters: {'max_depth': 9, 'learning_rate': 0.09310809343658767, 'n_estimators': 536, 'subsample': 0.5716199059316843, 'colsample_bytree': 0.9816906360758642, 'reg_alpha': 9.111125187612256, 'reg_lambda': 3.5384468221618466, 'gamma': 3.2598248938477505}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:50,310] Trial 910 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.11208566208884471, 'n_estimators': 561, 'subsample': 0.5640433494419094, 'colsample_bytree': 0.973733461132989, 'reg_alpha': 6.021641979928871, 'reg_lambda': 3.4874014620551925, 'gamma': 3.4624435248435397}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:50,755] Trial 911 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.10543596573358621, 'n_estimators': 493, 'subsample': 0.5228836286822912, 'colsample_bytree': 0.9932475075653342, 'reg_alpha': 5.853005338376284, 'reg_lambda': 3.741520256422629, 'gamma': 3.2950777786634466}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:51,190] Trial 912 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.12083700619618416, 'n_estimators': 506, 'subsample': 0.5654719297038882, 'colsample_bytree': 0.9996699077384719, 'reg_alpha': 7.321144953726524, 'reg_lambda': 3.971520165676597, 'gamma': 3.219647353475436}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:51,689] Trial 913 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.09705233495224386, 'n_estimators': 586, 'subsample': 0.5482301051173883, 'colsample_bytree': 0.9839852065028317, 'reg_alpha': 6.98947100191431, 'reg_lambda': 3.3791307165414683, 'gamma': 3.6203456195476194}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:52,158] Trial 914 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.116332501994776, 'n_estimators': 546, 'subsample': 0.538362627858058, 'colsample_bytree': 0.9747579650882704, 'reg_alpha': 6.088913556175063, 'reg_lambda': 3.6621423841022107, 'gamma': 3.392076546110215}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:52,640] Trial 915 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.10935535440985412, 'n_estimators': 526, 'subsample': 0.5824952066035332, 'colsample_bytree': 0.9848176652681967, 'reg_alpha': 5.923808827783894, 'reg_lambda': 3.4322215402457035, 'gamma': 3.165579590999832}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:53,158] Trial 916 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.10066836771494773, 'n_estimators': 570, 'subsample': 0.5554172142172457, 'colsample_bytree': 0.9730322197843564, 'reg_alpha': 6.182517302515318, 'reg_lambda': 7.991634502626006, 'gamma': 3.343207259866383}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:53,894] Trial 917 finished with value: 0.7228 and parameters: {'max_depth': 5, 'learning_rate': 0.08900621167575053, 'n_estimators': 917, 'subsample': 0.6154372147137875, 'colsample_bytree': 0.9588848019387861, 'reg_alpha': 6.680096362672749, 'reg_lambda': 3.544832589659978, 'gamma': 3.5494627651143693}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:54,336] Trial 918 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.12147082521345347, 'n_estimators': 510, 'subsample': 0.5308109599079718, 'colsample_bytree': 0.9992029643465483, 'reg_alpha': 5.832052369274374, 'reg_lambda': 3.825966542994652, 'gamma': 3.2485905023178923}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:54,800] Trial 919 finished with value: 0.7208 and parameters: {'max_depth': 7, 'learning_rate': 0.11403130304283504, 'n_estimators': 532, 'subsample': 0.5172639628248986, 'colsample_bytree': 0.9998633574595924, 'reg_alpha': 5.009526676400748, 'reg_lambda': 6.197160769472015, 'gamma': 3.1284849713580414}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:55,225] Trial 920 finished with value: 0.722 and parameters: {'max_depth': 8, 'learning_rate': 0.10402936772366396, 'n_estimators': 487, 'subsample': 0.5458821910005406, 'colsample_bytree': 0.9841490442794179, 'reg_alpha': 6.453825506117824, 'reg_lambda': 4.280295279987693, 'gamma': 3.302000434377681}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:55,808] Trial 921 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.09627645333294137, 'n_estimators': 767, 'subsample': 0.5630004384473996, 'colsample_bytree': 0.9736693429870942, 'reg_alpha': 6.023825071176676, 'reg_lambda': 1.9980224098869028, 'gamma': 3.5090353655915876}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:56,265] Trial 922 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.12149059413775318, 'n_estimators': 556, 'subsample': 0.5347575818913586, 'colsample_bytree': 0.9536011058188341, 'reg_alpha': 6.255093020237559, 'reg_lambda': 3.034485443817072, 'gamma': 3.1789400016579807}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:56,708] Trial 923 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.11136021155673198, 'n_estimators': 522, 'subsample': 0.553722611982967, 'colsample_bytree': 0.9674618014087815, 'reg_alpha': 6.839924082696577, 'reg_lambda': 8.088250285482124, 'gamma': 3.388641207054319}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:57,191] Trial 924 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10708532261395842, 'n_estimators': 545, 'subsample': 0.5428313800885549, 'colsample_bytree': 0.9843830017680436, 'reg_alpha': 5.81228994250182, 'reg_lambda': 4.138553800596563, 'gamma': 3.10984900730258}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:57,615] Trial 925 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.09257205908369849, 'n_estimators': 502, 'subsample': 0.5666550588093799, 'colsample_bytree': 0.9766496317851291, 'reg_alpha': 6.092091273916691, 'reg_lambda': 8.240605180088687, 'gamma': 3.7602337918443567}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:58,088] Trial 926 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.11572008923916965, 'n_estimators': 529, 'subsample': 0.5270910850292474, 'colsample_bytree': 0.9903937438566097, 'reg_alpha': 6.50400221567501, 'reg_lambda': 3.2524699967835486, 'gamma': 3.2668096353268994}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:58,731] Trial 927 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10164109822669601, 'n_estimators': 855, 'subsample': 0.5582782971383994, 'colsample_bytree': 0.9547507140436626, 'reg_alpha': 6.2578271600622255, 'reg_lambda': 3.718874154186078, 'gamma': 3.4264365789461335}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:59,165] Trial 928 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.1244959077239606, 'n_estimators': 488, 'subsample': 0.5083095819721161, 'colsample_bytree': 0.9640504337241986, 'reg_alpha': 5.653466399621389, 'reg_lambda': 3.443418114190331, 'gamma': 3.6366536236618403}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:54:59,716] Trial 929 finished with value: 0.7276 and parameters: {'max_depth': 5, 'learning_rate': 0.0822811113024823, 'n_estimators': 587, 'subsample': 0.5465707124827945, 'colsample_bytree': 0.9759439286124465, 'reg_alpha': 5.909816854102523, 'reg_lambda': 3.1923907535096174, 'gamma': 3.139878556441147}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:54:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:00,311] Trial 930 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.10911131356528529, 'n_estimators': 710, 'subsample': 0.537456208023085, 'colsample_bytree': 0.9905877056932284, 'reg_alpha': 6.66426272421113, 'reg_lambda': 8.341994022585425, 'gamma': 3.2452055211434083}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:00,816] Trial 931 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.1169253444486426, 'n_estimators': 547, 'subsample': 0.5843013949003605, 'colsample_bytree': 0.9671274382747181, 'reg_alpha': 7.040590350628292, 'reg_lambda': 5.538453949435328, 'gamma': 3.4858788913085803}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:01,268] Trial 932 finished with value: 0.726 and parameters: {'max_depth': 5, 'learning_rate': 0.10376169517122777, 'n_estimators': 510, 'subsample': 0.7069635354308981, 'colsample_bytree': 0.9575725848228516, 'reg_alpha': 6.387429572478773, 'reg_lambda': 8.444220197996811, 'gamma': 3.0612732486031446}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:01,802] Trial 933 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.09594168090549862, 'n_estimators': 564, 'subsample': 0.5228908280474086, 'colsample_bytree': 0.9820872283597466, 'reg_alpha': 5.038883547032894, 'reg_lambda': 7.80950441587753, 'gamma': 3.3261332302906452}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:02,262] Trial 934 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12387401568119065, 'n_estimators': 529, 'subsample': 0.5517745582080904, 'colsample_bytree': 0.9706161782123044, 'reg_alpha': 6.129699616616579, 'reg_lambda': 3.398925186912258, 'gamma': 3.2041895111662653}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:02,737] Trial 935 finished with value: 0.7216 and parameters: {'max_depth': 7, 'learning_rate': 0.11060105859347258, 'n_estimators': 510, 'subsample': 0.5680865405868326, 'colsample_bytree': 0.760383322662957, 'reg_alpha': 5.825414701133102, 'reg_lambda': 2.8244430183402844, 'gamma': 3.0757287699319664}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:03,180] Trial 936 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.0864910300733962, 'n_estimators': 479, 'subsample': 0.5343998623994691, 'colsample_bytree': 0.9884959764330226, 'reg_alpha': 5.528415363114964, 'reg_lambda': 3.997509523396419, 'gamma': 3.3595990067383337}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:03,678] Trial 937 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.25641364381785836, 'n_estimators': 548, 'subsample': 0.5445451113061145, 'colsample_bytree': 0.9542167209097421, 'reg_alpha': 5.304175018233717, 'reg_lambda': 3.5379531152677477, 'gamma': 3.164170988120832}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:04,182] Trial 938 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.11809184005347101, 'n_estimators': 577, 'subsample': 0.5596640338706416, 'colsample_bytree': 0.9766770939232922, 'reg_alpha': 6.005901959229973, 'reg_lambda': 3.041237741059775, 'gamma': 3.9091486075212534}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:04,759] Trial 939 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1003485277847764, 'n_estimators': 603, 'subsample': 0.5718363630168876, 'colsample_bytree': 0.999851434292198, 'reg_alpha': 6.308257666685977, 'reg_lambda': 3.736315915057608, 'gamma': 3.4960599858185377}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:05,381] Trial 940 finished with value: 0.7152 and parameters: {'max_depth': 5, 'learning_rate': 0.09110462079634715, 'n_estimators': 535, 'subsample': 0.5182004504077731, 'colsample_bytree': 0.9620478676472803, 'reg_alpha': 5.680698952668271, 'reg_lambda': 8.213230896646468, 'gamma': 1.0739794859856127}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:05,831] Trial 941 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.10504566712002991, 'n_estimators': 497, 'subsample': 0.5307563412029016, 'colsample_bytree': 0.9824055764358213, 'reg_alpha': 6.7332753767811315, 'reg_lambda': 8.51413929901561, 'gamma': 3.0381087614312516}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:06,292] Trial 942 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.12439649770533272, 'n_estimators': 518, 'subsample': 0.5500530044010098, 'colsample_bytree': 0.9705557681005872, 'reg_alpha': 6.01079701428357, 'reg_lambda': 7.977879366642333, 'gamma': 3.2923550440357747}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:06,761] Trial 943 finished with value: 0.7292 and parameters: {'max_depth': 5, 'learning_rate': 0.11185613374583198, 'n_estimators': 563, 'subsample': 0.5398266962298215, 'colsample_bytree': 0.9510135480281885, 'reg_alpha': 6.471630228670592, 'reg_lambda': 3.270978050825117, 'gamma': 3.1558040376487764}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:07,212] Trial 944 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1165514485509356, 'n_estimators': 522, 'subsample': 0.5589672295012087, 'colsample_bytree': 0.9907076008763179, 'reg_alpha': 5.247420656652757, 'reg_lambda': 4.409999134151162, 'gamma': 3.414117582344659}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:07,802] Trial 945 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.09690940525257088, 'n_estimators': 782, 'subsample': 0.7975763169078987, 'colsample_bytree': 0.7460003950950092, 'reg_alpha': 5.570696029900041, 'reg_lambda': 3.5215252463186024, 'gamma': 3.6030271514013585}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:08,267] Trial 946 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.10623422427152714, 'n_estimators': 543, 'subsample': 0.5743579339741799, 'colsample_bytree': 0.9781319353757847, 'reg_alpha': 5.761042743027578, 'reg_lambda': 3.054041434547518, 'gamma': 2.9971779598462396}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:08,714] Trial 947 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.123761633090614, 'n_estimators': 504, 'subsample': 0.5283310340430367, 'colsample_bytree': 0.9649389195884674, 'reg_alpha': 6.24264402556328, 'reg_lambda': 3.7756588181540964, 'gamma': 3.2630323377138017}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:09,145] Trial 948 finished with value: 0.72 and parameters: {'max_depth': 5, 'learning_rate': 0.1006477309632776, 'n_estimators': 484, 'subsample': 0.547882666193679, 'colsample_bytree': 0.7253853573071947, 'reg_alpha': 6.859378002321768, 'reg_lambda': 8.566263719526688, 'gamma': 3.109224690893369}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:09,587] Trial 949 finished with value: 0.7192 and parameters: {'max_depth': 5, 'learning_rate': 0.11405407983865819, 'n_estimators': 535, 'subsample': 0.5095746349588621, 'colsample_bytree': 0.951930432446927, 'reg_alpha': 6.4779249296588794, 'reg_lambda': 8.132302152859625, 'gamma': 3.7046970248869164}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:10,154] Trial 950 finished with value: 0.7236 and parameters: {'max_depth': 5, 'learning_rate': 0.24007829356639077, 'n_estimators': 742, 'subsample': 0.6002293862556729, 'colsample_bytree': 0.9900037826782434, 'reg_alpha': 5.88836496429509, 'reg_lambda': 3.2815209946584907, 'gamma': 3.363339825595137}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:10,828] Trial 951 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.10835067062851363, 'n_estimators': 876, 'subsample': 0.5590795362023947, 'colsample_bytree': 0.9717112168453218, 'reg_alpha': 6.1186103856746135, 'reg_lambda': 3.6208089361935545, 'gamma': 3.216847628237658}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:11,324] Trial 952 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.11963265277927518, 'n_estimators': 551, 'subsample': 0.5390198356655078, 'colsample_bytree': 0.9616187671736324, 'reg_alpha': 5.434975977374739, 'reg_lambda': 5.347155636037415, 'gamma': 2.995353205013535}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:11,766] Trial 953 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.12731056725739875, 'n_estimators': 516, 'subsample': 0.5197592807547353, 'colsample_bytree': 0.9822186889961316, 'reg_alpha': 6.56497676555861, 'reg_lambda': 8.3663997491257, 'gamma': 3.495555983054427}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:12,280] Trial 954 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.09167133860783526, 'n_estimators': 575, 'subsample': 0.548342125311833, 'colsample_bytree': 0.9754866374548182, 'reg_alpha': 5.776846818204296, 'reg_lambda': 3.9200940272223996, 'gamma': 2.8830996193169898}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:13,004] Trial 955 finished with value: 0.72 and parameters: {'max_depth': 6, 'learning_rate': 0.1034390261949341, 'n_estimators': 954, 'subsample': 0.5348952853026034, 'colsample_bytree': 0.9515405042782334, 'reg_alpha': 5.088788132889613, 'reg_lambda': 3.4456476528043005, 'gamma': 3.0898444802784977}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:13,628] Trial 956 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.0969624542216497, 'n_estimators': 824, 'subsample': 0.5605015374588153, 'colsample_bytree': 0.9631529990215675, 'reg_alpha': 7.494140492739193, 'reg_lambda': 2.172311809959149, 'gamma': 3.2597110479062295}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:14,098] Trial 957 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.11133287024187219, 'n_estimators': 528, 'subsample': 0.5513561239695253, 'colsample_bytree': 0.9925826840872196, 'reg_alpha': 6.204609246096816, 'reg_lambda': 2.502297816402233, 'gamma': 3.394256538403116}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:14,539] Trial 958 finished with value: 0.7228 and parameters: {'max_depth': 8, 'learning_rate': 0.12095009104427226, 'n_estimators': 496, 'subsample': 0.578741553517826, 'colsample_bytree': 0.9699015261992555, 'reg_alpha': 5.558592933509893, 'reg_lambda': 2.842120926320933, 'gamma': 3.5804091530887914}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:14,979] Trial 959 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.11546873322347238, 'n_estimators': 476, 'subsample': 0.5273131078528736, 'colsample_bytree': 0.9853666490975624, 'reg_alpha': 5.960210561913388, 'reg_lambda': 7.90502444416261, 'gamma': 3.180011866781158}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:15,496] Trial 960 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.1256891076770993, 'n_estimators': 555, 'subsample': 0.5671288477965631, 'colsample_bytree': 0.9575828558938941, 'reg_alpha': 6.293266643166241, 'reg_lambda': 3.205535825046664, 'gamma': 3.309175004812943}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:15,956] Trial 961 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.08746479830872703, 'n_estimators': 509, 'subsample': 0.5442786835270671, 'colsample_bytree': 0.9813132468154699, 'reg_alpha': 6.683940678988531, 'reg_lambda': 8.656575162273782, 'gamma': 3.01284501882344}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:16,438] Trial 962 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.1053309216688991, 'n_estimators': 536, 'subsample': 0.539852686284248, 'colsample_bytree': 0.9989583985288994, 'reg_alpha': 4.930065855243136, 'reg_lambda': 8.35960096313238, 'gamma': 3.1373048162637334}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:17,084] Trial 963 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.10029619349475666, 'n_estimators': 591, 'subsample': 0.515740386322603, 'colsample_bytree': 0.9718239781382239, 'reg_alpha': 7.074788424935619, 'reg_lambda': 3.102262032088146, 'gamma': 2.95345237207823}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:17,579] Trial 964 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.11026766916251031, 'n_estimators': 564, 'subsample': 0.5546869052403788, 'colsample_bytree': 0.9634152666323522, 'reg_alpha': 5.402021455752679, 'reg_lambda': 3.646255808229918, 'gamma': 2.802441363679458}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:18,050] Trial 965 finished with value: 0.724 and parameters: {'max_depth': 7, 'learning_rate': 0.09466168909528641, 'n_estimators': 520, 'subsample': 0.5280014159410704, 'colsample_bytree': 0.9495039486312608, 'reg_alpha': 5.730700132418499, 'reg_lambda': 3.4129824993691127, 'gamma': 3.486615522124433}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:18,491] Trial 966 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.2230614587982841, 'n_estimators': 503, 'subsample': 0.8359665658422026, 'colsample_bytree': 0.9903455212309081, 'reg_alpha': 5.257731320074101, 'reg_lambda': 5.09018297797975, 'gamma': 3.2312036838438645}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:18,840] Trial 967 finished with value: 0.7208 and parameters: {'max_depth': 5, 'learning_rate': 0.11836194759979717, 'n_estimators': 354, 'subsample': 0.5023808730974633, 'colsample_bytree': 0.9801119296050382, 'reg_alpha': 6.032752106466874, 'reg_lambda': 7.755988413741377, 'gamma': 3.3756068723192802}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:19,300] Trial 968 finished with value: 0.7196 and parameters: {'max_depth': 5, 'learning_rate': 0.07766403374245923, 'n_estimators': 543, 'subsample': 0.5879625062133242, 'colsample_bytree': 0.9727662838200761, 'reg_alpha': 6.394015611330283, 'reg_lambda': 8.079229386232065, 'gamma': 3.691028648075698}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:19,738] Trial 969 finished with value: 0.726 and parameters: {'max_depth': 6, 'learning_rate': 0.12743010545948247, 'n_estimators': 487, 'subsample': 0.565573708220476, 'colsample_bytree': 0.9477410914507678, 'reg_alpha': 6.631653821943689, 'reg_lambda': 8.569199504643926, 'gamma': 3.0629241398774303}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:20,281] Trial 970 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.10824596656989076, 'n_estimators': 695, 'subsample': 0.5381882044061387, 'colsample_bytree': 0.9634017227982519, 'reg_alpha': 5.540591268573457, 'reg_lambda': 3.289160980262599, 'gamma': 3.7743603390121225}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:20,744] Trial 971 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.11412677299346435, 'n_estimators': 524, 'subsample': 0.5531876375753968, 'colsample_bytree': 0.9999445560846781, 'reg_alpha': 5.852929961136668, 'reg_lambda': 3.8150933305613224, 'gamma': 3.1511147101599235}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:21,297] Trial 972 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.08241196973894846, 'n_estimators': 546, 'subsample': 0.544336354157437, 'colsample_bytree': 0.9844694753576798, 'reg_alpha': 6.188206529821032, 'reg_lambda': 8.253235334327195, 'gamma': 3.2825025386630795}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:21,765] Trial 973 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.09811005068235502, 'n_estimators': 500, 'subsample': 0.5733528931003391, 'colsample_bytree': 0.9566643074520846, 'reg_alpha': 6.820057784699263, 'reg_lambda': 4.0809289719941875, 'gamma': 2.90571748359077}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:22,312] Trial 974 finished with value: 0.7184 and parameters: {'max_depth': 5, 'learning_rate': 0.12092018328912427, 'n_estimators': 573, 'subsample': 0.5266688122150842, 'colsample_bytree': 0.973733808137391, 'reg_alpha': 6.373082117907879, 'reg_lambda': 2.955476003097752, 'gamma': 3.0438926902296157}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:22,884] Trial 975 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.10213616770844972, 'n_estimators': 518, 'subsample': 0.5574030269923159, 'colsample_bytree': 0.8560486255276494, 'reg_alpha': 5.663434455866172, 'reg_lambda': 3.5528047703827434, 'gamma': 3.583769953256282}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:23,340] Trial 976 finished with value: 0.7224 and parameters: {'max_depth': 5, 'learning_rate': 0.12856051911568223, 'n_estimators': 475, 'subsample': 0.5329917826853442, 'colsample_bytree': 0.9898521728657987, 'reg_alpha': 6.02184026924497, 'reg_lambda': 8.405882613924522, 'gamma': 3.411767538694539}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:23,891] Trial 977 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.09162714048386418, 'n_estimators': 536, 'subsample': 0.5499749972750398, 'colsample_bytree': 0.818131386925101, 'reg_alpha': 5.168528712168687, 'reg_lambda': 8.629772927523272, 'gamma': 3.180564853660194}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:24,414] Trial 978 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.1077858318270291, 'n_estimators': 606, 'subsample': 0.562961069246627, 'colsample_bytree': 0.9802114651692159, 'reg_alpha': 5.41448488108846, 'reg_lambda': 3.4168450977303055, 'gamma': 3.2936222839112275}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:24,906] Trial 979 finished with value: 0.7252 and parameters: {'max_depth': 5, 'learning_rate': 0.11390803766226076, 'n_estimators': 557, 'subsample': 0.5169170514492315, 'colsample_bytree': 0.9472678202476956, 'reg_alpha': 6.534222748201944, 'reg_lambda': 5.891393850576105, 'gamma': 2.8972572860639745}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:25,369] Trial 980 finished with value: 0.7268 and parameters: {'max_depth': 5, 'learning_rate': 0.12428433860784477, 'n_estimators': 498, 'subsample': 0.5443382126426938, 'colsample_bytree': 0.9681304968735462, 'reg_alpha': 5.840123612109042, 'reg_lambda': 8.075790632889984, 'gamma': 3.0869509936660604}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:25,809] Trial 981 finished with value: 0.7164 and parameters: {'max_depth': 5, 'learning_rate': 0.1030251121466985, 'n_estimators': 520, 'subsample': 0.8632673393400663, 'colsample_bytree': 0.9996786340579505, 'reg_alpha': 6.13810205544497, 'reg_lambda': 2.71634377191661, 'gamma': 2.7959673083308383}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:26,284] Trial 982 finished with value: 0.7272 and parameters: {'max_depth': 5, 'learning_rate': 0.12023864939159341, 'n_estimators': 536, 'subsample': 0.5365132077506389, 'colsample_bytree': 0.959584293933963, 'reg_alpha': 7.178287191418023, 'reg_lambda': 3.122334390114136, 'gamma': 2.9886158139079644}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:26,824] Trial 983 finished with value: 0.7232 and parameters: {'max_depth': 6, 'learning_rate': 0.09609953286150741, 'n_estimators': 565, 'subsample': 0.5528923360974108, 'colsample_bytree': 0.9787523235971243, 'reg_alpha': 5.600125585959957, 'reg_lambda': 3.759100121124119, 'gamma': 3.4504651859023623}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:27,472] Trial 984 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.13090909724726327, 'n_estimators': 894, 'subsample': 0.5651237743886506, 'colsample_bytree': 0.9672787051031944, 'reg_alpha': 6.870893408783321, 'reg_lambda': 7.908348542575347, 'gamma': 3.2317961098194683}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:28,211] Trial 985 finished with value: 0.7232 and parameters: {'max_depth': 7, 'learning_rate': 0.1095058536183541, 'n_estimators': 976, 'subsample': 0.5232317294552746, 'colsample_bytree': 0.9894294161799537, 'reg_alpha': 6.37149774339723, 'reg_lambda': 7.7290784325442665, 'gamma': 3.3202843449187167}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:28,670] Trial 986 finished with value: 0.7288 and parameters: {'max_depth': 5, 'learning_rate': 0.1153428147316559, 'n_estimators': 510, 'subsample': 0.5395579204954776, 'colsample_bytree': 0.9559983545270289, 'reg_alpha': 5.893451609238833, 'reg_lambda': 4.844690504937391, 'gamma': 3.1155644348115756}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:29,350] Trial 987 finished with value: 0.7248 and parameters: {'max_depth': 5, 'learning_rate': 0.10297278700048022, 'n_estimators': 930, 'subsample': 0.5565314283337188, 'colsample_bytree': 0.9737319244784497, 'reg_alpha': 5.287577874055912, 'reg_lambda': 3.310576987402, 'gamma': 3.533797790043262}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:29,795] Trial 988 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.09014998971609287, 'n_estimators': 487, 'subsample': 0.5734928319064586, 'colsample_bytree': 0.9853658593919921, 'reg_alpha': 6.188883360745211, 'reg_lambda': 1.7409496584870743, 'gamma': 2.9909350026033583}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:30,378] Trial 989 finished with value: 0.724 and parameters: {'max_depth': 5, 'learning_rate': 0.12037222731530754, 'n_estimators': 727, 'subsample': 0.508214563997766, 'colsample_bytree': 0.9483222739254101, 'reg_alpha': 4.949141523650418, 'reg_lambda': 8.694304966260841, 'gamma': 3.834303696922541}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:30,748] Trial 990 finished with value: 0.7244 and parameters: {'max_depth': 6, 'learning_rate': 0.127753416824412, 'n_estimators': 376, 'subsample': 0.5465495601183378, 'colsample_bytree': 0.9650324771009995, 'reg_alpha': 5.697469401175085, 'reg_lambda': 3.610805523103041, 'gamma': 3.2007062143810563}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:31,212] Trial 991 finished with value: 0.7264 and parameters: {'max_depth': 5, 'learning_rate': 0.10894866518940825, 'n_estimators': 529, 'subsample': 0.5275406943937584, 'colsample_bytree': 0.9760737738131797, 'reg_alpha': 6.001863866319304, 'reg_lambda': 8.460792512737758, 'gamma': 3.356630200689568}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:31,834] Trial 992 finished with value: 0.7168 and parameters: {'max_depth': 5, 'learning_rate': 0.09894657869316746, 'n_estimators': 550, 'subsample': 0.5357522595349778, 'colsample_bytree': 0.9845295576860015, 'reg_alpha': 0.6367575047747351, 'reg_lambda': 3.4417169549532143, 'gamma': 2.8924658014749327}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:32,312] Trial 993 finished with value: 0.7256 and parameters: {'max_depth': 5, 'learning_rate': 0.11572297710722441, 'n_estimators': 578, 'subsample': 0.5857795031405526, 'colsample_bytree': 0.95616002791441, 'reg_alpha': 6.523938075331593, 'reg_lambda': 3.1185221492869113, 'gamma': 3.094862066713614}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:32,807] Trial 994 finished with value: 0.7244 and parameters: {'max_depth': 5, 'learning_rate': 0.08486626311640397, 'n_estimators': 468, 'subsample': 0.5618459083092789, 'colsample_bytree': 0.9999187931896266, 'reg_alpha': 5.414194202690939, 'reg_lambda': 4.418285351092913, 'gamma': 3.2185926566208996}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:33,389] Trial 995 finished with value: 0.7232 and parameters: {'max_depth': 5, 'learning_rate': 0.10500375776383489, 'n_estimators': 756, 'subsample': 0.545181529256121, 'colsample_bytree': 0.9674658370870625, 'reg_alpha': 6.645397775952785, 'reg_lambda': 3.9526238406191747, 'gamma': 3.654459548566865}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:33,821] Trial 996 finished with value: 0.7192 and parameters: {'max_depth': 5, 'learning_rate': 0.2677418636129903, 'n_estimators': 509, 'subsample': 0.5176400849242201, 'colsample_bytree': 0.9898118361786731, 'reg_alpha': 6.299778638151989, 'reg_lambda': 8.213797779364867, 'gamma': 3.406186399351093}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:34,294] Trial 997 finished with value: 0.728 and parameters: {'max_depth': 5, 'learning_rate': 0.09474454900049491, 'n_estimators': 538, 'subsample': 0.5533009654691589, 'colsample_bytree': 0.9441879015272272, 'reg_alpha': 5.7814626198000365, 'reg_lambda': 8.791857271755674, 'gamma': 3.0305094435385693}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:34,849] Trial 998 finished with value: 0.7212 and parameters: {'max_depth': 6, 'learning_rate': 0.12465373397906361, 'n_estimators': 669, 'subsample': 0.5332103100199647, 'colsample_bytree': 0.9759165974623121, 'reg_alpha': 6.1277011132343775, 'reg_lambda': 3.2622502233500517, 'gamma': 3.3120868958380143}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-03-19 00:55:35,271] Trial 999 finished with value: 0.716 and parameters: {'max_depth': 6, 'learning_rate': 0.11155156918305481, 'n_estimators': 495, 'subsample': 0.6437860241376769, 'colsample_bytree': 0.7719496656196834, 'reg_alpha': 3.442497941605648, 'reg_lambda': 3.6816576462459496, 'gamma': 4.119303894467433}. Best is trial 837 with value: 0.7324.\n",
      "c:\\Users\\dltjs\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:55:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 5, 'learning_rate': 0.09976068728329174, 'n_estimators': 535, 'subsample': 0.5457055989159076, 'colsample_bytree': 0.9727094003502108, 'reg_alpha': 6.45550321235626, 'reg_lambda': 3.457148566236242, 'gamma': 2.9296956909032517}\n",
      "Final Model Accuracy: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# 최적 파라미터 찾기\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "# Optuna 최적화 함수 정의\n",
    "def objective(trial):\n",
    "    # 하이퍼파라미터 탐색 공간 정의\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # 이진 분류\n",
    "        'eval_metric': 'logloss',  # 손실 함수\n",
    "        'booster': 'gbtree',  # 기본 부스터\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),  # 트리 깊이\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),  # 학습률\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),  # 트리 개수\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 데이터 샘플링 비율\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 피처 샘플링 비율\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),  # L1 정규화\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),  # L2 정규화\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),  # 리프 노드 분할 시 최소 손실 감소량\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 학습\n",
    "    model = xgb.XGBClassifier(**params, use_label_encoder=False)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 예측 및 평가\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy  # 높은 정확도를 목표로 최적화\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화 수행\n",
    "study = optuna.create_study(direction='maximize')  # 정확도를 높이는 방향으로 최적화\n",
    "study.optimize(objective, n_trials=1000)  # 50번 시도\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "\n",
    "# 최적의 하이퍼파라미터로 모델 학습\n",
    "best_params = study.best_params\n",
    "best_model = xgb.XGBClassifier(**best_params, use_label_encoder=False)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델 평가\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Final Model Accuracy:\", final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 정확도:\n",
      " 0.7585333333333333\n",
      "훈련 데이터 정밀도:\n",
      " 0.7096209912536443\n",
      "훈련 데이터 재현율:\n",
      " 0.4810276679841897\n",
      "==============================\n",
      "평가 데이터 정확도:\n",
      " 0.7324\n",
      "평가 데이터 정밀도:\n",
      " 0.6939890710382514\n",
      "평가 데이터 재현율:\n",
      " 0.43197278911564624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "\n",
    "# 평가 (accuracy_score 사용)\n",
    "print(\"훈련 데이터 정확도:\\n\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"훈련 데이터 정밀도:\\n\", precision_score(y_train, y_pred_train))\n",
    "print(\"훈련 데이터 재현율:\\n\", recall_score(y_train, y_pred_train))\n",
    "\n",
    "print('='*30)\n",
    "\n",
    "print(\"평가 데이터 정확도:\\n\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"평가 데이터 정밀도:\\n\", precision_score(y_test, y_pred_test))\n",
    "print(\"평가 데이터 재현율:\\n\", recall_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
