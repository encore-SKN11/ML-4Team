import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# 한글 폰트 설정
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# 1. 데이터 로드
df = pd.read_csv("./file/train.csv")

# 2. 데이터 전처리
# 결측값이 있는 행 제거
df = df.dropna()

# 범주형 변수(Label Encoding 적용)
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# 특성과 타겟 분리
X = df.drop(columns=['채무 불이행 여부'])  # 입력 변수
y = df['채무 불이행 여부']  # 목표 변수

# 데이터 정규화 (스케일링)
scaler = StandardScaler()
X = scaler.fit_transform(X)

# 학습 데이터와 테스트 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 모델 학습
# Decision Tree 모델 (과적합 방지 조치 포함)
dt_model = DecisionTreeClassifier(max_depth=5, min_samples_split=10, random_state=42)
dt_model.fit(X_train, y_train)

# Hard Voting을 사용하는 앙상블 모델 (RandomForest 포함)
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
log_model = LogisticRegression()
svm_model = SVC(probability=True)

ensemble_model = VotingClassifier(estimators=[
    ('dt', dt_model),
    ('rf', rf_model),
    ('svm', svm_model)
], voting='hard')
ensemble_model.fit(X_train, y_train)

# 4. 정확도 평가
dt_pred = dt_model.predict(X_test)
ensemble_pred = ensemble_model.predict(X_test)

dt_accuracy = accuracy_score(y_test, dt_pred)
ensemble_accuracy = accuracy_score(y_test, ensemble_pred)

print(f"의사결정나무 정확도: {dt_accuracy:.4f}")
print(f"하드 보팅 앙상블 정확도: {ensemble_accuracy:.4f}")

# 5. Decision Tree의 Feature Importance 시각화
feature_importance = dt_model.feature_importances_
feature_names = df.drop(columns=['채무 불이행 여부']).columns

plt.figure(figsize=(10, 6))
sns.barplot(x=feature_importance, y=feature_names, palette='viridis')
plt.xlabel("특성 중요도")
plt.ylabel("특성")
plt.title("의사결정나무 - 특성 중요도 분석")
plt.show()

# 6. Hard Voting 모델 예측 결과 시각화
plt.figure(figsize=(8, 5))
sns.histplot(ensemble_pred, bins=3, kde=False, color='green')
plt.xticks([0, 1], labels=['정상 납부', '채무 불이행'])
plt.xlabel("예측 결과")
plt.ylabel("개수")
plt.title("하드 보팅 앙상블 - 예측 결과 분포")
plt.show()

# 의사결정나무 정확도: 0.6705
# 하드 보팅 앙상블 정확도: 0.6950
